{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "import keras.backend as K\n",
    "from keras.layers import Dense, Dropout, Activation,Input, Merge, add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Data/trainset_impute50000.csv')\n",
    "x = data.drop(data.columns[[0, 1]], axis=1)\n",
    "x = np.array(x)\n",
    "y = data['target']\n",
    "y = np.array(y)\n",
    "random.seed(867)\n",
    "train_index = np.random.choice(range(data.shape[0]),int(0.8*data.shape[0]))\n",
    "validate_index=set(range(data.shape[0]))-set(train_index)\n",
    "validate_index=np.array(list(validate_index),dtype='int64')\n",
    "#\n",
    "x_train = x[train_index,:]\n",
    "x_validate = x[validate_index,:]\n",
    "y_train = y[train_index]\n",
    "y_validate = y[validate_index]\n",
    "#\n",
    "case_index = [i for i,t in enumerate(y_train) if t == 1]\n",
    "control_index = [i for i,t in enumerate(y_train) if t == 0]\n",
    "#\n",
    "new_control_index = np.random.choice(control_index,4*len(case_index))\n",
    "new_index = np.concatenate((new_control_index,case_index))\n",
    "new_index\n",
    "#\n",
    "new_x_train = x_train[new_index,:]\n",
    "new_y_train = y_train[new_index]\n",
    "# Convert to one-hot-vector\n",
    "nb_classes = 2\n",
    "#OH_new_y_train = np.eye(nb_classes)[y_train]\n",
    "OH_new_y_train = np.eye(nb_classes)[new_y_train]\n",
    "OH_y_validate = np.eye(nb_classes)[y_validate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.6344379316\n"
     ]
    }
   ],
   "source": [
    "print(sum(y_train==0)/sum(y_train==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "# Fit only to the training data\n",
    "scaler.fit(new_x_train)\n",
    "\n",
    "new_x_train = scaler.transform(new_x_train)\n",
    "#new_x_train = scaler.transform(x_train)\n",
    "x_validate = scaler.transform(x_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gini(OH_y_trues, OH_y_preds):\n",
    "    sess = tf.Session()\n",
    "    with sess.as_default():\n",
    "        y_true = tf.constant(OH_y_trues).eval(shape=(2, ), dtype=float32)\n",
    "        y_pred = tf.Variable(OH_y_preds).eval(shape=(2, ), dtype=float32)\n",
    "    # check and get number of samples\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    n_samples = y_true.shape[0]\n",
    "    \n",
    "    # sort rows on prediction column \n",
    "    # (from largest to smallest)\n",
    "    arr = np.array([y_true, y_pred]).transpose()\n",
    "    true_order = arr[arr[:,0].argsort()][::-1,0]\n",
    "    pred_order = arr[arr[:,1].argsort()][::-1,0]\n",
    "    \n",
    "    # get Lorenz curves\n",
    "    L_true = np.cumsum(true_order) / np.sum(true_order)\n",
    "    L_pred = np.cumsum(pred_order) / np.sum(pred_order)\n",
    "    L_ones = np.linspace(1/n_samples, 1, n_samples)\n",
    "    \n",
    "    # get Gini coefficients (area between curves)\n",
    "    G_true = np.sum(L_ones - L_true)\n",
    "    G_pred = np.sum(L_ones - L_pred)\n",
    "    \n",
    "    # normalize to true Gini coefficient\n",
    "    val = G_pred/G_true\n",
    "    var = K.variable(value=val)\n",
    "    return(var)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable_1:0' shape=() dtype=float32_ref>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean_pred(y_true, y_pred):\n",
    "    m = np.mean(y_true)\n",
    "    var = K.variable(value=m)\n",
    "    return (var)\n",
    "mean_pred(np.array([0,1]),np.array([0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(type(tf.constant(OH_y_true)))\n",
    "with sess.as_default():\n",
    "    OH_y_true = tf.constant(OH_y_true).eval()\n",
    "#    OH_y_pred = OH_y_pred.eval()\n",
    "    print(type(OH_y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "def gini(actual, pred):\n",
    "    pred = tf.argmax(pred, axis=1)\n",
    "    actual = tf.argmax(actual, axis=1)\n",
    "    nT = K.shape(pred)[0]\n",
    "    n = K.cast(nT, dtype='int32')\n",
    "    n_float = K.cast(nT, dtype=K.floatx())\n",
    "    actual = K.reshape(actual,(1,n))[-1]\n",
    "    pred = K.reshape(pred,(1,n))[-1]\n",
    "    inds = tf.nn.top_k(pred, n)[1]\n",
    "    a_s = K.gather(actual, inds)\n",
    "    a_c = K.cumsum(a_s)\n",
    "    s1 = K.sum(a_c)\n",
    "    s2 = K.sum(a_s)\n",
    "    giniSum = K.cast(tf.divide(s1,s2),dtype=K.floatx()) - K.cast(tf.divide(n+1,2),dtype=K.floatx())\n",
    "    standard_gini = K.cast(tf.divide(giniSum,n_float),dtype=K.floatx())\n",
    "    return standard_gini\n",
    "\n",
    "def gini_normalized(a, p):\n",
    "    norm_gini = K.cast(tf.divide(gini(a, p),gini(a, a)),dtype=K.floatx())\n",
    "    return norm_gini\n",
    "\n",
    "## new loss\n",
    "## pred  actual  loss\n",
    "##  0       1      9\n",
    "##  1       0      1 \n",
    "##  1/0     1/0    0\n",
    "##  a=5,b=-4,c=0\n",
    "\n",
    "def new_loss(actual,pred):\n",
    "    return K.mean(5*K.square(pred-actual)-4*(pred-actual),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.625,  2.5  ])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weight = class_weight.compute_class_weight('balanced', np.unique(new_y_train), new_y_train)\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 86155 samples, validate on 267355 samples\n",
      "Epoch 1/20\n",
      "86155/86155 [==============================] - 10s 110us/step - loss: 0.4890 - acc: 0.7996 - gini_normalized: 0.0036 - val_loss: 0.2554 - val_acc: 0.9618 - val_gini_normalized: -0.0029\n",
      "Epoch 2/20\n",
      "86155/86155 [==============================] - 8s 92us/step - loss: 0.4715 - acc: 0.8015 - gini_normalized: 0.0217 - val_loss: 0.3015 - val_acc: 0.9495 - val_gini_normalized: 0.0169\n",
      "Epoch 3/20\n",
      "86155/86155 [==============================] - 8s 96us/step - loss: 0.4542 - acc: 0.8058 - gini_normalized: 0.0669 - val_loss: 0.2925 - val_acc: 0.9452 - val_gini_normalized: 0.0214\n",
      "Epoch 4/20\n",
      "86155/86155 [==============================] - 9s 99us/step - loss: 0.4323 - acc: 0.8144 - gini_normalized: 0.1180 - val_loss: 0.2763 - val_acc: 0.9413 - val_gini_normalized: 0.0180\n",
      "Epoch 5/20\n",
      "86155/86155 [==============================] - 9s 100us/step - loss: 0.4080 - acc: 0.8249 - gini_normalized: 0.1865 - val_loss: 0.2472 - val_acc: 0.9434 - val_gini_normalized: 0.0169\n",
      "Epoch 6/20\n",
      "86155/86155 [==============================] - 8s 98us/step - loss: 0.3808 - acc: 0.8384 - gini_normalized: 0.2579 - val_loss: 0.2491 - val_acc: 0.9331 - val_gini_normalized: 0.0220\n",
      "Epoch 7/20\n",
      "86155/86155 [==============================] - 8s 97us/step - loss: 0.3559 - acc: 0.8509 - gini_normalized: 0.3363 - val_loss: 0.2216 - val_acc: 0.9411 - val_gini_normalized: 0.0170\n",
      "Epoch 8/20\n",
      "86155/86155 [==============================] - 8s 96us/step - loss: 0.3310 - acc: 0.8640 - gini_normalized: 0.4027 - val_loss: 0.3686 - val_acc: 0.8571 - val_gini_normalized: 0.0490\n",
      "Epoch 9/20\n",
      "86155/86155 [==============================] - 9s 104us/step - loss: 0.3086 - acc: 0.8747 - gini_normalized: 0.4620 - val_loss: 0.2930 - val_acc: 0.9003 - val_gini_normalized: 0.0356\n",
      "Epoch 10/20\n",
      "86155/86155 [==============================] - 8s 98us/step - loss: 0.2877 - acc: 0.8860 - gini_normalized: 0.5202 - val_loss: 0.2620 - val_acc: 0.9196 - val_gini_normalized: 0.0150\n",
      "Epoch 11/20\n",
      "86155/86155 [==============================] - 9s 100us/step - loss: 0.2691 - acc: 0.8938 - gini_normalized: 0.5638 - val_loss: 0.3452 - val_acc: 0.8697 - val_gini_normalized: 0.0428\n",
      "Epoch 12/20\n",
      "86155/86155 [==============================] - 9s 105us/step - loss: 0.2484 - acc: 0.9033 - gini_normalized: 0.6074 - val_loss: 0.3238 - val_acc: 0.8846 - val_gini_normalized: 0.0368\n",
      "Epoch 13/20\n",
      "86155/86155 [==============================] - 9s 109us/step - loss: 0.2311 - acc: 0.9115 - gini_normalized: 0.6491 - val_loss: 0.3000 - val_acc: 0.9012 - val_gini_normalized: 0.0276\n",
      "Epoch 14/20\n",
      "86155/86155 [==============================] - 9s 104us/step - loss: 0.2140 - acc: 0.9186 - gini_normalized: 0.6761 - val_loss: 0.4268 - val_acc: 0.8341 - val_gini_normalized: 0.0458\n",
      "Epoch 15/20\n",
      "86155/86155 [==============================] - 10s 116us/step - loss: 0.2014 - acc: 0.9243 - gini_normalized: 0.7063 - val_loss: 0.5225 - val_acc: 0.7928 - val_gini_normalized: 0.0591\n",
      "Epoch 16/20\n",
      "86155/86155 [==============================] - 9s 99us/step - loss: 0.1850 - acc: 0.9306 - gini_normalized: 0.7362 - val_loss: 0.3392 - val_acc: 0.8907 - val_gini_normalized: 0.0284\n",
      "Epoch 17/20\n",
      "86155/86155 [==============================] - 10s 111us/step - loss: 0.1745 - acc: 0.9345 - gini_normalized: 0.7497 - val_loss: 0.3724 - val_acc: 0.8784 - val_gini_normalized: 0.0344\n",
      "Epoch 18/20\n",
      "86155/86155 [==============================] - 9s 108us/step - loss: 0.1605 - acc: 0.9402 - gini_normalized: 0.7731 - val_loss: 0.4486 - val_acc: 0.8501 - val_gini_normalized: 0.0428\n",
      "Epoch 19/20\n",
      "86155/86155 [==============================] - 8s 97us/step - loss: 0.1486 - acc: 0.9450 - gini_normalized: 0.7927 - val_loss: 0.3328 - val_acc: 0.9131 - val_gini_normalized: 0.0236\n",
      "Epoch 20/20\n",
      "86155/86155 [==============================] - 10s 114us/step - loss: 0.1381 - acc: 0.9492 - gini_normalized: 0.8098 - val_loss: 0.4104 - val_acc: 0.8782 - val_gini_normalized: 0.0355\n",
      "267355/267355 [==============================] - 3s 13us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.41044083386015878, 0.87821061852153492, 0.044885182301120825]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(400, input_dim=np.shape(x)[1], activation='relu'))\n",
    "model.add(Dense(200, input_dim=np.shape(x)[1], activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',gini_normalized])\n",
    "\n",
    "model.fit(new_x_train, OH_new_y_train,epochs=20,batch_size=200 ,#,class_weight = {0:0.51901583 , 1:13.64693913},\n",
    "          validation_data=(x_validate, OH_y_validate))\n",
    "model.evaluate(x_validate, OH_y_validate, batch_size=1000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datagen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-bb7634cd73a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fit the model on the batches generated by datagen.flow().\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model1.fit_generator(datagen.flow(new_x_train, OH_new_y_train,\n\u001b[0m\u001b[1;32m      3\u001b[0m                     batch_size=1000),\n\u001b[1;32m      4\u001b[0m                     \u001b[0msamples_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_x_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datagen' is not defined"
     ]
    }
   ],
   "source": [
    "# Fit the model on the batches generated by datagen.flow().\n",
    "model1.fit_generator(datagen.flow(new_x_train, OH_new_y_train,\n",
    "                    batch_size=1000),\n",
    "                    samples_per_epoch=new_x_train.shape[0],\n",
    "                    nb_epoch=40,\n",
    "                    validation_data=(x_validate, OH_y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"metrics_61/gini_normalized/Shape:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"metrics_61/gini_normalized/Shape_2:0\", shape=(2,), dtype=int32)\n",
      "Epoch 1/10\n",
      "86150/86150 [==============================] - 6s 75us/step - loss: 0.5189 - acc: 0.7965 - gini_normalized: 0.6007\n",
      "Epoch 2/10\n",
      "86150/86150 [==============================] - 5s 58us/step - loss: 0.5036 - acc: 0.7999 - gini_normalized: 0.5868\n",
      "Epoch 3/10\n",
      "86150/86150 [==============================] - 5s 55us/step - loss: 0.5007 - acc: 0.7998 - gini_normalized: 0.5369\n",
      "Epoch 4/10\n",
      "86150/86150 [==============================] - 5s 56us/step - loss: 0.5005 - acc: 0.7999 - gini_normalized: 0.5926\n",
      "Epoch 5/10\n",
      "86150/86150 [==============================] - 5s 59us/step - loss: 0.4994 - acc: 0.7999 - gini_normalized: 0.6019\n",
      "Epoch 6/10\n",
      "86150/86150 [==============================] - 5s 58us/step - loss: 0.4988 - acc: 0.8000 - gini_normalized: 0.5961\n",
      "Epoch 7/10\n",
      "86150/86150 [==============================] - 5s 58us/step - loss: 0.4987 - acc: 0.7999 - gini_normalized: 0.5775\n",
      "Epoch 8/10\n",
      "86150/86150 [==============================] - 5s 59us/step - loss: 0.4973 - acc: 0.7999 - gini_normalized: 0.6053\n",
      "Epoch 9/10\n",
      "25400/86150 [=======>......................] - ETA: 4s - loss: 0.4981 - acc: 0.8003 - gini_normalized: 0.5748"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-197-632093fe5bf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m               metrics=['accuracy',gini_normalized])\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_x_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOH_new_y_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    891\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2330\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2331\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2332\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "##\n",
    "model = Sequential()\n",
    "model.add(Dense(400, input_dim=np.shape(x)[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(200, input_dim=np.shape(x)[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, input_dim=np.shape(x)[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "sgd = SGD(lr=0.01, decay=1e-2, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy',gini_normalized])\n",
    "\n",
    "model.fit(new_x_train, OH_new_y_train,epochs=10,batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Libraries\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras import regularizers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Read in data\n",
    "data_linear_true = pd.read_csv('../Data/Simulation/sim_int_truefeatures.csv') \n",
    "data_linear_extra = pd.read_csv('../Data/Simulation/sim_int_withextrafeatures.csv')\n",
    "data_nonlinear_true = pd.read_csv('../Data/Simulation/sim_nonlinear_int_truefeatures.csv')\n",
    "data_nonlinear_extra = pd.read_csv('../Data/Simulation/sim_nonlinear_int_withextrafeatures.csv')\n",
    "\n",
    "x_linear_true = np.array(data_linear_true.iloc[:,1:data_linear_true.shape[1]]) #1:12 - true predictors, 13:17 - useless predictors\n",
    "x_linear_extra = np.array(data_linear_extra.iloc[:,1:data_linear_extra.shape[1]])\n",
    "y_linear = np.array(data_linear_true.iloc[:,0])\n",
    "\n",
    "x_nonlinear_true = np.array(data_nonlinear_true.iloc[:,1:data_nonlinear_true.shape[1]])\n",
    "x_nonlinear_extra = np.array(data_nonlinear_extra.iloc[:,1:data_nonlinear_extra.shape[1]])\n",
    "y_nonlinear = np.array(data_nonlinear_true.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Define gini coefficient\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "def gini(actual, pred):\n",
    "    pred = tf.argmax(pred, axis=1)\n",
    "    actual = tf.argmax(actual, axis=1)\n",
    "    nT = K.shape(pred)[0]\n",
    "    n = K.cast(nT, dtype='int32')\n",
    "    n_float = K.cast(nT, dtype=K.floatx())\n",
    "    actual = K.reshape(actual,(1,n))[-1]\n",
    "    pred = K.reshape(pred,(1,n))[-1]\n",
    "    inds = tf.nn.top_k(pred, n)[1]\n",
    "    a_s = K.gather(actual, inds)\n",
    "    a_c = K.cumsum(a_s)\n",
    "    s1 = K.sum(a_c)\n",
    "    s2 = K.sum(a_s)\n",
    "    giniSum = K.cast(tf.divide(s1,s2),dtype=K.floatx()) - K.cast(tf.divide(n+1,2),dtype=K.floatx())\n",
    "    standard_gini = K.cast(tf.divide(giniSum,n_float),dtype=K.floatx())\n",
    "    return standard_gini\n",
    "\n",
    "def gini_normalized(a, p):\n",
    "    norm_gini = K.cast(tf.divide(gini(a, p),gini(a, a)),dtype=K.floatx())\n",
    "    return norm_gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.2171 - acc: 0.7336 - gini_normalized: nan - val_loss: 1.0183 - val_acc: 0.8220 - val_gini_normalized: nan\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.8879 - acc: 0.8376 - gini_normalized: nan - val_loss: 0.7713 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.6918 - acc: 0.8508 - gini_normalized: nan - val_loss: 0.6168 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.5678 - acc: 0.8556 - gini_normalized: nan - val_loss: 0.5175 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.4953 - acc: 0.8588 - gini_normalized: nan - val_loss: 0.4667 - val_acc: 0.8520 - val_gini_normalized: nan\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.4579 - acc: 0.8600 - gini_normalized: nan - val_loss: 0.4393 - val_acc: 0.8520 - val_gini_normalized: nan\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4367 - acc: 0.8592 - gini_normalized: nan - val_loss: 0.4253 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.4232 - acc: 0.8588 - gini_normalized: nan - val_loss: 0.4124 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4138 - acc: 0.8616 - gini_normalized: nan - val_loss: 0.4090 - val_acc: 0.8580 - val_gini_normalized: nan\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.4077 - acc: 0.8616 - gini_normalized: nan - val_loss: 0.3992 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4019 - acc: 0.8620 - gini_normalized: nan - val_loss: 0.3924 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.3982 - acc: 0.8608 - gini_normalized: nan - val_loss: 0.4001 - val_acc: 0.8520 - val_gini_normalized: nan\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3957 - acc: 0.8584 - gini_normalized: nan - val_loss: 0.3877 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.3927 - acc: 0.8572 - gini_normalized: nan - val_loss: 0.3823 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.3904 - acc: 0.8564 - gini_normalized: nan - val_loss: 0.3794 - val_acc: 0.8560 - val_gini_normalized: nan\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.3874 - acc: 0.8588 - gini_normalized: nan - val_loss: 0.3789 - val_acc: 0.8560 - val_gini_normalized: nan\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.3853 - acc: 0.8628 - gini_normalized: nan - val_loss: 0.3796 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.3843 - acc: 0.8584 - gini_normalized: nan - val_loss: 0.3795 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.3822 - acc: 0.8608 - gini_normalized: nan - val_loss: 0.3731 - val_acc: 0.8520 - val_gini_normalized: nan\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.3812 - acc: 0.8548 - gini_normalized: nan - val_loss: 0.3754 - val_acc: 0.8560 - val_gini_normalized: nan\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.3796 - acc: 0.8612 - gini_normalized: nan - val_loss: 0.3765 - val_acc: 0.8560 - val_gini_normalized: nan\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.3797 - acc: 0.8576 - gini_normalized: nan - val_loss: 0.3744 - val_acc: 0.8580 - val_gini_normalized: nan\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3763 - acc: 0.8600 - gini_normalized: nan - val_loss: 0.3678 - val_acc: 0.8520 - val_gini_normalized: nan\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.3769 - acc: 0.8608 - gini_normalized: nan - val_loss: 0.3717 - val_acc: 0.8520 - val_gini_normalized: nan\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.3757 - acc: 0.8628 - gini_normalized: nan - val_loss: 0.3658 - val_acc: 0.8560 - val_gini_normalized: nan\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.3742 - acc: 0.8624 - gini_normalized: nan - val_loss: 0.3843 - val_acc: 0.8520 - val_gini_normalized: nan\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.3730 - acc: 0.8588 - gini_normalized: nan - val_loss: 0.3786 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.3736 - acc: 0.8572 - gini_normalized: nan - val_loss: 0.3868 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.3742 - acc: 0.8596 - gini_normalized: nan - val_loss: 0.3697 - val_acc: 0.8580 - val_gini_normalized: nan\n",
      "Epoch 30/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.3711 - acc: 0.8584 - gini_normalized: nan - val_loss: 0.3649 - val_acc: 0.8600 - val_gini_normalized: nan\n",
      "Epoch 31/50\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.3702 - acc: 0.8596 - gini_normalized: nan - val_loss: 0.3624 - val_acc: 0.8560 - val_gini_normalized: nan\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.3695 - acc: 0.8620 - gini_normalized: nan - val_loss: 0.3844 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.3702 - acc: 0.8588 - gini_normalized: nan - val_loss: 0.3828 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.3700 - acc: 0.8564 - gini_normalized: nan - val_loss: 0.3587 - val_acc: 0.8620 - val_gini_normalized: nan\n",
      "Epoch 35/50\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.3680 - acc: 0.8536 - gini_normalized: nan - val_loss: 0.3579 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 36/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3673 - acc: 0.8592 - gini_normalized: nan - val_loss: 0.3808 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 37/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.3675 - acc: 0.8604 - gini_normalized: nan - val_loss: 0.3628 - val_acc: 0.8640 - val_gini_normalized: nan\n",
      "Epoch 38/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.3660 - acc: 0.8512 - gini_normalized: nan - val_loss: 0.3750 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 39/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.3670 - acc: 0.8556 - gini_normalized: nan - val_loss: 0.3583 - val_acc: 0.8580 - val_gini_normalized: nan\n",
      "Epoch 40/50\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.3661 - acc: 0.8620 - gini_normalized: nan - val_loss: 0.3595 - val_acc: 0.8580 - val_gini_normalized: nan\n",
      "Epoch 41/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.3655 - acc: 0.8588 - gini_normalized: nan - val_loss: 0.3663 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 42/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.3664 - acc: 0.8588 - gini_normalized: nan - val_loss: 0.3564 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 43/50\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.3646 - acc: 0.8584 - gini_normalized: nan - val_loss: 0.3713 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 44/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.3659 - acc: 0.8604 - gini_normalized: nan - val_loss: 0.3615 - val_acc: 0.8540 - val_gini_normalized: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.3640 - acc: 0.8596 - gini_normalized: nan - val_loss: 0.3545 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 46/50\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.3646 - acc: 0.8572 - gini_normalized: nan - val_loss: 0.3576 - val_acc: 0.8600 - val_gini_normalized: nan\n",
      "Epoch 47/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3624 - acc: 0.8560 - gini_normalized: nan - val_loss: 0.3732 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 48/50\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.3641 - acc: 0.8540 - gini_normalized: nan - val_loss: 0.3637 - val_acc: 0.8560 - val_gini_normalized: nan\n",
      "Epoch 49/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3614 - acc: 0.8564 - gini_normalized: nan - val_loss: 0.3748 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 50/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.3639 - acc: 0.8576 - gini_normalized: nan - val_loss: 0.3620 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "500/500 [==============================] - ETA:  - 0s 54us/step\n"
     ]
    }
   ],
   "source": [
    "## with interaction but no useless predictors\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(100, input_dim=np.shape(x_linear_true)[1]-5, kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model1.add(Dense(10, kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',gini_normalized])\n",
    "\n",
    "trace1 = model1.fit(x_linear_true[0:2500,0:12], y_linear[0:2500],epochs=50,batch_size=64, \\\n",
    "                    validation_data=(x_linear_true[2500:3000,0:12], y_linear[2500:3000]))\n",
    "score1 = model1.evaluate(x_linear_true[2500:3000,0:12], y_linear[2500:3000], batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.36199387168884278, 0.85400000047683711, nan]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.1036 - acc: 0.6892 - gini_normalized: nan - val_loss: 0.9686 - val_acc: 0.7380 - val_gini_normalized: nan\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.8752 - acc: 0.7652 - gini_normalized: nan - val_loss: 0.8066 - val_acc: 0.7120 - val_gini_normalized: nan\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.7364 - acc: 0.7796 - gini_normalized: nan - val_loss: 0.6910 - val_acc: 0.7720 - val_gini_normalized: nan\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.6470 - acc: 0.7916 - gini_normalized: nan - val_loss: 0.6181 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.5935 - acc: 0.8068 - gini_normalized: nan - val_loss: 0.5798 - val_acc: 0.8100 - val_gini_normalized: nan\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.5642 - acc: 0.8172 - gini_normalized: nan - val_loss: 0.5547 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.5469 - acc: 0.8272 - gini_normalized: nan - val_loss: 0.5426 - val_acc: 0.8260 - val_gini_normalized: nan\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.5350 - acc: 0.8284 - gini_normalized: nan - val_loss: 0.5347 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.5273 - acc: 0.8300 - gini_normalized: nan - val_loss: 0.5278 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.5206 - acc: 0.8328 - gini_normalized: nan - val_loss: 0.5211 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.5150 - acc: 0.8376 - gini_normalized: nan - val_loss: 0.5144 - val_acc: 0.8200 - val_gini_normalized: nan\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.5090 - acc: 0.8364 - gini_normalized: nan - val_loss: 0.5060 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.5047 - acc: 0.8364 - gini_normalized: nan - val_loss: 0.5044 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.5007 - acc: 0.8416 - gini_normalized: nan - val_loss: 0.5121 - val_acc: 0.8220 - val_gini_normalized: nan\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4980 - acc: 0.8364 - gini_normalized: nan - val_loss: 0.4948 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4919 - acc: 0.8360 - gini_normalized: nan - val_loss: 0.4900 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4894 - acc: 0.8412 - gini_normalized: nan - val_loss: 0.4948 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4875 - acc: 0.8432 - gini_normalized: nan - val_loss: 0.4840 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4844 - acc: 0.8412 - gini_normalized: nan - val_loss: 0.4847 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4809 - acc: 0.8420 - gini_normalized: nan - val_loss: 0.4797 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4797 - acc: 0.8436 - gini_normalized: nan - val_loss: 0.4825 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.4766 - acc: 0.8404 - gini_normalized: nan - val_loss: 0.4798 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4742 - acc: 0.8416 - gini_normalized: nan - val_loss: 0.4706 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4717 - acc: 0.8388 - gini_normalized: nan - val_loss: 0.4679 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4704 - acc: 0.8388 - gini_normalized: nan - val_loss: 0.4662 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4685 - acc: 0.8440 - gini_normalized: nan - val_loss: 0.4706 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4674 - acc: 0.8440 - gini_normalized: nan - val_loss: 0.4620 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4655 - acc: 0.8400 - gini_normalized: nan - val_loss: 0.4644 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4628 - acc: 0.8468 - gini_normalized: nan - val_loss: 0.4706 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 30/50\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4635 - acc: 0.8392 - gini_normalized: nan - val_loss: 0.4619 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 31/50\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4615 - acc: 0.8416 - gini_normalized: nan - val_loss: 0.4604 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4588 - acc: 0.8440 - gini_normalized: nan - val_loss: 0.4598 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.4584 - acc: 0.8444 - gini_normalized: nan - val_loss: 0.4713 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4569 - acc: 0.8456 - gini_normalized: nan - val_loss: 0.4551 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 35/50\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.4555 - acc: 0.8416 - gini_normalized: nan - val_loss: 0.4630 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 36/50\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4561 - acc: 0.8416 - gini_normalized: nan - val_loss: 0.4521 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 37/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4519 - acc: 0.8456 - gini_normalized: nan - val_loss: 0.4532 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 38/50\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4512 - acc: 0.8456 - gini_normalized: nan - val_loss: 0.4517 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 39/50\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4498 - acc: 0.8448 - gini_normalized: nan - val_loss: 0.4481 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 40/50\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.4491 - acc: 0.8444 - gini_normalized: nan - val_loss: 0.4557 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 41/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4483 - acc: 0.8456 - gini_normalized: nan - val_loss: 0.4645 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 42/50\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4470 - acc: 0.8400 - gini_normalized: nan - val_loss: 0.4546 - val_acc: 0.8180 - val_gini_normalized: nan\n",
      "Epoch 43/50\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4474 - acc: 0.8396 - gini_normalized: nan - val_loss: 0.4545 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 44/50\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.4458 - acc: 0.8432 - gini_normalized: nan - val_loss: 0.4478 - val_acc: 0.8360 - val_gini_normalized: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.4439 - acc: 0.8488 - gini_normalized: nan - val_loss: 0.4774 - val_acc: 0.8140 - val_gini_normalized: nan\n",
      "Epoch 46/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4467 - acc: 0.8380 - gini_normalized: nan - val_loss: 0.4432 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 47/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4432 - acc: 0.8476 - gini_normalized: nan - val_loss: 0.4518 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 48/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4422 - acc: 0.8416 - gini_normalized: nan - val_loss: 0.4544 - val_acc: 0.8180 - val_gini_normalized: nan\n",
      "Epoch 49/50\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4409 - acc: 0.8472 - gini_normalized: nan - val_loss: 0.4396 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 50/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4391 - acc: 0.8500 - gini_normalized: nan - val_loss: 0.4781 - val_acc: 0.8140 - val_gini_normalized: nan\n",
      "500/500 [==============================] - 0s 52us/step\n"
     ]
    }
   ],
   "source": [
    "## without interaction or useless predictors\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(100, input_dim=np.shape(x_linear_true)[1]-10, kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model2.add(Dense(10, kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',gini_normalized])\n",
    "\n",
    "trace2 = model2.fit(x_linear_true[0:2500,0:7], y_linear[0:2500],epochs=50,batch_size=64, \\\n",
    "                    validation_data=(x_linear_true[2500:3000,0:7], y_linear[2500:3000]))\n",
    "score2 = model2.evaluate(x_linear_true[2500:3000,0:7], y_linear[2500:3000], batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4781001751422882, 0.81399999952316282, nan]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.2442 - acc: 0.6912 - gini_normalized: nan - val_loss: 1.0701 - val_acc: 0.7220 - val_gini_normalized: nan\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 0s 88us/step - loss: 0.9566 - acc: 0.7544 - gini_normalized: nan - val_loss: 0.8552 - val_acc: 0.7460 - val_gini_normalized: nan\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.7788 - acc: 0.7672 - gini_normalized: nan - val_loss: 0.7156 - val_acc: 0.7600 - val_gini_normalized: nan\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.6715 - acc: 0.7804 - gini_normalized: nan - val_loss: 0.6379 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.6122 - acc: 0.7936 - gini_normalized: nan - val_loss: 0.5938 - val_acc: 0.8020 - val_gini_normalized: nan\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.5765 - acc: 0.8064 - gini_normalized: nan - val_loss: 0.5672 - val_acc: 0.8000 - val_gini_normalized: nan\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.5552 - acc: 0.8200 - gini_normalized: nan - val_loss: 0.5582 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.5416 - acc: 0.8188 - gini_normalized: nan - val_loss: 0.5464 - val_acc: 0.8040 - val_gini_normalized: nan\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.5305 - acc: 0.8272 - gini_normalized: nan - val_loss: 0.5236 - val_acc: 0.8200 - val_gini_normalized: nan\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.5225 - acc: 0.8268 - gini_normalized: nan - val_loss: 0.5221 - val_acc: 0.8260 - val_gini_normalized: nan\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.5155 - acc: 0.8292 - gini_normalized: nan - val_loss: 0.5190 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.5076 - acc: 0.8328 - gini_normalized: nan - val_loss: 0.5050 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.5033 - acc: 0.8340 - gini_normalized: nan - val_loss: 0.5064 - val_acc: 0.8260 - val_gini_normalized: nan\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4994 - acc: 0.8400 - gini_normalized: nan - val_loss: 0.4943 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.4942 - acc: 0.8400 - gini_normalized: nan - val_loss: 0.5053 - val_acc: 0.8180 - val_gini_normalized: nan\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.4919 - acc: 0.8420 - gini_normalized: nan - val_loss: 0.5041 - val_acc: 0.8080 - val_gini_normalized: nan\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.4874 - acc: 0.8416 - gini_normalized: nan - val_loss: 0.5063 - val_acc: 0.8080 - val_gini_normalized: nan\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.4861 - acc: 0.8448 - gini_normalized: nan - val_loss: 0.4849 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.4804 - acc: 0.8452 - gini_normalized: nan - val_loss: 0.4874 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4785 - acc: 0.8448 - gini_normalized: nan - val_loss: 0.4765 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.4775 - acc: 0.8416 - gini_normalized: nan - val_loss: 0.4828 - val_acc: 0.8220 - val_gini_normalized: nan\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4739 - acc: 0.8468 - gini_normalized: nan - val_loss: 0.4904 - val_acc: 0.8220 - val_gini_normalized: nan\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.4719 - acc: 0.8384 - gini_normalized: nan - val_loss: 0.4715 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.4706 - acc: 0.8404 - gini_normalized: nan - val_loss: 0.4664 - val_acc: 0.8520 - val_gini_normalized: nan\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.4686 - acc: 0.8436 - gini_normalized: nan - val_loss: 0.4692 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.4665 - acc: 0.8408 - gini_normalized: nan - val_loss: 0.4804 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.4662 - acc: 0.8436 - gini_normalized: nan - val_loss: 0.4591 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4642 - acc: 0.8380 - gini_normalized: nan - val_loss: 0.4643 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.4617 - acc: 0.8496 - gini_normalized: nan - val_loss: 0.4585 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 30/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4589 - acc: 0.8432 - gini_normalized: nan - val_loss: 0.4703 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 31/50\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.4588 - acc: 0.8420 - gini_normalized: nan - val_loss: 0.4633 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.4576 - acc: 0.8424 - gini_normalized: nan - val_loss: 0.4540 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4541 - acc: 0.8392 - gini_normalized: nan - val_loss: 0.4579 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.4546 - acc: 0.8444 - gini_normalized: nan - val_loss: 0.4551 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 35/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4521 - acc: 0.8428 - gini_normalized: nan - val_loss: 0.4641 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 36/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4518 - acc: 0.8388 - gini_normalized: nan - val_loss: 0.4696 - val_acc: 0.8220 - val_gini_normalized: nan\n",
      "Epoch 37/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4518 - acc: 0.8480 - gini_normalized: nan - val_loss: 0.4508 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 38/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4491 - acc: 0.8488 - gini_normalized: nan - val_loss: 0.4667 - val_acc: 0.8200 - val_gini_normalized: nan\n",
      "Epoch 39/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4473 - acc: 0.8416 - gini_normalized: nan - val_loss: 0.4482 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 40/50\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.4481 - acc: 0.8428 - gini_normalized: nan - val_loss: 0.4650 - val_acc: 0.8260 - val_gini_normalized: nan\n",
      "Epoch 41/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.4476 - acc: 0.8448 - gini_normalized: nan - val_loss: 0.4493 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 42/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4461 - acc: 0.8500 - gini_normalized: nan - val_loss: 0.4584 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 43/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4464 - acc: 0.8452 - gini_normalized: nan - val_loss: 0.4486 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 44/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4423 - acc: 0.8448 - gini_normalized: nan - val_loss: 0.4486 - val_acc: 0.8340 - val_gini_normalized: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.4424 - acc: 0.8500 - gini_normalized: nan - val_loss: 0.4721 - val_acc: 0.8160 - val_gini_normalized: nan\n",
      "Epoch 46/50\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.4417 - acc: 0.8436 - gini_normalized: nan - val_loss: 0.4773 - val_acc: 0.8040 - val_gini_normalized: nan\n",
      "Epoch 47/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4409 - acc: 0.8508 - gini_normalized: nan - val_loss: 0.4497 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 48/50\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.4383 - acc: 0.8512 - gini_normalized: nan - val_loss: 0.4431 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 49/50\n",
      "2500/2500 [==============================] - 0s 84us/step - loss: 0.4394 - acc: 0.8440 - gini_normalized: nan - val_loss: 0.4422 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 50/50\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.4370 - acc: 0.8472 - gini_normalized: nan - val_loss: 0.4378 - val_acc: 0.8360 - val_gini_normalized: nan\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_308_input to have shape (None, 12) but got array with shape (500, 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-292-9c47330ce543>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mtrace3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_linear_true\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_linear_true\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m17\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_linear\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2500\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_linear_true\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2500\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_linear_true\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2500\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m17\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_linear\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2500\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mscore3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_linear_true\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2500\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_linear\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2500\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Irina\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight)\u001b[0m\n\u001b[0;32m    987\u001b[0m                                    \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m                                    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 989\u001b[1;33m                                    sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    990\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Irina\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[0;32m   1714\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1715\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1716\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1717\u001b[0m         \u001b[1;31m# Prepare inputs, delegate logic to `_test_loop`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1718\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Irina\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[0;32m   1405\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1406\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m                                     exception_prefix='input')\n\u001b[0m\u001b[0;32m   1408\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[0;32m   1409\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Irina\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    151\u001b[0m                             \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m                             \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m                             str(array.shape))\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_308_input to have shape (None, 12) but got array with shape (500, 17)"
     ]
    }
   ],
   "source": [
    "## all original predictors #0:7,12:17\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(100, input_dim=12, kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model3.add(Dense(10, kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',gini_normalized])\n",
    "\n",
    "trace3 = model3.fit(np.concatenate((x_linear_true[0:2500,0:7],x_linear_true[0:2500,12:17]), axis=1), y_linear[0:2500],epochs=50,batch_size=64, \\\n",
    "                    validation_data=(np.concatenate((x_linear_true[2500:3000,0:7],x_linear_true[2500:3000,12:17]), axis=1), y_linear[2500:3000]))\n",
    "score3 = model3.evaluate(x_linear_true[2500:3000,:], y_linear[2500:3000], batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.36987637090682984, 0.86000000238418584, nan]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 2.0072 - acc: 0.7484 - gini_normalized: nan - val_loss: 1.7020 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 1.4856 - acc: 0.8044 - gini_normalized: nan - val_loss: 1.3306 - val_acc: 0.8120 - val_gini_normalized: nan\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 1.1784 - acc: 0.8192 - gini_normalized: nan - val_loss: 1.1502 - val_acc: 0.8060 - val_gini_normalized: nan\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.9969 - acc: 0.8332 - gini_normalized: nan - val_loss: 0.9420 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 0s 88us/step - loss: 0.8723 - acc: 0.8336 - gini_normalized: nan - val_loss: 0.8743 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.8102 - acc: 0.8368 - gini_normalized: nan - val_loss: 0.7649 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.7527 - acc: 0.8416 - gini_normalized: nan - val_loss: 0.7353 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.7195 - acc: 0.8404 - gini_normalized: nan - val_loss: 0.7399 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.6857 - acc: 0.8420 - gini_normalized: nan - val_loss: 0.7029 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.6664 - acc: 0.8488 - gini_normalized: nan - val_loss: 0.6545 - val_acc: 0.8260 - val_gini_normalized: nan\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.6410 - acc: 0.8504 - gini_normalized: nan - val_loss: 0.6560 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 0s 84us/step - loss: 0.6067 - acc: 0.8452 - gini_normalized: nan - val_loss: 0.6414 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.6015 - acc: 0.8456 - gini_normalized: nan - val_loss: 0.6195 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.5947 - acc: 0.8516 - gini_normalized: nan - val_loss: 0.6046 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.5774 - acc: 0.8520 - gini_normalized: nan - val_loss: 0.6074 - val_acc: 0.8260 - val_gini_normalized: nan\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.5535 - acc: 0.8504 - gini_normalized: nan - val_loss: 0.5510 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.5497 - acc: 0.8576 - gini_normalized: nan - val_loss: 0.5512 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.5442 - acc: 0.8516 - gini_normalized: nan - val_loss: 0.5569 - val_acc: 0.8180 - val_gini_normalized: nan\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.5247 - acc: 0.8532 - gini_normalized: nan - val_loss: 0.5723 - val_acc: 0.8180 - val_gini_normalized: nan\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.5297 - acc: 0.8552 - gini_normalized: nan - val_loss: 0.5311 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.5224 - acc: 0.8516 - gini_normalized: nan - val_loss: 0.5489 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.5035 - acc: 0.8544 - gini_normalized: nan - val_loss: 0.5568 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.5053 - acc: 0.8512 - gini_normalized: nan - val_loss: 0.5228 - val_acc: 0.8260 - val_gini_normalized: nan\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.5076 - acc: 0.8444 - gini_normalized: nan - val_loss: 0.4960 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4853 - acc: 0.8544 - gini_normalized: nan - val_loss: 0.5074 - val_acc: 0.8220 - val_gini_normalized: nan\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.4795 - acc: 0.8544 - gini_normalized: nan - val_loss: 0.5045 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 0s 85us/step - loss: 0.4774 - acc: 0.8580 - gini_normalized: nan - val_loss: 0.5141 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4905 - acc: 0.8552 - gini_normalized: nan - val_loss: 0.5205 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4784 - acc: 0.8596 - gini_normalized: nan - val_loss: 0.4779 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 30/50\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 0.4900 - acc: 0.8496 - gini_normalized: n - 0s 62us/step - loss: 0.4832 - acc: 0.8488 - gini_normalized: nan - val_loss: 0.5127 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 31/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4749 - acc: 0.8548 - gini_normalized: nan - val_loss: 0.5225 - val_acc: 0.8260 - val_gini_normalized: nan\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - 0s 86us/step - loss: 0.4628 - acc: 0.8564 - gini_normalized: nan - val_loss: 0.5286 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.4589 - acc: 0.8588 - gini_normalized: nan - val_loss: 0.4709 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.4500 - acc: 0.8560 - gini_normalized: nan - val_loss: 0.4904 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 35/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4465 - acc: 0.8608 - gini_normalized: nan - val_loss: 0.5106 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 36/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4384 - acc: 0.8592 - gini_normalized: nan - val_loss: 0.4691 - val_acc: 0.8520 - val_gini_normalized: nan\n",
      "Epoch 37/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4423 - acc: 0.8592 - gini_normalized: nan - val_loss: 0.4709 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 38/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4450 - acc: 0.8556 - gini_normalized: nan - val_loss: 0.4948 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 39/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4417 - acc: 0.8568 - gini_normalized: nan - val_loss: 0.4649 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 40/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4380 - acc: 0.8556 - gini_normalized: nan - val_loss: 0.4406 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 41/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4386 - acc: 0.8624 - gini_normalized: nan - val_loss: 0.4809 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 42/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4357 - acc: 0.8520 - gini_normalized: nan - val_loss: 0.4686 - val_acc: 0.8120 - val_gini_normalized: nan\n",
      "Epoch 43/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.4389 - acc: 0.8612 - gini_normalized: nan - val_loss: 0.4675 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4413 - acc: 0.8532 - gini_normalized: nan - val_loss: 0.4467 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 45/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4254 - acc: 0.8532 - gini_normalized: nan - val_loss: 0.4433 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 46/50\n",
      "2500/2500 [==============================] - 0s 53us/step - loss: 0.4217 - acc: 0.8592 - gini_normalized: nan - val_loss: 0.4305 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 47/50\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.4361 - acc: 0.8584 - gini_normalized: nan - val_loss: 0.4536 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 48/50\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.4174 - acc: 0.8624 - gini_normalized: nan - val_loss: 0.5426 - val_acc: 0.8260 - val_gini_normalized: nan\n",
      "Epoch 49/50\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.4288 - acc: 0.8584 - gini_normalized: nan - val_loss: 0.4507 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 50/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4131 - acc: 0.8544 - gini_normalized: nan - val_loss: 0.4603 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "500/500 [==============================] - 0s 52us/step\n"
     ]
    }
   ],
   "source": [
    "## with interaction and useless features & original useless predictors\n",
    "model4 = Sequential()\n",
    "model4.add(Dense(100, input_dim=np.shape(x_linear_extra)[1], kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model4.add(Dense(10, kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model4.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model4.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',gini_normalized])\n",
    "\n",
    "trace4 = model4.fit(x_linear_extra[0:2500,:], y_linear[0:2500],epochs=50,batch_size=64, \\\n",
    "                    validation_data=(x_linear_extra[2500:3000,:], y_linear[2500:3000]))\n",
    "score4 = model4.evaluate(x_linear_extra[2500:3000,:], y_linear[2500:3000], batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.46030194759368898, 0.82999999952316283, nan]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Irina\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 8 iterations, alpha=2.171e-01, previous alpha=1.991e-01, with an active set of 9 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEXCAYAAAC+mHPKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFwwzMyvEBcPMzAr5HwLDhlZILSBuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21eb4fb8080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|coef| / max|coef| 0.669633684936\n",
      "Nonzero features: 5\n",
      "Nonzero columns: \n",
      "[25 26 27 28 31]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.707692</td>\n",
       "      <td>0.361229</td>\n",
       "      <td>5.692984</td>\n",
       "      <td>1.335716</td>\n",
       "      <td>-0.525556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.962434</td>\n",
       "      <td>2.631511</td>\n",
       "      <td>6.007690</td>\n",
       "      <td>0.958707</td>\n",
       "      <td>0.696791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.442242</td>\n",
       "      <td>0.216815</td>\n",
       "      <td>1.691355</td>\n",
       "      <td>2.163867</td>\n",
       "      <td>0.533716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.235778</td>\n",
       "      <td>0.348115</td>\n",
       "      <td>2.392982</td>\n",
       "      <td>0.678406</td>\n",
       "      <td>-1.112818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.180373</td>\n",
       "      <td>1.522978</td>\n",
       "      <td>1.192875</td>\n",
       "      <td>0.193737</td>\n",
       "      <td>0.394207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         25        26        27        28        31\n",
       "0  1.707692  0.361229  5.692984  1.335716 -0.525556\n",
       "1  1.962434  2.631511  6.007690  0.958707  0.696791\n",
       "2  0.442242  0.216815  1.691355  2.163867  0.533716\n",
       "3  3.235778  0.348115  2.392982  0.678406 -1.112818\n",
       "4  1.180373  1.522978  1.192875  0.193737  0.394207"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature selection\n",
    "from sklearn import linear_model\n",
    "alphas, _, coefs = linear_model.lars_path(x_linear_extra[0:2500,:], y_linear[0:2500], method='lasso', verbose=True)\n",
    "\n",
    "# Plot results\n",
    "xx = np.sum(np.abs(coefs.T), axis=1)\n",
    "xx /= xx[-1]\n",
    "\n",
    "plt.plot(xx, coefs.T)\n",
    "ymin, ymax = plt.ylim()\n",
    "#plt.vlines(xx, ymin, ymax, linestyle='dashed')\n",
    "plt.xlabel('|coef| / max|coef|')\n",
    "plt.ylabel('Coefficients')\n",
    "plt.title('LASSO Path')\n",
    "plt.axis('tight')\n",
    "plt.show()\n",
    "\n",
    "# Top 5 variables\n",
    "i = 5\n",
    "print('|coef| / max|coef|',xx[i])\n",
    "print('Nonzero features:',sum(abs(coefs.T[i])>0))\n",
    "print(\"Nonzero columns: \")\n",
    "print(pd.DataFrame(x_linear_extra[0:2500,:]).iloc[:,abs(coefs.T[i])>0].columns.values)\n",
    "pd.DataFrame(x_linear_extra[0:2500,:]).iloc[:,abs(coefs.T[i])>0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XucndO9x/HPV0QSSQgS6ZAQFK3GtalqqQZVRIrqjR6q\nPVrVu5ajeqWnx6GHKqcXGo26tUHd2qYcUuKS0uikjZCLNojmgqCCuIX4nT/Wmtgm+/LMzN57JpPv\n+/XaLzPP86xn/2ZHVp75rbV+SxGBmZmt+dbp7gDMzKw+3KGbmfUS7tDNzHoJd+hmZr2EO3Qzs17C\nHbqZWS/hDt16LUkXSPpOd8dh1izyPHRrT9ICYDiwsuTwdhGxpAv3HAtcHhEjuhbdmknSxcCiiPh2\nd8divZef0K2SD0TEoJJXpzvzepC0bne+f1dI6tPdMdjawR26dYikPSTdJWmZpHvzk3fbuU9Jmivp\nOUkPSfpsPj4QuBHYTNLy/NpM0sWS/quk/VhJi0q+XyDp65JmAc9LWje3u0bSE5IelvTlKrGuun/b\nvSWdLGmppEclHSZpnKS/S/qXpG+WtD1N0tWSrsw/z18l7Vxy/q2Sbsufw2xJh7R73/Ml3SDpeeBY\n4N+Ak/PP/vt83SmSHsz3nyPpgyX3+KSkaZLOlvR0/lkPKjm/saRfSlqSz19fcm68pJk5trsk7VRy\n7uuSFuf3fEDSfgX+2G1NERF++fWGF7AAeF+Z45sDTwHjSA8D++fvh+XzBwPbAALeC7wA7JbPjSWl\nHErvdzHwXyXfv+GaHMdMYCQwIL/nDOC7wHrA1sBDwAEVfo5V98/3fjW37Qt8BngC+DUwGHgb8CKw\nVb7+NOAV4MP5+pOAh/PXfYH5wDdzHPsCzwHbl7zvM8CeOeb+7X/WfN1HgM3yNR8Dngda8rlP5vf/\nDNAH+BywhNfTpH8ArgQ2yvG8Nx/fFVgKvDO3OyZ/jv2A7YGFwGb52lHANt39/5tf9Xv5Cd0quT4/\n4S0refo7CrghIm6IiNciYgrQSurgiYg/RMSDkdwO3Ay8p4tx/G9ELIyIF4F3kP7x+M+IWBERDwEX\nAkcUvNcrwOkR8QpwBTAUOC8inouI2cAcYOeS62dExNX5+nNIHfMe+TUIODPHcSswGTiypO1vI+JP\n+XN6qVwwEfGbiFiSr7kS+Aewe8klj0TEhRGxErgEaAGGS2oBDgKOj4inI+KV/HkDHAf8PCKmR8TK\niLgEeDnHvJLUse8gqW9ELIiIBwt+drYGcIdulRwWEUPy67B8bEvgIyUd/TJgL1JHg6SDJP05py+W\nkTr6oV2MY2HJ11uS0jal7/9N0gBuEU/lzhHS0zjA4yXnXyR11Ku9d0S8BiwiPVFvBizMx9o8QvoN\nplzcZUn6RElqZBkwmjd+Xo+VvP8L+ctBpN9Y/hURT5e57ZbAie0+o5Gkp/L5wAmk3z6WSrpC0ma1\n4rQ1hzt064iFwGUlHf2QiBgYEWdK6gdcA5wNDI+IIcANpPQLQLnpVM8D65d8/6Yy15S2Wwg83O79\nB0fEuC7/ZOWNbPtC0jrACFLaYwkwMh9rswWwuELcq30vaUvSbxdfBDbJn9f9vP55VbMQ2FjSkArn\nTm/3Ga0fEZMAIuLXEbEXqeMP4AcF3s/WEO7QrSMuBz4g6QBJfST1z4ONI0i55H6kvPSreQDv/SVt\nHwc2kbRhybGZwLg8wPcm0tNjNfcAz+WBvQE5htGS3lG3n/CN3i7pcKUZNieQUhd/BqaTxgdOltQ3\nDwx/gJTGqeRxUs6/zUBSh/oEpAFl0hN6TRHxKGmQ+WeSNsox7J1PXwgcL+mdSgZKOljSYEnbS9o3\n/+P7Euk3ktcqvI2tgdyhW2ERsRA4lJTmeIL0NPgfwDoR8RzwZeAq4Gng48DvStrOAyYBD+VUwGbA\nZcC9pEG7m0mDfNXefyUwHtiFNED5JPALYMNq7brgt6TByqeBo4HDc756BakDPyjH8DPgE/lnrGQi\nKXe9TNL1ETEH+CFwN6mz3xH4UwdiO5o0JjCPNAh6AkBEtJIGUn+S455PGmCF9A/umTnmx4BNgW90\n4D2th/PCIrMyJJ0GvDkijuruWMyK8hO6mVkv4Q7dzKyXcMrFzKyX8BO6mVkv0dSCR0OHDo1Ro0Y1\n8y3NzNZ4M2bMeDIihtW6rqkd+qhRo2htbW3mW5qZrfEkPVLkuk6nXPIihZklr2cl1VoYYmZmDdLp\nJ/SIeIC0wKOt3vNi4Lpqbe5b/AyjTvlDZ9/SzGyNtODMg5vyPvUaFN0PeDAiCv1aYGZm9VevDv0I\n0rLu1Ug6TlKrpNaVLzxTp7czM7P2anbokkZKmpp3VJkt6Sv5+M6S7pZ0P2k3lhvLtY+ICRExJiLG\n9Fm/USU3zMysSA79VeDEiPirpMHADElTSEWRTgKGAKeTCgBV3WF9x803pLVJuSQzs7VNzQ49l+p8\nNH/9nKS5pEL+2wF3kFItvyTtm1i1Q/egqJmtLZo1EFqqQzl0SaNIexZOB2YDHyXtK9mPks0A2rVx\nDt3MrAkKd+iSBpF2pDkhIp4F/p30VL6AtEntinLtnEM3M2uOQvPQJfUldea/iohr8+HnSR35ANLm\nwctr3cc5dDOzxqnZoUsSabeVuRFxTsmpDYETSduIXQ7sK2mHvBNLWc6hm619uiOXvLYqknLZk7Td\n1b4ly/zHkRYTXUHaAuufpLz65pVvY2ZmjVRklss0Ku9Efh6sGiy9g9Spv4Gk44DjAPpsULNYmJmZ\ndVJXFhZdmZ/WZwEPACvzYOkbeFDUzKw5Or2wKCI+lgdLJwP/Am6tdSMPipqZNU6nFxbl/04E5gIf\nAj5T614eFLU1hQfybE3UlYVFbYOlHwA2AX6TB0vbt/HCIjOzJihcD73MwqJp6bDOB+ZHxA/LtYuI\nCcAEgH4t23pHajOzBikyD70/cCewPfACsDNwraSdgQuAMcBtki4sNyhayjl0M7PGKfKE/jLwD+BP\nwH8A0yTdCPwYuIq05H9SPufiXLZGcs7ceoOiC4uOBPYFWoEdgXeRqi2+jdSZTyENjJqZWTep2aHn\nhUXrAq8B2wA/jogfkaotXh8RFwAfwdUWzcy6VZGFRf2Bu0mrRRcCH5U0mlTD5TJJLwCfB14p194L\ni8zMmkMR1See5OJcAyNieV5I9DBwLfDttkFQSd8HPhsRm1a715gxY6K1tbU+kZuZrSUkzYiIMbWu\nKzIoOpTXn74Hk7acWwD0B56VtA5wMCkFU5UHRa2rPHhpVlmRQdEWYKqkF4EngL/lMrpHSnqKNAtm\nJGn3IjMz6yZFBkVnRcSuETGAtCL0VUmjI+K8iNgkIvoC5wBfLNfeg6JmZs1RJIfen1Qatx8pRbMU\n+ANwEXAlMAp4DNgkInaodi/n0M3MOq6eOfTBwAcjYnGutriYVGHxB8AtEXGmpN8CNYudO4e+dnP+\n26yxinToLcAlkvoAfUh7h04DTgMWS/o46Qm9b6OCNDOz2oqUz50laQwwA9ga+GlETJe0MiLeAqum\nNj5drr13LDIza44iC4suItVDXxcYAewu6WvAYEmvSRoTKRFfNhnvhUVmZs1RJOVyMfAT4NKIWCZp\nKvAm4BFSqgVJLaTB0qpcbdHMrHGKdOhzSXl0JA0A9icNiIrXC3IdA/y21o08KNqzedDSbM1WdFB0\nEqkw11+AqyJisqS7gU+TygD8HS8sMjPrVkUHRQ8GJkfE6JLjT0m6FzgpIipOLvegqJlZcxRZWDSS\ntJHFrsCDwISIOC8X5PoqaV76I8AnI2JJtXt5YZGZWccVXVhUpENvAXYj5c3fRZq+eBiwCPgdcBLw\nbmCHiDi+2r36tWwbLcecW+gHsOZy/tys56rnStFzgLGkqotzSQW6PkrKnw8jlQF4Brils8GamVnX\nFSnOdWREtOQiXHuRCnSdExEjgLNJe4quAL5brr2Lc5mZNUeR8rkASBoEXAOc0LaxBXAn8AKvz4RZ\njRcWmZk1R5GUC3mnomuAX0XEtflYH+CnpHnpAu6XtENEzKl0Hy8sMjNrnJodeq7TMhGYmze2aHM4\nMD8iHpL0JWA+cChQsUP3wqKex4OhZr1HkSf0PYGjgfskzczHvgmcCGwnaRZp2uKFwHYNidLMzGoq\nsrBoGiml8gaS1gcOjIhP5++PLtfeC4vMzJqj5jz0VRemnHkrsDgixkv6BXAUMC9fMhN4ICLOqHQP\nLywyM+u4es5Db/MV0jz0DfL3S4DngQ+SVov+BTir2g2cQ+85nDs3630KTVuUNAI4GPhFyeHXgOuA\nm0gd/VURMbvuEZqZWSFF56GfC5xM6sRL7Q+8BNwO/KxcQy8sMjNrjiI7Fo0HlkbEjHanzidtSbcL\naUejH5Zr74VFZmbNUXTa4iGSxgH9gQ0kXR4RR+Xt6caT9hN9pdaNvLDIzKxxCs9yAZA0llT/fHyu\nwrgtsJxUoOv2iDiiWntXW+x+Hgw1W/M0YpZLe/9DSresCwwk1UY3M7Nu0qEOPSJuA27LXx8NIGkU\naTejR8u18cIiM7PmKDIoOlLSVElzJM2W9JV8/DRJi4EbgG1yjn01HhQ1M2uOIk/orwInRsRfJQ0G\nZkiaks/9CLia9IR+Q6OCtM5zztxs7VGklsujpGmJRMRzkuYCmzc6MDMz65jCG1zAqnz5rsD0fOh7\nwD+AHSQtlnRsmTZeWGRm1gRd2bHofFJdl37AGcBNETGxfTvn0M3MmqPIBhcjgcuAMaQ55yMBIuLx\nvLHFF0j/MGxU615eWGRm1jhFB0WXkwpzfYfXB0XfStqhaGfg88DetW7kaouN5QFQs7VbkQ59G1Kl\nxfuAscBwUsncz5CKdf0FWAB8tiERmplZITVz6BExLSIUETsBhwHPAD8GlpFSMS8CGwIjyrX3oKiZ\nWXMUWVh0kaSlkuaQB0WBrUj7h34BWAqcBlyVN5R+Aw+Kmpk1R5GUy8XABcAtwKkRca2kv5BSMKeQ\nOvd9SemXocATjQl17eb8uJnVUqRDv5O0GvTliDgnH9sO+DqwD3AhMBVYD3iyEUGamVltReuhHw68\nLGlmPraY1HnvBdwDbArsH2Vq8bo4l5lZcxQaFCWlVeZHxC4RsQupgz+ONHXxAmBZRNxaob1z6GZm\nTVBkYVF/4HpSRcXZwNURcaqkC0mDoacCc4q8mRcWmZk1TpGUy8vAx4GrSHVcpkn6M3A/8CFSffRr\ni7yZFxZ1jgdEzayIIh36r0kLioaSFhC9CuxP2ksUYAXwuwbEZmZmHVAkh34kadHQbNICoisi4msR\nsV1EbAc8VK29FxaZmTVHoYVFpHro65I69t0lvVvSFEn/AHYCBldq70FRM7PmUJmZhm+8QNqbVJzr\n0ogYLem7pPnnN0XEmZIeAu6MiGNqvdmYMWOitbW1HnGbma01JM2IiDG1riuSQ58LtOSbDiDlz7ci\nDZQCPAa8t0hQHhQtxoOgZtYZRTa4aAEmAW8mVVacAgwC9pC0CHg7sIWkm8o1dg7dzKw5igyKziKV\nz50fEaMj4j/z8esiYkRE9AOeiYgDKrR3Dt3MrAmKLCy6CDiE9FTeZh1J95OmMG4CDCjyZl5YZGbW\nOEWrLV6TX21+DjyVB0XvAB4p8mbOoVfn3LmZdUWRDv1zwH5Av5wzPxU4k1T//FjSHqN7NS5EMzMr\nomaHHhFHShoFTI6I0SWn9stTGs+JiIpzEV1t0cysOYouLGolzXJpO7ZLrudyLTBc0u6V2ntQ1Mys\nOYouLBoMXBMR/fOxm4HzgIuAk4BjI2JsrTfzwiIzs46r28KiiLhDUvsceZA2vphHmumypEhQHhSt\nzAOiZtZVRaYtTmL1QdETSIuMVgBnA++u0t45dDOzJihabXF3YHZeSDSRNPPlmIjYGPgqMLFKe+fQ\nzcyaoFM7FgHHABflgdH+wI6Sdo+Ie6rdywuLzMwap8igqEh7h67asYi0KfSTwHdJaZcLgMW1Bkb7\ntWwbLcec2/WoeyHn0M2sknpWWyy3Y9HpwFnA+cDjwC+B0eWbm5lZM3R2x6IJwB65/WbAF4BvlGvv\naotmZs1RZGFRf+BuQMBC4KOSRgOX5/ZPA4uBS8q196ComVlzFEm5vAzsGxHLJfUFHiZNQ3wLsGFE\nvCrpB6SpjFV5UNTMrHGKdOhDgVfy14OBIaRc+j9JRbluA54nbVNXlRcWJR4ANbNGKNKhtwCXSHoL\nsB5wV0ScI+ke4DxJ6wJbAD8s19gLi8zMmqPQjkURsWtEDCBtZvGqpNERMS0i3k6azngbaeZLufbO\noZuZNUGRhUUjgUuB4aQaLo8AB0p6K3AuaZbLXlFrQjvOoZuZNVKRlMsGwKm5SNcwUof+e1Iu/UXg\nLtLAaU3OoTt/bmaNU6RD70PKlfchpWgeAeaTFhX1A3YGfiVpakQc37BIzcysqiLlc2eRlvyTdy66\nA5geEW/Ox24DTqq0a5EHRc3MmqPIwqKRkqZKmgvMBaZExLOSzpI0DxgDnCVpSLn2HhQ1M2uOIsW5\nWkgbQX+fNJvlU8BhpHIAtwJ/JKVhHouIr1e7l3csMjPruHoW53oM+AEwNyLOkLQHsHlE3JzfCOA+\nclqmGg+KelDUzBqnSIe+J3A0cJ+kOaTNoi+V9EHgx8Aw4F3AAw2L0szMaioyKDqNVBZ9EHA7cERE\nXJtPXyfpW6Q8+uHl2ntQ1MysOWrm0AFyUa7JwNuAmRExXtJZwFGkeeq3AJ+IiGXV7uMcuplZx9Ut\nh553LJpI2mruDlIHDqls7tPATsBJpHroVQdF1/YcuvPnZtZIHcmhLwc2B4ZJGgf8O2lh0RTSxhev\nUqNDNzOzximUQ5d0DXAGqXzuSRFxA3BD2zWSfg9cWa69c+hmZs1RJOUyHlgKzATmkVMukjYmdeK7\nAq8BnyjXPm9XNwHSJtF1idrMzFZTZGHRGaSUy/rAAFJN9EnAEmAr0gKjG4BBXlhkZlZ/RQdFi85y\nGUHaM3QycEpEDJe0kFRtcU/Sk/5tEbF9tfv0a9k2Wo45t0j8vY4HRM2ss4p26DVruWTnAieT6qG3\n2Yz0xD4FuBEY1cEYzcysjgrn0CNihqTBwF/yqeciYmTJdU9XaO9BUTOzJiiSQ/8f4IS2b/N/rwTe\nAYwFPg6cDTzYVlK3EufQzcw6rm459LywaGBELJe0H3A1cBDwIdLc892A3YHLI+JL1e7lHLqZWcfV\nbaVo3it0ecn165By6WeS6qO/SFpFel6nozUzsy4rNCgqqY+kmcA1wAURMR3YC5gUEVsCjwNl67hI\nOk5Sq6TWlS88U6+4zcysnSJL/4mIlcAueVei6yTtBHwTeH+Btl5YZGbWBEVmubQV5eqXr18KHEpa\nVPSQpA3y8YckbRcRj1W6146bb0irc8lmZg1R5Al9MPDBiFicpy0uJi0w+hjwLeBg0uYWB1brzGHt\nrbboAVEza4YiHXoLcImkPkAf0gDpNOBE4MyIeDlvQ/dkw6I0M7Oaag6KRsQs0o5ErwFbApflQdHt\ngPdImk7aJHqrcu09KGpm1hyFarlAmukC/I205H8sqSDXQGAj4FPAacDWUeWGXlhkZtZxdZuHXuIr\nwP2kwdEDSU/lF5I2uphNeoIfCjxR6Qa9PYfuXLmZdacis1yGAcNIg59nAQeQ6qIvB9qW+m9BKqvr\nPLqZWTcpOih6O6mzPh94MiImS1oPuIhU0+W/gWPKpVtcnMvMrDmKrBTdgrQidFtSrvwfABGxIiKO\nIlVfPCoibi3XOCImRMSYiBjTZ/0N6xW3mZm105Vqi/OBz5A2iF4MfDXvNVqRB0XNzDquGdUWDyTl\n0ceTNo6u2VP31mqLHgw1s0ZqRrXFt5A69QHAHyTNjIgDOh+ymZl1RaFpi3kO+gzSrJafRsR0SfOA\ndwH/BFpJK0fLtfWgqJlZExQqn5urLb4deAg4VtJo0oyXrYFLSYOlP6nQ1oOiZmZNUHSTaHh9YdFT\npEJcj5NWje5PGhTdrf7h9XzOn5tZT1GzQ5c0TNIOpIVFl5JWg86T1AL8CDgZWJ+0e5GZmXWTriws\nmgrsSCrS1R/4TrnGzqGbmTVHpxYWSVqf9FS+TUTsRNr04vFyjZ1DNzNrjiJP6HsCh0gaB2xO+kfg\nMrxjkZlZj9KR8rlfA8YBO0bEcEn7sPqORfOq3aM3LSzyYKiZNUvRhUWFZrlIGkHquEtr336OvGNR\n/t6VFs3MulHRaYvnkmaz/I1UjAu8Y5GZWY9SZNriFFKq5ZKSY2cBbwW+ACwBvgdcleu+vIEHRc3M\nmqPIoOjjwHOkJ/IrgA1I9VtuA84k1XM5gAI7FnlQ1MyscYoU5zpK0ihgMvBFUmXF8ZKOB/YB/kya\nzlhzx6LetAWdB0XNrKfpyNL/9i4i1XK5hLTAqOKORc6hm5k1Xkc2iSYibiOlWoiIFZLmAgOBw8t1\n5vm6CcAESNMWuxKsmZlV1qEOvZSkTwKfBl4A7pd0YURUnWTuHLqZWeN0qkOXdCCpdstLpE2iVwD/\nJ2lyRMyv1M45dDOzxikybXEScDewvaRFko4l1T7fENgUuCt/fztweANjNTOzKorMcjmyzOGJkt4K\n/BbYD3gRuIW0c9EbuNqimVlzFHlC7y/pHkn3Spot6Xv51GmksrkLgX8B2wIr27f3wiIzs+YokkN/\nGdg3IpZL6gtMk3RjRHys7QJJPyTl0v9e7UYeFDUza5wiKZcAludv++ZXAEjalLQy9EhS2uXX1e7l\nQVEzs8YpWm2xj6SZpI0spkTE9HzqGuBhYAhwXEQsK9PWC4vMzJqgUIceESsjYhdgBLC7pNH5+HuA\nG4HvRMQtFdo6h25m1gQ1Uy6SRpI2hx5OSrU8AhwoaQlwFTAWuEvSRRHxdLV7OYduZtY4NXcskvQ2\nYJOIuEPSMFKHfiKp/vlQYBvSU/pGEfH1avfqDTsWOXduZs1Wzx2L+gDnSZoFTCV16POBQ0l1XCaR\nCnQd1vlwzcysq4rMcpkF7AqQy+jeAUwHhrdNXcwbWwwv194Li8zMmqNwLRdJGwBzgDkR8WxecDSL\ntLHF0krtXG3RzKw5CnXoeUHRPcA84LF8eCFwQEQ8KunbwO617uNBUTOzxikyy0WkPPn6wOeBr+VT\n1wPHkLah24s0H72q3rCwyIOiZtZTFXlC3xP4EGkgdAIwTNI4UkfeKun7pPIAu5Zr7By6mVlzFJnl\nMgQ4PyK2JW1ocWdE3BART0XEVhHRFzgdOKpcYy8sMjNrjiLz0H9C6sjXAURaXHQVcDZwAani4jrA\nwIjYptq9xowZE62tq1XYNTOzKorOQy/SobcALRHxV0kHAb8hDYBOAE6PiBslnQ98OCKq5lTW9IVF\nzp+bWXco2qEXmYf+KPBo/vZFUuXFzYE3Az+XtAx4BZjW+XDNzKyrChXnKrGAtH/odGCffGwj4E3A\nCeUauNqimVlzFNmxaKSkqZLmAnNJ5XOfBT4HfBU4F9iMVMBrNR4UNTNrjqI59JHA94HbgE+R6rbc\nDYwGfgG8Bdg4IgZXu5cHRc3MOq5uOXTSytAfAHMj4gxJe5By6EuAy4EvAzcBD9a60Zq4sMgDoWa2\npiiSQ98TOBrYV9Ic4CBgA1KFxbeQUi0bkUrqmplZN6nZoUfEtIgQ8G7SLJcjSPXPPwhsFxE7k2bB\n3FuuvQdFzcyao2YOHVYV55oM3BQR50jaEbiFlLIZRNo4+gVgh4h4pNJ9nEM3M+u4uuXQc3GuiaQc\n+jkAEXGfpF1Jc883J81+mUmaynhxpXv15By6c+VmtqbraA59Zn6Ny+fWBQbkrweQBkrNzKwbFFkp\nOo1Uw2U1ks4G/knKrT8ZETeXucbVFs3MmqCjK0VXkfQm0tz0BaQdi94uabWKi15YZGbWHIW3oCvj\nPcB1EXFMHjSdR5r5cnmlBt6xyMyscbrSof8TGCNp/fz9EGrsWtQTB0U9GGpmvUWnUy4RMR24BvgX\n8BxpLvq36hSXmZl1UKc7dICI+G5E9Ac2AZ4Atm1/jRcWmZk1R5HiXBcB44GlETG65PiXgC8AK4E/\nkOqkvxARZ1e6lxcWmZl1XD2Lc10M/ISS8riS9gE+DOwdEUslbQH8ilTEq6KekkN33tzMeqMi89Dv\nkDSq3eHPkWaz3CSpDyl1c1VETK57hGZmVkhnZ7lsR1ruvwJ4CTgpIv5S7kIvLDIza47ODoquC2wM\nHAC8CvxJ0lxJ72p/oRcWmZk1R2ef0BcB1wLnAZOAUcB+pIqLFXlhkZlZ43S2Q78eOBDYGzgdOBV4\nNGpMmfGgqJlZ4xTZJHoSaf/Q7SUtknQscBFpP9Hh+dxLwIWSBjYyWDMzq6zIjkVHRkRLRPSNiBER\nMTEiVpCeytcDxkXEtsDzwCnt23thkZlZc3RlYdGbgDmk/USHAW8FTomIivkMLywyM+u4hi4syvqS\n6qS3bWqxH6mDr6i7c+jOnZtZb1Yk5XIHqQBXez8CPgsMBW4HdgH+u67RmZlZYZ2ahy7pUGBxRFxF\nqrL43og4LCKeLnOtc+hmZk3Q4WmLuf75N4H3F7k+IiYAEwD6tWxbPWFvZmadVrNDz4OihwCD8qFt\nSFMWn5DUdo97Jb09Ih6rdi8vLDIza5yig6LX5BcRcZ+kloh4FkDSU8CUWp05dN+gqAdDzWxtUCSH\n/jngl0C/toVFbZ15yT2cSjEz62ZFyucemcvnTm43D/104BPAYuDkSu1dbdHMrDmKLiw6BBiUt5tD\n0mnAZ0jbzm0KTI2If6v1Zl5YZGbWcfVeWLQqh17iRxFxdt6t6IYiQXVHDt35czNbWxRdWNR+AvnG\nJV8fCsyrZ1BmZtZxRaYtTiIt6+8naRGpKNf7gDdL+j4p7XJglfbOoZuZNUGhaovA7sDstmqLwD7A\nAGAgcBlwUpX23rHIzKwJOrXBRUQ83va1pInAbEmbRsT4au28sMjMrHE61aHnhUWP5m/PAZYWadfI\nQVEPfprZ2q5oDn0sMLQkhz5W0i65/VDS4qNPNi5MMzOrpdDCojKHJwJIuho4Axhcqb0HRc3MmqOz\nm0QjaTyp4uL2pAHSoeWuc7VFM7Pm6FQ99GxPYH1gQ1IlxvUkXV6XqMzMrMM63aFHxDeARcBuwBHA\nrRFxVL28YdbwAAAE40lEQVQCMzOzjul0yiUL4I+klMvL5S5wDt3MrDm6knIB2CsidgHeA4Skvdtf\n4IVFZmbN0aUn9IhYnP+7VNJ1pBWld1S63guLzMwap9NP6JIGShrc9jVpxsv99QrMzMw6pitP6MOB\n60r2Ff11RPxfXaIyM7MOq7nBRV3fTHoOeKBpb9gxQ4EnuzuICnpybNCz43NsnePYOq8R8W0ZETVn\nlXR1lktHPVBk143uIKnVsXVOT47PsXWOY+u87oyvq7NczMysh3CHbmbWSzS7Q5/Q5PfrCMfWeT05\nPsfWOY6t87otvqYOipqZWeM45WJm1ku4Qzcz6yXq0qFLOlDSA5LmSzqlzHlJ+t98fpak3Yq27QHx\nXSRpqaSGrILtbGySRkqaKmmOpNmSvtKDYusv6R5J9+bYvtdTYis530fS3yRN7kmxSVog6T5JMyW1\n1ju2OsQ3RNLVkuZJmivpXT0hNknb58+s7fWspBN6Qmz53Ffz34X7JU2S1L+esa0SEV16AX2AB4Gt\ngfWAe4Ed2l0zDrgRELAHML1o2+6ML5/bm1Qi+P56xlWHz64F2C1/PRj4ez0/uy7GJmBQ/rovMB3Y\noyfEVnL+a8Cvgck95c80n1sADK33/2t1jO8S4NP56/WAIT0ltnb3eYy0GKfbYwM2Bx4GBuTvrwI+\n2Yg/33o8oe8OzI+IhyJiBXAFcGi7aw4FLo3kz8AQSS0F23ZnfETEHcC/6hxTl2OLiEcj4q85xueA\nuaT/cXpCbBERy/M1ffOrnqPvXfozlTQCOBj4RR1jqktsTdDp+CRtSHrAmQgQESsiYllPiK3dNfsB\nD0bEIz0otnWBAZLWJW0MtKSOsa1Sjw59c2BhyfeLWL1jqXRNkbbdGV+j1SU2SaOAXUlPwj0itpzS\nmAksBaZERI+JDTgXOBl4rY4x1Su2AP4oaYbSXgI9Kb6tgCeAX+Z01S+UCvP1hNhKHQFMqmNcXYot\nUlXas4F/Ao8Cz0TEzXWOD/Cg6BpP0iDgGuCEiHi2u+NpExErI9XKHwHsLml0d8cEq/bCXRoRM7o7\nlgra9hg4CPiCyuwx0I3WJaUfz4+IXYHngYaMe3WWpPWAQ4DfdHcsbSRtRHp63wrYDBgoqSG7u9Wj\nQ18MjCz5fkQ+VuSaIm27M75G61JskvqSOvNfRcS1PSm2NvlX8qnAgT0ktj2BQyQtIP3avK/quxdu\nlz63KNljAGjbY6CeuhLfImBRyW9bV5M6+J4QW5uDgL9GxON1jKursb0PeDginoiIV4BrgXfXOb6k\nq0l40r/aD5H+9WkbLHhbu2sO5o2DBfcUbdud8ZWcH0VjBkW78tkJuBQ4t95x1SG2YeTBMtL2hHcC\n43tCbO2uGUv9B0W78rkNBAaXfH0XcGBPiS+fuxPYPn99GnBWT4ktn78C+FQP+/vwTmA2KXcu0sDy\nl+odY0R0vUPPAY8jzbJ4EPhWPnY8cHz+WsBP8/n7gDHV2jbgD6Mr8U0i5b1eIT2hHNsTYgP2IuVb\nZwEz82tcD4ltJ+BvObb7ge/2pD/TknuMpc4dehc/t61JHcW9uQPoiX8fdgFa85/t9cBGPSi2gcBT\nwIY98HP7HjAv/324DOjXiBi99N/MrJfwoKiZWS/hDt3MrJdwh25m1ku4Qzcz6yXcoZuZ9RLu0M3M\negl36GZmvcT/AzYhlnQO4es1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21eb4e690f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) 7                              0.081353\n",
      " 2) 29                             0.080754\n",
      " 3) 2                              0.064868\n",
      " 4) 27                             0.043589\n",
      " 5) 39                             0.042504\n",
      " 6) 33                             0.036890\n",
      " 7) 30                             0.032569\n",
      " 8) 11                             0.026663\n",
      " 9) 23                             0.026372\n",
      "10) 0                              0.025795\n",
      "11) 45                             0.025165\n",
      "12) 1                              0.024811\n",
      "13) 25                             0.023745\n",
      "14) 26                             0.022431\n",
      "15) 19                             0.020065\n",
      "16) 31                             0.019842\n",
      "17) 10                             0.018910\n",
      "18) 17                             0.018439\n",
      "19) 18                             0.018234\n",
      "20) 38                             0.018050\n",
      "21) 32                             0.016921\n",
      "22) 21                             0.016702\n",
      "23) 22                             0.016683\n",
      "24) 42                             0.016291\n",
      "25) 40                             0.016088\n",
      "26) 34                             0.016061\n",
      "27) 36                             0.015802\n",
      "28) 41                             0.014349\n",
      "29) 35                             0.013676\n",
      "30) 44                             0.013429\n",
      "31) 46                             0.013151\n",
      "32) 12                             0.013114\n",
      "33) 9                              0.013109\n",
      "34) 37                             0.012908\n",
      "35) 20                             0.012574\n",
      "36) 43                             0.012461\n",
      "37) 28                             0.012329\n",
      "38) 24                             0.011387\n",
      "39) 8                              0.010007\n",
      "40) 3                              0.009448\n",
      "41) 16                             0.008648\n",
      "42) 6                              0.008560\n",
      "43) 14                             0.008269\n",
      "44) 13                             0.007670\n",
      "45) 15                             0.007409\n",
      "46) 4                              0.006006\n",
      "47) 5                              0.005903\n"
     ]
    }
   ],
   "source": [
    "### Random forest feature importance\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "\n",
    "forest.fit(x_linear_extra[0:2500,:], y_linear[0:2500])\n",
    "\n",
    "### Plot feature importance\n",
    "# https://stackoverflow.com/questions/44511636/matplotlib-plot-feature-importance-with-feature-names\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.barh(range(x_linear_extra[0:2500,:].shape[1]), importances[indices])#,\n",
    "       #color=\"r\")#, xerr=std[indices], align=\"center\")\n",
    "# If you want to define your own labels,\n",
    "# change indices to a list of labels on the following line.\n",
    "plt.yticks(range(x_linear_extra[0:2500,:].shape[1]), indices)\n",
    "plt.ylim([-1, x_linear_extra[0:2500,:].shape[1]])\n",
    "plt.show()\n",
    "\n",
    "# Selected features\n",
    "feat_labels = pd.DataFrame(x_linear_extra[0:2500,:]).columns\n",
    "indices = np.argsort(forest.feature_importances_)[::-1]\n",
    "\n",
    "for f in range(pd.DataFrame(x_linear_extra[0:2500,:]).shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30,feat_labels[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 7, 11, 23, 25, 26, 27, 28, 29, 30, 31, 33, 39, 45]\n"
     ]
    }
   ],
   "source": [
    "# Selecting features based on how precipitously variable coefficients fall to zero in lasso/at jump in variable importance:\n",
    "selected_features = sorted(list(set(pd.DataFrame(x_linear_extra[0:2500,:]).iloc[:,abs(coefs.T[i])>0].columns.values.tolist()+ \\\n",
    "                                    indices[0:14].tolist())))\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.3558 - acc: 0.7744 - gini_normalized: nan - val_loss: 1.1586 - val_acc: 0.8200 - val_gini_normalized: nan\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 1.0658 - acc: 0.8308 - gini_normalized: nan - val_loss: 0.9883 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.9137 - acc: 0.8336 - gini_normalized: nan - val_loss: 0.8676 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.7933 - acc: 0.8404 - gini_normalized: nan - val_loss: 0.7733 - val_acc: 0.8260 - val_gini_normalized: nan\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.7156 - acc: 0.8368 - gini_normalized: nan - val_loss: 0.6671 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.6648 - acc: 0.8388 - gini_normalized: nan - val_loss: 0.6414 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.6477 - acc: 0.8404 - gini_normalized: nan - val_loss: 0.6384 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.5993 - acc: 0.8432 - gini_normalized: nan - val_loss: 0.6208 - val_acc: 0.8220 - val_gini_normalized: nan\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.5990 - acc: 0.8456 - gini_normalized: nan - val_loss: 0.5957 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.5812 - acc: 0.8496 - gini_normalized: nan - val_loss: 0.5847 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 0s 84us/step - loss: 0.5617 - acc: 0.8440 - gini_normalized: nan - val_loss: 0.5900 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.5567 - acc: 0.8404 - gini_normalized: nan - val_loss: 0.5657 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.5402 - acc: 0.8488 - gini_normalized: nan - val_loss: 0.5440 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.5304 - acc: 0.8400 - gini_normalized: nan - val_loss: 0.5336 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.5131 - acc: 0.8452 - gini_normalized: nan - val_loss: 0.5823 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.5152 - acc: 0.8400 - gini_normalized: nan - val_loss: 0.5396 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.5017 - acc: 0.8436 - gini_normalized: nan - val_loss: 0.5106 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4984 - acc: 0.8396 - gini_normalized: nan - val_loss: 0.5055 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4909 - acc: 0.8456 - gini_normalized: nan - val_loss: 0.4867 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4993 - acc: 0.8464 - gini_normalized: nan - val_loss: 0.5146 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4876 - acc: 0.8420 - gini_normalized: nan - val_loss: 0.4769 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4772 - acc: 0.8424 - gini_normalized: nan - val_loss: 0.4527 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4897 - acc: 0.8404 - gini_normalized: nan - val_loss: 0.4856 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.4612 - acc: 0.8456 - gini_normalized: nan - val_loss: 0.4513 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.4898 - acc: 0.8448 - gini_normalized: nan - val_loss: 0.5058 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4788 - acc: 0.8412 - gini_normalized: nan - val_loss: 0.5303 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.4824 - acc: 0.8420 - gini_normalized: nan - val_loss: 0.4839 - val_acc: 0.8260 - val_gini_normalized: nan\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4492 - acc: 0.8460 - gini_normalized: nan - val_loss: 0.5078 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4489 - acc: 0.8492 - gini_normalized: nan - val_loss: 0.5263 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 30/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.4567 - acc: 0.8420 - gini_normalized: nan - val_loss: 0.4579 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 31/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4503 - acc: 0.8428 - gini_normalized: nan - val_loss: 0.4216 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4465 - acc: 0.8408 - gini_normalized: nan - val_loss: 0.4337 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4522 - acc: 0.8400 - gini_normalized: nan - val_loss: 0.4770 - val_acc: 0.8260 - val_gini_normalized: nan\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4438 - acc: 0.8436 - gini_normalized: nan - val_loss: 0.4974 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 35/50\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4566 - acc: 0.8412 - gini_normalized: nan - val_loss: 0.4820 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 36/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4513 - acc: 0.8432 - gini_normalized: nan - val_loss: 0.4578 - val_acc: 0.8260 - val_gini_normalized: nan\n",
      "Epoch 37/50\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4558 - acc: 0.8412 - gini_normalized: nan - val_loss: 0.4551 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 38/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4369 - acc: 0.8384 - gini_normalized: nan - val_loss: 0.5104 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 39/50\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4481 - acc: 0.8480 - gini_normalized: nan - val_loss: 0.4528 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 40/50\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4412 - acc: 0.8460 - gini_normalized: nan - val_loss: 0.4720 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 41/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4265 - acc: 0.8452 - gini_normalized: nan - val_loss: 0.4670 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 42/50\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.4234 - acc: 0.8440 - gini_normalized: nan - val_loss: 0.4709 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 43/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4364 - acc: 0.8396 - gini_normalized: nan - val_loss: 0.4548 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 44/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4294 - acc: 0.8480 - gini_normalized: nan - val_loss: 0.4563 - val_acc: 0.8440 - val_gini_normalized: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4239 - acc: 0.8440 - gini_normalized: nan - val_loss: 0.4200 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 46/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.4247 - acc: 0.8492 - gini_normalized: nan - val_loss: 0.4205 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 47/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4417 - acc: 0.8424 - gini_normalized: nan - val_loss: 0.4216 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 48/50\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.4269 - acc: 0.8440 - gini_normalized: nan - val_loss: 0.4412 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 49/50\n",
      "2500/2500 [==============================] - 0s 86us/step - loss: 0.4274 - acc: 0.8432 - gini_normalized: nan - val_loss: 0.4856 - val_acc: 0.8220 - val_gini_normalized: nan\n",
      "Epoch 50/50\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.4346 - acc: 0.8420 - gini_normalized: nan - val_loss: 0.4069 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "500/500 [==============================] - 0s 40us/step\n"
     ]
    }
   ],
   "source": [
    "## Feature selection then NN\n",
    "model5 = Sequential()\n",
    "model5.add(Dense(100, input_dim=len(selected_features), kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model5.add(Dense(10, kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model5.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model5.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',gini_normalized])\n",
    "\n",
    "trace5 = model5.fit(x_linear_extra[0:2500,selected_features], y_linear[0:2500],epochs=50,batch_size=64, \\\n",
    "                    validation_data=(x_linear_extra[2500:3000,selected_features], y_linear[2500:3000]))\n",
    "score5 = model5.evaluate(x_linear_extra[2500:3000,selected_features], y_linear[2500:3000], batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.40688827180862425, 0.84999999761581424, nan]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEOCAYAAACQMUyOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21ed607af60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Validation accuracy')\n",
    "fig = plt.figure(figsize=(10*.55,7*.55))\n",
    "plt.title('Hidden layers: (100,10)')\n",
    "plt.plot(trace2.history['val_acc'],label='original true covariates', color=\"red\")\n",
    "plt.plot(trace4.history['val_acc'],label='all engineered features', color=\"orange\")\n",
    "plt.plot(trace5.history['val_acc'],label='feature selection', color=\"purple\")\n",
    "plt.plot(trace1.history['val_acc'],label='true model', color=\"green\")\n",
    "plt.plot(trace3.history['val_acc'],label='all original covariates', color=\"blue\")\n",
    "plt.legend(loc=4)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n",
    "fig.savefig('C:/Users/Irina/Downloads/fig1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding engineered features improves performance in the first few iterations, and correctly identifying the true interaction terms is able to achieve better long-run performance. However, including unnecessary engineered features results in similar performance in the long run as not performing any feature engineering. Optimal accuracy is achieved when only the true interactions are included, reflecting that one should only perform feature engineering in the presence of subject expertise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.8840 - acc: 0.6756 - gini_normalized: nan - val_loss: 0.8096 - val_acc: 0.7100 - val_gini_normalized: nan\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.7627 - acc: 0.7444 - gini_normalized: nan - val_loss: 0.7054 - val_acc: 0.7780 - val_gini_normalized: nan\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.6714 - acc: 0.7936 - gini_normalized: nan - val_loss: 0.6235 - val_acc: 0.8140 - val_gini_normalized: nan\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.5983 - acc: 0.8228 - gini_normalized: nan - val_loss: 0.5573 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.5405 - acc: 0.8364 - gini_normalized: nan - val_loss: 0.5061 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.4952 - acc: 0.8456 - gini_normalized: nan - val_loss: 0.4664 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 0s 88us/step - loss: 0.4594 - acc: 0.8468 - gini_normalized: nan - val_loss: 0.4357 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 0s 88us/step - loss: 0.4333 - acc: 0.8500 - gini_normalized: nan - val_loss: 0.4137 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4141 - acc: 0.8532 - gini_normalized: nan - val_loss: 0.3985 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4003 - acc: 0.8588 - gini_normalized: nan - val_loss: 0.3869 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3891 - acc: 0.8604 - gini_normalized: nan - val_loss: 0.3783 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3815 - acc: 0.8572 - gini_normalized: nan - val_loss: 0.3723 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.3752 - acc: 0.8612 - gini_normalized: nan - val_loss: 0.3666 - val_acc: 0.8520 - val_gini_normalized: nan\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3700 - acc: 0.8576 - gini_normalized: nan - val_loss: 0.3613 - val_acc: 0.8520 - val_gini_normalized: nan\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3659 - acc: 0.8604 - gini_normalized: nan - val_loss: 0.3584 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3623 - acc: 0.8592 - gini_normalized: nan - val_loss: 0.3549 - val_acc: 0.8580 - val_gini_normalized: nan\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3594 - acc: 0.8608 - gini_normalized: nan - val_loss: 0.3532 - val_acc: 0.8560 - val_gini_normalized: nan\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.3571 - acc: 0.8600 - gini_normalized: nan - val_loss: 0.3507 - val_acc: 0.8560 - val_gini_normalized: nan\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.3550 - acc: 0.8604 - gini_normalized: nan - val_loss: 0.3485 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3527 - acc: 0.8620 - gini_normalized: nan - val_loss: 0.3452 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 0s 87us/step - loss: 0.3509 - acc: 0.8628 - gini_normalized: nan - val_loss: 0.3443 - val_acc: 0.8580 - val_gini_normalized: nan\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.3496 - acc: 0.8612 - gini_normalized: nan - val_loss: 0.3421 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3480 - acc: 0.8636 - gini_normalized: nan - val_loss: 0.3416 - val_acc: 0.8600 - val_gini_normalized: nan\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3471 - acc: 0.8632 - gini_normalized: nan - val_loss: 0.3410 - val_acc: 0.8580 - val_gini_normalized: nan\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.3456 - acc: 0.8624 - gini_normalized: nan - val_loss: 0.3389 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.3445 - acc: 0.8588 - gini_normalized: nan - val_loss: 0.3377 - val_acc: 0.8580 - val_gini_normalized: nan\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.3438 - acc: 0.8616 - gini_normalized: nan - val_loss: 0.3374 - val_acc: 0.8560 - val_gini_normalized: nan\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3428 - acc: 0.8580 - gini_normalized: nan - val_loss: 0.3360 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.3421 - acc: 0.8624 - gini_normalized: nan - val_loss: 0.3347 - val_acc: 0.8520 - val_gini_normalized: nan\n",
      "Epoch 30/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3412 - acc: 0.8612 - gini_normalized: nan - val_loss: 0.3332 - val_acc: 0.8520 - val_gini_normalized: nan\n",
      "Epoch 31/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3402 - acc: 0.8588 - gini_normalized: nan - val_loss: 0.3320 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.3397 - acc: 0.8624 - gini_normalized: nan - val_loss: 0.3311 - val_acc: 0.8580 - val_gini_normalized: nan\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3388 - acc: 0.8620 - gini_normalized: nan - val_loss: 0.3320 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3380 - acc: 0.8624 - gini_normalized: nan - val_loss: 0.3302 - val_acc: 0.8620 - val_gini_normalized: nan\n",
      "Epoch 35/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3375 - acc: 0.8596 - gini_normalized: nan - val_loss: 0.3308 - val_acc: 0.8600 - val_gini_normalized: nan\n",
      "Epoch 36/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.3376 - acc: 0.8640 - gini_normalized: nan - val_loss: 0.3311 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 37/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3361 - acc: 0.8604 - gini_normalized: nan - val_loss: 0.3295 - val_acc: 0.8560 - val_gini_normalized: nan\n",
      "Epoch 38/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.3358 - acc: 0.8612 - gini_normalized: nan - val_loss: 0.3286 - val_acc: 0.8560 - val_gini_normalized: nan\n",
      "Epoch 39/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.3354 - acc: 0.8616 - gini_normalized: nan - val_loss: 0.3282 - val_acc: 0.8580 - val_gini_normalized: nan\n",
      "Epoch 40/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.3352 - acc: 0.8608 - gini_normalized: nan - val_loss: 0.3277 - val_acc: 0.8560 - val_gini_normalized: nan\n",
      "Epoch 41/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.3341 - acc: 0.8612 - gini_normalized: nan - val_loss: 0.3286 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 42/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3343 - acc: 0.8636 - gini_normalized: nan - val_loss: 0.3266 - val_acc: 0.8560 - val_gini_normalized: nan\n",
      "Epoch 43/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.3336 - acc: 0.8596 - gini_normalized: nan - val_loss: 0.3255 - val_acc: 0.8520 - val_gini_normalized: nan\n",
      "Epoch 44/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3336 - acc: 0.8612 - gini_normalized: nan - val_loss: 0.3268 - val_acc: 0.8520 - val_gini_normalized: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.3333 - acc: 0.8620 - gini_normalized: nan - val_loss: 0.3264 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 46/50\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.3326 - acc: 0.8600 - gini_normalized: nan - val_loss: 0.3254 - val_acc: 0.8560 - val_gini_normalized: nan\n",
      "Epoch 47/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.3326 - acc: 0.8616 - gini_normalized: nan - val_loss: 0.3257 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 48/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3318 - acc: 0.8624 - gini_normalized: nan - val_loss: 0.3272 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 49/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.3325 - acc: 0.8584 - gini_normalized: nan - val_loss: 0.3244 - val_acc: 0.8560 - val_gini_normalized: nan\n",
      "Epoch 50/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.3318 - acc: 0.8580 - gini_normalized: nan - val_loss: 0.3241 - val_acc: 0.8520 - val_gini_normalized: nan\n",
      "500/500 [==============================] - 0s 68us/step\n"
     ]
    }
   ],
   "source": [
    "## with interaction and true covariates\n",
    "model_narrow1 = Sequential()\n",
    "model_narrow1.add(Dense(20, input_dim=np.shape(x_linear_true)[1]-5, kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model_narrow1.add(Dense(1, activation='sigmoid'))\n",
    "model_narrow1.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',gini_normalized])\n",
    "\n",
    "trace_narrow1 = model_narrow1.fit(x_linear_true[0:2500,0:12], y_linear[0:2500],epochs=50,batch_size=64, \\\n",
    "                    validation_data=(x_linear_true[2500:3000,0:12], y_linear[2500:3000]))\n",
    "score_narrow1 = model_narrow1.evaluate(x_linear_true[2500:3000,0:12], y_linear[2500:3000], batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.8799 - acc: 0.4800 - gini_normalized: nan - val_loss: 0.8187 - val_acc: 0.5780 - val_gini_normalized: nan\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.7804 - acc: 0.6592 - gini_normalized: nan - val_loss: 0.7404 - val_acc: 0.7280 - val_gini_normalized: nan\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.7118 - acc: 0.7264 - gini_normalized: nan - val_loss: 0.6849 - val_acc: 0.7340 - val_gini_normalized: nan\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.6611 - acc: 0.7452 - gini_normalized: nan - val_loss: 0.6413 - val_acc: 0.7500 - val_gini_normalized: nan\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.6244 - acc: 0.7532 - gini_normalized: nan - val_loss: 0.6113 - val_acc: 0.7580 - val_gini_normalized: nan\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.5970 - acc: 0.7624 - gini_normalized: nan - val_loss: 0.5865 - val_acc: 0.7680 - val_gini_normalized: nan\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.5748 - acc: 0.7664 - gini_normalized: nan - val_loss: 0.5658 - val_acc: 0.7780 - val_gini_normalized: nan\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.5566 - acc: 0.7744 - gini_normalized: nan - val_loss: 0.5506 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.5426 - acc: 0.7832 - gini_normalized: nan - val_loss: 0.5377 - val_acc: 0.7800 - val_gini_normalized: nan\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.5305 - acc: 0.7832 - gini_normalized: nan - val_loss: 0.5270 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.5198 - acc: 0.7868 - gini_normalized: nan - val_loss: 0.5167 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.5104 - acc: 0.7936 - gini_normalized: nan - val_loss: 0.5086 - val_acc: 0.8000 - val_gini_normalized: nan\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.5021 - acc: 0.8028 - gini_normalized: nan - val_loss: 0.5002 - val_acc: 0.8020 - val_gini_normalized: nan\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4949 - acc: 0.8084 - gini_normalized: nan - val_loss: 0.4920 - val_acc: 0.8140 - val_gini_normalized: nan\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4888 - acc: 0.8144 - gini_normalized: nan - val_loss: 0.4859 - val_acc: 0.8220 - val_gini_normalized: nan\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.4835 - acc: 0.8172 - gini_normalized: nan - val_loss: 0.4810 - val_acc: 0.8220 - val_gini_normalized: nan\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4785 - acc: 0.8200 - gini_normalized: nan - val_loss: 0.4758 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4738 - acc: 0.8228 - gini_normalized: nan - val_loss: 0.4712 - val_acc: 0.8140 - val_gini_normalized: nan\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.4697 - acc: 0.8232 - gini_normalized: nan - val_loss: 0.4666 - val_acc: 0.8260 - val_gini_normalized: nan\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.4658 - acc: 0.8264 - gini_normalized: nan - val_loss: 0.4627 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4623 - acc: 0.8280 - gini_normalized: nan - val_loss: 0.4598 - val_acc: 0.8260 - val_gini_normalized: nan\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.4589 - acc: 0.8304 - gini_normalized: nan - val_loss: 0.4554 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.4558 - acc: 0.8300 - gini_normalized: nan - val_loss: 0.4527 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4527 - acc: 0.8316 - gini_normalized: nan - val_loss: 0.4498 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4496 - acc: 0.8324 - gini_normalized: nan - val_loss: 0.4460 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4469 - acc: 0.8372 - gini_normalized: nan - val_loss: 0.4440 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4444 - acc: 0.8348 - gini_normalized: nan - val_loss: 0.4422 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4419 - acc: 0.8368 - gini_normalized: nan - val_loss: 0.4393 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4399 - acc: 0.8364 - gini_normalized: nan - val_loss: 0.4370 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 30/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.4378 - acc: 0.8348 - gini_normalized: nan - val_loss: 0.4349 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 31/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4361 - acc: 0.8384 - gini_normalized: nan - val_loss: 0.4335 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.4338 - acc: 0.8388 - gini_normalized: nan - val_loss: 0.4315 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.4322 - acc: 0.8408 - gini_normalized: nan - val_loss: 0.4294 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.4306 - acc: 0.8396 - gini_normalized: nan - val_loss: 0.4282 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 35/50\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.4289 - acc: 0.8376 - gini_normalized: nan - val_loss: 0.4250 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 36/50\n",
      "2500/2500 [==============================] - 0s 87us/step - loss: 0.4275 - acc: 0.8388 - gini_normalized: nan - val_loss: 0.4236 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 37/50\n",
      "2500/2500 [==============================] - 0s 91us/step - loss: 0.4261 - acc: 0.8436 - gini_normalized: nan - val_loss: 0.4225 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 38/50\n",
      "2500/2500 [==============================] - 0s 88us/step - loss: 0.4247 - acc: 0.8424 - gini_normalized: nan - val_loss: 0.4210 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 39/50\n",
      "2500/2500 [==============================] - 0s 88us/step - loss: 0.4232 - acc: 0.8412 - gini_normalized: nan - val_loss: 0.4200 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 40/50\n",
      "2500/2500 [==============================] - 0s 95us/step - loss: 0.4220 - acc: 0.8440 - gini_normalized: nan - val_loss: 0.4191 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 41/50\n",
      "2500/2500 [==============================] - 0s 118us/step - loss: 0.4207 - acc: 0.8440 - gini_normalized: nan - val_loss: 0.4182 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 42/50\n",
      "2500/2500 [==============================] - 0s 104us/step - loss: 0.4197 - acc: 0.8428 - gini_normalized: nan - val_loss: 0.4175 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 43/50\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4184 - acc: 0.8452 - gini_normalized: nan - val_loss: 0.4153 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 44/50\n",
      "2500/2500 [==============================] - 0s 94us/step - loss: 0.4173 - acc: 0.8448 - gini_normalized: nan - val_loss: 0.4136 - val_acc: 0.8320 - val_gini_normalized: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "2500/2500 [==============================] - 0s 90us/step - loss: 0.4158 - acc: 0.8428 - gini_normalized: nan - val_loss: 0.4129 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 46/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4148 - acc: 0.8416 - gini_normalized: nan - val_loss: 0.4121 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 47/50\n",
      "2500/2500 [==============================] - 0s 79us/step - loss: 0.4144 - acc: 0.8484 - gini_normalized: nan - val_loss: 0.4101 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 48/50\n",
      "2500/2500 [==============================] - 0s 99us/step - loss: 0.4134 - acc: 0.8440 - gini_normalized: nan - val_loss: 0.4097 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 49/50\n",
      "2500/2500 [==============================] - 0s 138us/step - loss: 0.4120 - acc: 0.8432 - gini_normalized: nan - val_loss: 0.4097 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 50/50\n",
      "2500/2500 [==============================] - 0s 102us/step - loss: 0.4111 - acc: 0.8452 - gini_normalized: nan - val_loss: 0.4081 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "500/500 [==============================] - 0s 68us/step\n"
     ]
    }
   ],
   "source": [
    "## without interactions\n",
    "model_narrow2 = Sequential()\n",
    "model_narrow2.add(Dense(20, input_dim=np.shape(x_linear_true)[1]-10, kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model_narrow2.add(Dense(1, activation='sigmoid'))\n",
    "model_narrow2.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',gini_normalized])\n",
    "\n",
    "trace_narrow2 = model_narrow2.fit(x_linear_true[0:2500,0:7], y_linear[0:2500],epochs=50,batch_size=64, \\\n",
    "                    validation_data=(x_linear_true[2500:3000,0:7], y_linear[2500:3000]))\n",
    "score_narrow2 = model_narrow2.evaluate(x_linear_true[2500:3000,0:7], y_linear[2500:3000], batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.7335 - acc: 0.5676 - gini_normalized: nan - val_loss: 0.6924 - val_acc: 0.5940 - val_gini_normalized: nan\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.6683 - acc: 0.6072 - gini_normalized: nan - val_loss: 0.6399 - val_acc: 0.6280 - val_gini_normalized: nan\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.6213 - acc: 0.6592 - gini_normalized: nan - val_loss: 0.6014 - val_acc: 0.6740 - val_gini_normalized: nan\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.5880 - acc: 0.7076 - gini_normalized: nan - val_loss: 0.5747 - val_acc: 0.7100 - val_gini_normalized: nan\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.5602 - acc: 0.7464 - gini_normalized: nan - val_loss: 0.5483 - val_acc: 0.7280 - val_gini_normalized: nan\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.5344 - acc: 0.7612 - gini_normalized: nan - val_loss: 0.5255 - val_acc: 0.7540 - val_gini_normalized: nan\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.5127 - acc: 0.7760 - gini_normalized: nan - val_loss: 0.5055 - val_acc: 0.7700 - val_gini_normalized: nan\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 0s 84us/step - loss: 0.4944 - acc: 0.7828 - gini_normalized: nan - val_loss: 0.4897 - val_acc: 0.7720 - val_gini_normalized: nan\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.4794 - acc: 0.7892 - gini_normalized: nan - val_loss: 0.4756 - val_acc: 0.7800 - val_gini_normalized: nan\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.4660 - acc: 0.7932 - gini_normalized: nan - val_loss: 0.4616 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 0s 79us/step - loss: 0.4537 - acc: 0.7964 - gini_normalized: nan - val_loss: 0.4504 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.4429 - acc: 0.7976 - gini_normalized: nan - val_loss: 0.4380 - val_acc: 0.8080 - val_gini_normalized: nan\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.4323 - acc: 0.8044 - gini_normalized: nan - val_loss: 0.4276 - val_acc: 0.8140 - val_gini_normalized: nan\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.4230 - acc: 0.8112 - gini_normalized: nan - val_loss: 0.4166 - val_acc: 0.8220 - val_gini_normalized: nan\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.4143 - acc: 0.8236 - gini_normalized: nan - val_loss: 0.4072 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.4067 - acc: 0.8296 - gini_normalized: nan - val_loss: 0.3992 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3987 - acc: 0.8324 - gini_normalized: nan - val_loss: 0.3908 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.3920 - acc: 0.8348 - gini_normalized: nan - val_loss: 0.3840 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.3859 - acc: 0.8376 - gini_normalized: nan - val_loss: 0.3786 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.3804 - acc: 0.8392 - gini_normalized: nan - val_loss: 0.3723 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3755 - acc: 0.8376 - gini_normalized: nan - val_loss: 0.3668 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.3710 - acc: 0.8384 - gini_normalized: nan - val_loss: 0.3616 - val_acc: 0.8560 - val_gini_normalized: nan\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.3671 - acc: 0.8444 - gini_normalized: nan - val_loss: 0.3573 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.3635 - acc: 0.8480 - gini_normalized: nan - val_loss: 0.3537 - val_acc: 0.8620 - val_gini_normalized: nan\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.3600 - acc: 0.8468 - gini_normalized: nan - val_loss: 0.3501 - val_acc: 0.8600 - val_gini_normalized: nan\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.3568 - acc: 0.8476 - gini_normalized: nan - val_loss: 0.3481 - val_acc: 0.8580 - val_gini_normalized: nan\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3541 - acc: 0.8472 - gini_normalized: nan - val_loss: 0.3454 - val_acc: 0.8600 - val_gini_normalized: nan\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.3515 - acc: 0.8476 - gini_normalized: nan - val_loss: 0.3429 - val_acc: 0.8620 - val_gini_normalized: nan\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.3495 - acc: 0.8484 - gini_normalized: nan - val_loss: 0.3405 - val_acc: 0.8640 - val_gini_normalized: nan\n",
      "Epoch 30/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.3476 - acc: 0.8524 - gini_normalized: nan - val_loss: 0.3384 - val_acc: 0.8600 - val_gini_normalized: nan\n",
      "Epoch 31/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.3453 - acc: 0.8480 - gini_normalized: nan - val_loss: 0.3374 - val_acc: 0.8560 - val_gini_normalized: nan\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3442 - acc: 0.8520 - gini_normalized: nan - val_loss: 0.3357 - val_acc: 0.8640 - val_gini_normalized: nan\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.3421 - acc: 0.8520 - gini_normalized: nan - val_loss: 0.3349 - val_acc: 0.8620 - val_gini_normalized: nan\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3411 - acc: 0.8524 - gini_normalized: nan - val_loss: 0.3329 - val_acc: 0.8680 - val_gini_normalized: nan\n",
      "Epoch 35/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.3394 - acc: 0.8508 - gini_normalized: nan - val_loss: 0.3316 - val_acc: 0.8660 - val_gini_normalized: nan\n",
      "Epoch 36/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.3381 - acc: 0.8504 - gini_normalized: nan - val_loss: 0.3296 - val_acc: 0.8660 - val_gini_normalized: nan\n",
      "Epoch 37/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3369 - acc: 0.8544 - gini_normalized: nan - val_loss: 0.3288 - val_acc: 0.8640 - val_gini_normalized: nan\n",
      "Epoch 38/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3354 - acc: 0.8552 - gini_normalized: nan - val_loss: 0.3281 - val_acc: 0.8640 - val_gini_normalized: nan\n",
      "Epoch 39/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3341 - acc: 0.8556 - gini_normalized: nan - val_loss: 0.3268 - val_acc: 0.8680 - val_gini_normalized: nan\n",
      "Epoch 40/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.3331 - acc: 0.8544 - gini_normalized: nan - val_loss: 0.3265 - val_acc: 0.8680 - val_gini_normalized: nan\n",
      "Epoch 41/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.3323 - acc: 0.8564 - gini_normalized: nan - val_loss: 0.3253 - val_acc: 0.8680 - val_gini_normalized: nan\n",
      "Epoch 42/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3313 - acc: 0.8580 - gini_normalized: nan - val_loss: 0.3241 - val_acc: 0.8680 - val_gini_normalized: nan\n",
      "Epoch 43/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.3302 - acc: 0.8580 - gini_normalized: nan - val_loss: 0.3230 - val_acc: 0.8660 - val_gini_normalized: nan\n",
      "Epoch 44/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.3293 - acc: 0.8584 - gini_normalized: nan - val_loss: 0.3230 - val_acc: 0.8540 - val_gini_normalized: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.3283 - acc: 0.8540 - gini_normalized: nan - val_loss: 0.3220 - val_acc: 0.8700 - val_gini_normalized: nan\n",
      "Epoch 46/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3277 - acc: 0.8556 - gini_normalized: nan - val_loss: 0.3223 - val_acc: 0.8680 - val_gini_normalized: nan\n",
      "Epoch 47/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.3269 - acc: 0.8560 - gini_normalized: nan - val_loss: 0.3216 - val_acc: 0.8660 - val_gini_normalized: nan\n",
      "Epoch 48/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3261 - acc: 0.8564 - gini_normalized: nan - val_loss: 0.3208 - val_acc: 0.8640 - val_gini_normalized: nan\n",
      "Epoch 49/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3252 - acc: 0.8560 - gini_normalized: nan - val_loss: 0.3205 - val_acc: 0.8620 - val_gini_normalized: nan\n",
      "Epoch 50/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3247 - acc: 0.8572 - gini_normalized: nan - val_loss: 0.3199 - val_acc: 0.8640 - val_gini_normalized: nan\n",
      "500/500 [==============================] - 0s 40us/step\n"
     ]
    }
   ],
   "source": [
    "## with interaction and useless predictors\n",
    "model_narrow3 = Sequential()\n",
    "model_narrow3.add(Dense(20, input_dim=12, activation='relu'))\n",
    "model_narrow3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_narrow3.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',gini_normalized])\n",
    "\n",
    "trace_narrow3 = model_narrow3.fit(np.concatenate((x_linear_true[0:2500,0:7],x_linear_true[0:2500,12:17]),axis=1), y_linear[0:2500],epochs=50,batch_size=64, \\\n",
    "                    validation_data=(np.concatenate((x_linear_true[2500:3000,0:7],x_linear_true[2500:3000,12:17]),axis=1), y_linear[2500:3000]))\n",
    "score_narrow3 = model_narrow3.evaluate(np.concatenate((x_linear_true[2500:3000,0:7],x_linear_true[2500:3000,12:17]),axis=1), y_linear[2500:3000], batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 1.3553 - acc: 0.6032 - gini_normalized: nan - val_loss: 1.1376 - val_acc: 0.6480 - val_gini_normalized: nan\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 1.0317 - acc: 0.7372 - gini_normalized: nan - val_loss: 0.9562 - val_acc: 0.7260 - val_gini_normalized: nan\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 0s 46us/step - loss: 0.8720 - acc: 0.7672 - gini_normalized: nan - val_loss: 0.8195 - val_acc: 0.7780 - val_gini_normalized: nan\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 0s 46us/step - loss: 0.7683 - acc: 0.7920 - gini_normalized: nan - val_loss: 0.7336 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.6945 - acc: 0.8096 - gini_normalized: nan - val_loss: 0.6745 - val_acc: 0.8020 - val_gini_normalized: nan\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 0s 46us/step - loss: 0.6392 - acc: 0.8148 - gini_normalized: nan - val_loss: 0.6174 - val_acc: 0.8220 - val_gini_normalized: nan\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 0s 46us/step - loss: 0.5999 - acc: 0.8208 - gini_normalized: nan - val_loss: 0.5892 - val_acc: 0.8200 - val_gini_normalized: nan\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 0s 53us/step - loss: 0.5706 - acc: 0.8316 - gini_normalized: nan - val_loss: 0.5659 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 0s 48us/step - loss: 0.5502 - acc: 0.8324 - gini_normalized: nan - val_loss: 0.5616 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 0s 46us/step - loss: 0.5361 - acc: 0.8352 - gini_normalized: nan - val_loss: 0.5371 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 0s 46us/step - loss: 0.5211 - acc: 0.8356 - gini_normalized: nan - val_loss: 0.5231 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 0s 45us/step - loss: 0.5080 - acc: 0.8384 - gini_normalized: nan - val_loss: 0.5094 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 0s 46us/step - loss: 0.4945 - acc: 0.8400 - gini_normalized: nan - val_loss: 0.5130 - val_acc: 0.8220 - val_gini_normalized: nan\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4858 - acc: 0.8444 - gini_normalized: nan - val_loss: 0.4900 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4788 - acc: 0.8396 - gini_normalized: nan - val_loss: 0.4912 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 0s 51us/step - loss: 0.4775 - acc: 0.8444 - gini_normalized: nan - val_loss: 0.4922 - val_acc: 0.8260 - val_gini_normalized: nan\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.4666 - acc: 0.8396 - gini_normalized: nan - val_loss: 0.4769 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.4701 - acc: 0.8436 - gini_normalized: nan - val_loss: 0.4629 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 0s 53us/step - loss: 0.4585 - acc: 0.8416 - gini_normalized: nan - val_loss: 0.4570 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 0s 53us/step - loss: 0.4522 - acc: 0.8412 - gini_normalized: nan - val_loss: 0.4753 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4493 - acc: 0.8392 - gini_normalized: nan - val_loss: 0.4665 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4477 - acc: 0.8476 - gini_normalized: nan - val_loss: 0.4577 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.4409 - acc: 0.8472 - gini_normalized: nan - val_loss: 0.4456 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.4363 - acc: 0.8436 - gini_normalized: nan - val_loss: 0.4704 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4367 - acc: 0.8424 - gini_normalized: nan - val_loss: 0.4441 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 0s 47us/step - loss: 0.4347 - acc: 0.8460 - gini_normalized: nan - val_loss: 0.4498 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 0s 47us/step - loss: 0.4374 - acc: 0.8456 - gini_normalized: nan - val_loss: 0.4512 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 0s 46us/step - loss: 0.4272 - acc: 0.8492 - gini_normalized: nan - val_loss: 0.4476 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.4239 - acc: 0.8464 - gini_normalized: nan - val_loss: 0.4469 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 30/50\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.4277 - acc: 0.8496 - gini_normalized: nan - val_loss: 0.4501 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 31/50\n",
      "2500/2500 [==============================] - 0s 85us/step - loss: 0.4187 - acc: 0.8468 - gini_normalized: nan - val_loss: 0.4412 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - 0s 90us/step - loss: 0.4207 - acc: 0.8492 - gini_normalized: nan - val_loss: 0.4434 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 0s 95us/step - loss: 0.4191 - acc: 0.8516 - gini_normalized: nan - val_loss: 0.4402 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 0s 92us/step - loss: 0.4218 - acc: 0.8460 - gini_normalized: nan - val_loss: 0.4250 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 35/50\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.4163 - acc: 0.8484 - gini_normalized: nan - val_loss: 0.4234 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 36/50\n",
      "2500/2500 [==============================] - 0s 90us/step - loss: 0.4159 - acc: 0.8564 - gini_normalized: nan - val_loss: 0.4346 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 37/50\n",
      "2500/2500 [==============================] - 0s 93us/step - loss: 0.4144 - acc: 0.8508 - gini_normalized: nan - val_loss: 0.4279 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 38/50\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.4095 - acc: 0.8488 - gini_normalized: nan - val_loss: 0.4228 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 39/50\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.4096 - acc: 0.8516 - gini_normalized: nan - val_loss: 0.4330 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 40/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.4052 - acc: 0.8516 - gini_normalized: nan - val_loss: 0.4287 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 41/50\n",
      "2500/2500 [==============================] - 0s 53us/step - loss: 0.4109 - acc: 0.8492 - gini_normalized: nan - val_loss: 0.4237 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 42/50\n",
      "2500/2500 [==============================] - 0s 47us/step - loss: 0.4076 - acc: 0.8524 - gini_normalized: nan - val_loss: 0.4191 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 43/50\n",
      "2500/2500 [==============================] - 0s 47us/step - loss: 0.4039 - acc: 0.8524 - gini_normalized: nan - val_loss: 0.4179 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 44/50\n",
      "2500/2500 [==============================] - 0s 45us/step - loss: 0.4058 - acc: 0.8524 - gini_normalized: nan - val_loss: 0.4186 - val_acc: 0.8280 - val_gini_normalized: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "2500/2500 [==============================] - 0s 46us/step - loss: 0.3970 - acc: 0.8552 - gini_normalized: nan - val_loss: 0.4278 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 46/50\n",
      "2500/2500 [==============================] - 0s 45us/step - loss: 0.4097 - acc: 0.8524 - gini_normalized: nan - val_loss: 0.4197 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 47/50\n",
      "2500/2500 [==============================] - 0s 47us/step - loss: 0.3983 - acc: 0.8544 - gini_normalized: nan - val_loss: 0.4277 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 48/50\n",
      "2500/2500 [==============================] - 0s 46us/step - loss: 0.3968 - acc: 0.8584 - gini_normalized: nan - val_loss: 0.4198 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 49/50\n",
      "2500/2500 [==============================] - 0s 47us/step - loss: 0.4044 - acc: 0.8552 - gini_normalized: nan - val_loss: 0.4202 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 50/50\n",
      "2500/2500 [==============================] - 0s 45us/step - loss: 0.4006 - acc: 0.8528 - gini_normalized: nan - val_loss: 0.4050 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "500/500 [==============================] - 0s 36us/step\n"
     ]
    }
   ],
   "source": [
    "## with interaction and useless features & original useless predictors\n",
    "model_narrow4 = Sequential()\n",
    "model_narrow4.add(Dense(20, input_dim=np.shape(x_linear_extra)[1], kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model_narrow4.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_narrow4.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',gini_normalized])\n",
    "\n",
    "trace_narrow4 = model_narrow4.fit(x_linear_extra[0:2500,:], y_linear[0:2500],epochs=50,batch_size=64, \\\n",
    "                    validation_data=(x_linear_extra[2500:3000,:], y_linear[2500:3000]))\n",
    "score_narrow4 = model_narrow4.evaluate(x_linear_extra[2500:3000,:], y_linear[2500:3000], batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5303 - acc: 0.3604 - gini_normalized: nan - val_loss: 1.1199 - val_acc: 0.5200 - val_gini_normalized: nan\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 0s 39us/step - loss: 1.0233 - acc: 0.6212 - gini_normalized: nan - val_loss: 0.8667 - val_acc: 0.7120 - val_gini_normalized: nan\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 0s 40us/step - loss: 0.8180 - acc: 0.7432 - gini_normalized: nan - val_loss: 0.7636 - val_acc: 0.7620 - val_gini_normalized: nan\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 0s 40us/step - loss: 0.7172 - acc: 0.7864 - gini_normalized: nan - val_loss: 0.6951 - val_acc: 0.8040 - val_gini_normalized: nan\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 0s 42us/step - loss: 0.6518 - acc: 0.8168 - gini_normalized: nan - val_loss: 0.6310 - val_acc: 0.8220 - val_gini_normalized: nan\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 0s 39us/step - loss: 0.6052 - acc: 0.8284 - gini_normalized: nan - val_loss: 0.5826 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 0s 45us/step - loss: 0.5632 - acc: 0.8328 - gini_normalized: nan - val_loss: 0.5559 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 0s 51us/step - loss: 0.5257 - acc: 0.8392 - gini_normalized: nan - val_loss: 0.5319 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 0s 51us/step - loss: 0.5096 - acc: 0.8380 - gini_normalized: nan - val_loss: 0.5059 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 0s 44us/step - loss: 0.4944 - acc: 0.8388 - gini_normalized: nan - val_loss: 0.4864 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 0s 42us/step - loss: 0.4825 - acc: 0.8372 - gini_normalized: nan - val_loss: 0.4759 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 0s 40us/step - loss: 0.4673 - acc: 0.8400 - gini_normalized: nan - val_loss: 0.4734 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 0s 48us/step - loss: 0.4569 - acc: 0.8400 - gini_normalized: nan - val_loss: 0.4703 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 0s 42us/step - loss: 0.4511 - acc: 0.8416 - gini_normalized: nan - val_loss: 0.4608 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.4434 - acc: 0.8412 - gini_normalized: nan - val_loss: 0.4547 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.4366 - acc: 0.8408 - gini_normalized: nan - val_loss: 0.4410 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.4360 - acc: 0.8408 - gini_normalized: nan - val_loss: 0.4378 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4278 - acc: 0.8420 - gini_normalized: nan - val_loss: 0.4389 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.4266 - acc: 0.8436 - gini_normalized: nan - val_loss: 0.4241 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4233 - acc: 0.8400 - gini_normalized: nan - val_loss: 0.4195 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 0s 85us/step - loss: 0.4270 - acc: 0.8392 - gini_normalized: nan - val_loss: 0.4294 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.4161 - acc: 0.8432 - gini_normalized: nan - val_loss: 0.4237 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.4180 - acc: 0.8432 - gini_normalized: nan - val_loss: 0.4251 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.4170 - acc: 0.8436 - gini_normalized: nan - val_loss: 0.4358 - val_acc: 0.8260 - val_gini_normalized: nan\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.4178 - acc: 0.8448 - gini_normalized: nan - val_loss: 0.4357 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4138 - acc: 0.8468 - gini_normalized: nan - val_loss: 0.4276 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 0s 46us/step - loss: 0.4108 - acc: 0.8444 - gini_normalized: nan - val_loss: 0.4122 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 0s 45us/step - loss: 0.4090 - acc: 0.8396 - gini_normalized: nan - val_loss: 0.4288 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 0s 42us/step - loss: 0.4095 - acc: 0.8432 - gini_normalized: nan - val_loss: 0.4281 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 30/50\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.4120 - acc: 0.8424 - gini_normalized: nan - val_loss: 0.4261 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 31/50\n",
      "2500/2500 [==============================] - 0s 42us/step - loss: 0.3997 - acc: 0.8468 - gini_normalized: nan - val_loss: 0.4316 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - 0s 39us/step - loss: 0.4000 - acc: 0.8444 - gini_normalized: nan - val_loss: 0.4133 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 0s 42us/step - loss: 0.3949 - acc: 0.8444 - gini_normalized: nan - val_loss: 0.4170 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 0s 42us/step - loss: 0.3957 - acc: 0.8488 - gini_normalized: nan - val_loss: 0.4114 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 35/50\n",
      "2500/2500 [==============================] - 0s 47us/step - loss: 0.3894 - acc: 0.8460 - gini_normalized: nan - val_loss: 0.4107 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 36/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.3888 - acc: 0.8472 - gini_normalized: nan - val_loss: 0.4138 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 37/50\n",
      "2500/2500 [==============================] - 0s 45us/step - loss: 0.3957 - acc: 0.8452 - gini_normalized: nan - val_loss: 0.3988 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 38/50\n",
      "2500/2500 [==============================] - 0s 45us/step - loss: 0.3935 - acc: 0.8452 - gini_normalized: nan - val_loss: 0.3925 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 39/50\n",
      "2500/2500 [==============================] - 0s 39us/step - loss: 0.3970 - acc: 0.8464 - gini_normalized: nan - val_loss: 0.3980 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 40/50\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.3934 - acc: 0.8440 - gini_normalized: nan - val_loss: 0.3937 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 41/50\n",
      "2500/2500 [==============================] - 0s 47us/step - loss: 0.3958 - acc: 0.8436 - gini_normalized: nan - val_loss: 0.3925 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 42/50\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.3936 - acc: 0.8476 - gini_normalized: nan - val_loss: 0.3811 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 43/50\n",
      "2500/2500 [==============================] - 0s 42us/step - loss: 0.3869 - acc: 0.8448 - gini_normalized: nan - val_loss: 0.3951 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 44/50\n",
      "2500/2500 [==============================] - 0s 42us/step - loss: 0.3910 - acc: 0.8484 - gini_normalized: nan - val_loss: 0.3865 - val_acc: 0.8340 - val_gini_normalized: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "2500/2500 [==============================] - 0s 43us/step - loss: 0.3870 - acc: 0.8436 - gini_normalized: nan - val_loss: 0.3978 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 46/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3896 - acc: 0.8496 - gini_normalized: nan - val_loss: 0.3898 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 47/50\n",
      "2500/2500 [==============================] - 0s 44us/step - loss: 0.3798 - acc: 0.8464 - gini_normalized: nan - val_loss: 0.3790 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 48/50\n",
      "2500/2500 [==============================] - 0s 40us/step - loss: 0.3918 - acc: 0.8476 - gini_normalized: nan - val_loss: 0.3916 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 49/50\n",
      "2500/2500 [==============================] - 0s 46us/step - loss: 0.3808 - acc: 0.8472 - gini_normalized: nan - val_loss: 0.3814 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 50/50\n",
      "2500/2500 [==============================] - 0s 48us/step - loss: 0.3817 - acc: 0.8464 - gini_normalized: nan - val_loss: 0.3788 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "500/500 [==============================] - 0s 30us/step\n"
     ]
    }
   ],
   "source": [
    "## Feature selection then NN\n",
    "model_narrow5 = Sequential()\n",
    "model_narrow5.add(Dense(20, input_dim=len(selected_features), kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model_narrow5.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_narrow5.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',gini_normalized])\n",
    "\n",
    "trace_narrow5 = model_narrow5.fit(x_linear_extra[0:2500,selected_features], y_linear[0:2500],epochs=50,batch_size=64, \\\n",
    "                    validation_data=(x_linear_extra[2500:3000,selected_features], y_linear[2500:3000]))\n",
    "score_narrow5 = model_narrow5.evaluate(x_linear_extra[2500:3000,selected_features], y_linear[2500:3000], batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEOCAYAAACQMUyOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21ed61c2278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10*.55,7*.55))\n",
    "plt.title('Hidden layer: (20)')\n",
    "plt.plot(trace_narrow2.history['val_acc'],label='original true covariates', color=\"red\")\n",
    "plt.plot(trace_narrow4.history['val_acc'],label='all engineered features', color=\"orange\")\n",
    "plt.plot(trace_narrow5.history['val_acc'],label='feature selection', color=\"purple\")\n",
    "plt.plot(trace_narrow1.history['val_acc'],label='true model', color=\"green\")\n",
    "plt.plot(trace_narrow3.history['val_acc'],label='all original covariates', color=\"blue\")\n",
    "plt.legend(loc=4)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With less model complexity, it takes longer learn a model without engineered features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9101 - acc: 0.7624 - gini_normalized: nan - val_loss: 0.7785 - val_acc: 0.8180 - val_gini_normalized: nan\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 0s 110us/step - loss: 0.6929 - acc: 0.8348 - gini_normalized: nan - val_loss: 0.6144 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 0s 95us/step - loss: 0.5601 - acc: 0.8480 - gini_normalized: nan - val_loss: 0.5080 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 0s 93us/step - loss: 0.4760 - acc: 0.8520 - gini_normalized: nan - val_loss: 0.4407 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 0s 88us/step - loss: 0.4256 - acc: 0.8536 - gini_normalized: nan - val_loss: 0.4035 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 0s 99us/step - loss: 0.3972 - acc: 0.8584 - gini_normalized: nan - val_loss: 0.3796 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.3787 - acc: 0.8588 - gini_normalized: nan - val_loss: 0.3651 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.3672 - acc: 0.8588 - gini_normalized: nan - val_loss: 0.3606 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 0s 87us/step - loss: 0.3611 - acc: 0.8612 - gini_normalized: nan - val_loss: 0.3560 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 0s 90us/step - loss: 0.3554 - acc: 0.8620 - gini_normalized: nan - val_loss: 0.3456 - val_acc: 0.8580 - val_gini_normalized: nan\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.3513 - acc: 0.8628 - gini_normalized: nan - val_loss: 0.3450 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.3475 - acc: 0.8592 - gini_normalized: nan - val_loss: 0.3382 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 0s 95us/step - loss: 0.3451 - acc: 0.8640 - gini_normalized: nan - val_loss: 0.3364 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.3426 - acc: 0.8628 - gini_normalized: nan - val_loss: 0.3361 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.3411 - acc: 0.8596 - gini_normalized: nan - val_loss: 0.3332 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.3399 - acc: 0.8608 - gini_normalized: nan - val_loss: 0.3309 - val_acc: 0.8620 - val_gini_normalized: nan\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.3385 - acc: 0.8612 - gini_normalized: nan - val_loss: 0.3302 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.3379 - acc: 0.8596 - gini_normalized: nan - val_loss: 0.3333 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.3362 - acc: 0.8600 - gini_normalized: nan - val_loss: 0.3339 - val_acc: 0.8520 - val_gini_normalized: nan\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.3339 - acc: 0.8572 - gini_normalized: nan - val_loss: 0.3316 - val_acc: 0.8600 - val_gini_normalized: nan\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.3344 - acc: 0.8564 - gini_normalized: nan - val_loss: 0.3284 - val_acc: 0.8520 - val_gini_normalized: nan\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - 0s 102us/step - loss: 0.3331 - acc: 0.8596 - gini_normalized: nan - val_loss: 0.3260 - val_acc: 0.8580 - val_gini_normalized: nan\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 0s 105us/step - loss: 0.3327 - acc: 0.8620 - gini_normalized: nan - val_loss: 0.3285 - val_acc: 0.8620 - val_gini_normalized: nan\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.3318 - acc: 0.8576 - gini_normalized: nan - val_loss: 0.3255 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.3326 - acc: 0.8604 - gini_normalized: nan - val_loss: 0.3307 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.3307 - acc: 0.8624 - gini_normalized: nan - val_loss: 0.3235 - val_acc: 0.8520 - val_gini_normalized: nan\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 0s 89us/step - loss: 0.3321 - acc: 0.8584 - gini_normalized: nan - val_loss: 0.3210 - val_acc: 0.8520 - val_gini_normalized: nan\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.3311 - acc: 0.8600 - gini_normalized: nan - val_loss: 0.3220 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.3310 - acc: 0.8572 - gini_normalized: nan - val_loss: 0.3267 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 30/50\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.3305 - acc: 0.8596 - gini_normalized: nan - val_loss: 0.3226 - val_acc: 0.8520 - val_gini_normalized: nan\n",
      "Epoch 31/50\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.3300 - acc: 0.8568 - gini_normalized: nan - val_loss: 0.3222 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 0.3219 - acc: 0.8705 - gini_normalized: n - 0s 69us/step - loss: 0.3309 - acc: 0.8624 - gini_normalized: nan - val_loss: 0.3204 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.3296 - acc: 0.8556 - gini_normalized: nan - val_loss: 0.3255 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.3295 - acc: 0.8600 - gini_normalized: nan - val_loss: 0.3209 - val_acc: 0.8520 - val_gini_normalized: nan\n",
      "Epoch 35/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3288 - acc: 0.8592 - gini_normalized: nan - val_loss: 0.3249 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 36/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.3292 - acc: 0.8600 - gini_normalized: nan - val_loss: 0.3232 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 37/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3282 - acc: 0.8608 - gini_normalized: nan - val_loss: 0.3255 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 38/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.3283 - acc: 0.8608 - gini_normalized: nan - val_loss: 0.3208 - val_acc: 0.8620 - val_gini_normalized: nan\n",
      "Epoch 39/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.3276 - acc: 0.8560 - gini_normalized: nan - val_loss: 0.3234 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 40/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3273 - acc: 0.8588 - gini_normalized: nan - val_loss: 0.3197 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 41/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3274 - acc: 0.8584 - gini_normalized: nan - val_loss: 0.3239 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 42/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.3268 - acc: 0.8608 - gini_normalized: nan - val_loss: 0.3181 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 43/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3263 - acc: 0.8612 - gini_normalized: nan - val_loss: 0.3261 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.3269 - acc: 0.8568 - gini_normalized: nan - val_loss: 0.3212 - val_acc: 0.8600 - val_gini_normalized: nan\n",
      "Epoch 45/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3275 - acc: 0.8588 - gini_normalized: nan - val_loss: 0.3200 - val_acc: 0.8600 - val_gini_normalized: nan\n",
      "Epoch 46/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3263 - acc: 0.8584 - gini_normalized: nan - val_loss: 0.3361 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 47/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3270 - acc: 0.8592 - gini_normalized: nan - val_loss: 0.3200 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 48/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3258 - acc: 0.8576 - gini_normalized: nan - val_loss: 0.3207 - val_acc: 0.8600 - val_gini_normalized: nan\n",
      "Epoch 49/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3270 - acc: 0.8596 - gini_normalized: nan - val_loss: 0.3236 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 50/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.3263 - acc: 0.8616 - gini_normalized: nan - val_loss: 0.3232 - val_acc: 0.8520 - val_gini_normalized: nan\n",
      "500/500 [==============================] - 0s 56us/step\n",
      "Train on 2500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.8485 - acc: 0.6340 - gini_normalized: nan - val_loss: 0.7642 - val_acc: 0.6780 - val_gini_normalized: nan\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.7017 - acc: 0.7360 - gini_normalized: nan - val_loss: 0.6611 - val_acc: 0.7480 - val_gini_normalized: nan\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.6183 - acc: 0.7732 - gini_normalized: nan - val_loss: 0.5956 - val_acc: 0.7700 - val_gini_normalized: nan\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.5691 - acc: 0.7872 - gini_normalized: nan - val_loss: 0.5569 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.5383 - acc: 0.7968 - gini_normalized: nan - val_loss: 0.5303 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.5163 - acc: 0.8008 - gini_normalized: nan - val_loss: 0.5100 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.5001 - acc: 0.8124 - gini_normalized: nan - val_loss: 0.4954 - val_acc: 0.8080 - val_gini_normalized: nan\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.4876 - acc: 0.8208 - gini_normalized: nan - val_loss: 0.4827 - val_acc: 0.8140 - val_gini_normalized: nan\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.4774 - acc: 0.8208 - gini_normalized: nan - val_loss: 0.4717 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4685 - acc: 0.8300 - gini_normalized: nan - val_loss: 0.4631 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4612 - acc: 0.8336 - gini_normalized: nan - val_loss: 0.4553 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4550 - acc: 0.8384 - gini_normalized: nan - val_loss: 0.4485 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4494 - acc: 0.8368 - gini_normalized: nan - val_loss: 0.4448 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4441 - acc: 0.8392 - gini_normalized: nan - val_loss: 0.4379 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4392 - acc: 0.8404 - gini_normalized: nan - val_loss: 0.4348 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4356 - acc: 0.8388 - gini_normalized: nan - val_loss: 0.4289 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4321 - acc: 0.8380 - gini_normalized: nan - val_loss: 0.4270 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4291 - acc: 0.8404 - gini_normalized: nan - val_loss: 0.4237 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4259 - acc: 0.8392 - gini_normalized: nan - val_loss: 0.4227 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4228 - acc: 0.8448 - gini_normalized: nan - val_loss: 0.4200 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4206 - acc: 0.8436 - gini_normalized: nan - val_loss: 0.4154 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4179 - acc: 0.8436 - gini_normalized: nan - val_loss: 0.4172 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.4158 - acc: 0.8440 - gini_normalized: nan - val_loss: 0.4138 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.4140 - acc: 0.8404 - gini_normalized: nan - val_loss: 0.4109 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4125 - acc: 0.8448 - gini_normalized: nan - val_loss: 0.4089 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4111 - acc: 0.8436 - gini_normalized: nan - val_loss: 0.4049 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4090 - acc: 0.8464 - gini_normalized: nan - val_loss: 0.4045 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4078 - acc: 0.8464 - gini_normalized: nan - val_loss: 0.4009 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4056 - acc: 0.8472 - gini_normalized: nan - val_loss: 0.4008 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 30/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4038 - acc: 0.8456 - gini_normalized: nan - val_loss: 0.4038 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 31/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.4034 - acc: 0.8480 - gini_normalized: nan - val_loss: 0.3982 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4016 - acc: 0.8456 - gini_normalized: nan - val_loss: 0.3966 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.4000 - acc: 0.8488 - gini_normalized: nan - val_loss: 0.3927 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.3991 - acc: 0.8472 - gini_normalized: nan - val_loss: 0.3917 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 35/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3979 - acc: 0.8464 - gini_normalized: nan - val_loss: 0.3938 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 36/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3973 - acc: 0.8448 - gini_normalized: nan - val_loss: 0.3921 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.3956 - acc: 0.8484 - gini_normalized: nan - val_loss: 0.3908 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 38/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3944 - acc: 0.8440 - gini_normalized: nan - val_loss: 0.3883 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 39/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.3938 - acc: 0.8500 - gini_normalized: nan - val_loss: 0.3888 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 40/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3923 - acc: 0.8480 - gini_normalized: nan - val_loss: 0.3863 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 41/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3906 - acc: 0.8456 - gini_normalized: nan - val_loss: 0.3945 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 42/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3915 - acc: 0.8472 - gini_normalized: nan - val_loss: 0.3872 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 43/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.3888 - acc: 0.8488 - gini_normalized: nan - val_loss: 0.3896 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 44/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3886 - acc: 0.8512 - gini_normalized: nan - val_loss: 0.3829 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 45/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3879 - acc: 0.8500 - gini_normalized: nan - val_loss: 0.3861 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 46/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.3868 - acc: 0.8484 - gini_normalized: nan - val_loss: 0.3842 - val_acc: 0.8580 - val_gini_normalized: nan\n",
      "Epoch 47/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3859 - acc: 0.8476 - gini_normalized: nan - val_loss: 0.3852 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 48/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3847 - acc: 0.8468 - gini_normalized: nan - val_loss: 0.3855 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 49/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.3855 - acc: 0.8504 - gini_normalized: nan - val_loss: 0.3849 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 50/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3828 - acc: 0.8504 - gini_normalized: nan - val_loss: 0.3853 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "500/500 [==============================] - 0s 64us/step\n",
      "Train on 2500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9671 - acc: 0.6828 - gini_normalized: nan - val_loss: 0.8615 - val_acc: 0.6880 - val_gini_normalized: nan\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.7914 - acc: 0.7320 - gini_normalized: nan - val_loss: 0.7341 - val_acc: 0.7160 - val_gini_normalized: nan\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.6841 - acc: 0.7492 - gini_normalized: nan - val_loss: 0.6476 - val_acc: 0.7500 - val_gini_normalized: nan\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.6138 - acc: 0.7656 - gini_normalized: nan - val_loss: 0.5910 - val_acc: 0.7620 - val_gini_normalized: nan\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 0s 84us/step - loss: 0.5670 - acc: 0.7776 - gini_normalized: nan - val_loss: 0.5541 - val_acc: 0.7760 - val_gini_normalized: nan\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 0s 79us/step - loss: 0.5361 - acc: 0.7900 - gini_normalized: nan - val_loss: 0.5283 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 0s 79us/step - loss: 0.5144 - acc: 0.8004 - gini_normalized: nan - val_loss: 0.5086 - val_acc: 0.8140 - val_gini_normalized: nan\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.4980 - acc: 0.8132 - gini_normalized: nan - val_loss: 0.4902 - val_acc: 0.8140 - val_gini_normalized: nan\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.4856 - acc: 0.8220 - gini_normalized: nan - val_loss: 0.4781 - val_acc: 0.8160 - val_gini_normalized: nan\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.4758 - acc: 0.8328 - gini_normalized: nan - val_loss: 0.4686 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.4671 - acc: 0.8304 - gini_normalized: nan - val_loss: 0.4625 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.4600 - acc: 0.8344 - gini_normalized: nan - val_loss: 0.4586 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4547 - acc: 0.8320 - gini_normalized: nan - val_loss: 0.4548 - val_acc: 0.8260 - val_gini_normalized: nan\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4485 - acc: 0.8368 - gini_normalized: nan - val_loss: 0.4461 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4446 - acc: 0.8360 - gini_normalized: nan - val_loss: 0.4391 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4397 - acc: 0.8388 - gini_normalized: nan - val_loss: 0.4363 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4354 - acc: 0.8380 - gini_normalized: nan - val_loss: 0.4337 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.4324 - acc: 0.8452 - gini_normalized: nan - val_loss: 0.4297 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.4295 - acc: 0.8396 - gini_normalized: nan - val_loss: 0.4250 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.4259 - acc: 0.8460 - gini_normalized: nan - val_loss: 0.4219 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4237 - acc: 0.8428 - gini_normalized: nan - val_loss: 0.4217 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4219 - acc: 0.8364 - gini_normalized: nan - val_loss: 0.4188 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.4188 - acc: 0.8432 - gini_normalized: nan - val_loss: 0.4183 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.4166 - acc: 0.8452 - gini_normalized: nan - val_loss: 0.4132 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4151 - acc: 0.8468 - gini_normalized: nan - val_loss: 0.4123 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4120 - acc: 0.8436 - gini_normalized: nan - val_loss: 0.4179 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4102 - acc: 0.8452 - gini_normalized: nan - val_loss: 0.4106 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.4084 - acc: 0.8472 - gini_normalized: nan - val_loss: 0.4054 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4066 - acc: 0.8440 - gini_normalized: nan - val_loss: 0.4027 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4060 - acc: 0.8460 - gini_normalized: nan - val_loss: 0.4003 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 31/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4030 - acc: 0.8456 - gini_normalized: nan - val_loss: 0.4040 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4043 - acc: 0.8456 - gini_normalized: nan - val_loss: 0.4026 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.4005 - acc: 0.8472 - gini_normalized: nan - val_loss: 0.3975 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.3999 - acc: 0.8424 - gini_normalized: nan - val_loss: 0.3952 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 35/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.3986 - acc: 0.8460 - gini_normalized: nan - val_loss: 0.4010 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 36/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3969 - acc: 0.8460 - gini_normalized: nan - val_loss: 0.3983 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 37/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.3954 - acc: 0.8412 - gini_normalized: nan - val_loss: 0.3929 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 38/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3948 - acc: 0.8456 - gini_normalized: nan - val_loss: 0.3987 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 39/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3951 - acc: 0.8476 - gini_normalized: nan - val_loss: 0.3990 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 40/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3924 - acc: 0.8480 - gini_normalized: nan - val_loss: 0.3910 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 41/50\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.3936 - acc: 0.8476 - gini_normalized: nan - val_loss: 0.3951 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 42/50\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.3911 - acc: 0.8476 - gini_normalized: nan - val_loss: 0.3983 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 43/50\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.3909 - acc: 0.8488 - gini_normalized: nan - val_loss: 0.3894 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 44/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.3910 - acc: 0.8480 - gini_normalized: nan - val_loss: 0.3881 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 45/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3890 - acc: 0.8468 - gini_normalized: nan - val_loss: 0.3942 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 46/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.3881 - acc: 0.8524 - gini_normalized: nan - val_loss: 0.3845 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 47/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3870 - acc: 0.8496 - gini_normalized: nan - val_loss: 0.3873 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 48/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3865 - acc: 0.8540 - gini_normalized: nan - val_loss: 0.3843 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 49/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.3861 - acc: 0.8436 - gini_normalized: nan - val_loss: 0.3833 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 50/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.3840 - acc: 0.8456 - gini_normalized: nan - val_loss: 0.3799 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "500/500 [==============================] - 0s 44us/step\n",
      "Train on 2500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6926 - acc: 0.7280 - gini_normalized: nan - val_loss: 1.3908 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 1.2327 - acc: 0.8084 - gini_normalized: nan - val_loss: 1.0870 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.9871 - acc: 0.8248 - gini_normalized: nan - val_loss: 0.8877 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.8216 - acc: 0.8336 - gini_normalized: nan - val_loss: 0.7492 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.7308 - acc: 0.8372 - gini_normalized: nan - val_loss: 0.6780 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.6531 - acc: 0.8412 - gini_normalized: nan - val_loss: 0.6043 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.6052 - acc: 0.8440 - gini_normalized: nan - val_loss: 0.6112 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.5720 - acc: 0.8440 - gini_normalized: nan - val_loss: 0.5846 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.5527 - acc: 0.8468 - gini_normalized: nan - val_loss: 0.5754 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.5403 - acc: 0.8472 - gini_normalized: nan - val_loss: 0.5487 - val_acc: 0.8220 - val_gini_normalized: nan\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.5265 - acc: 0.8448 - gini_normalized: nan - val_loss: 0.5172 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.5084 - acc: 0.8448 - gini_normalized: nan - val_loss: 0.4963 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.4972 - acc: 0.8476 - gini_normalized: nan - val_loss: 0.4864 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.4883 - acc: 0.8492 - gini_normalized: nan - val_loss: 0.5083 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 0.4848 - acc: 0.8547 - gini_normalized: n - 0s 78us/step - loss: 0.4835 - acc: 0.8544 - gini_normalized: nan - val_loss: 0.4891 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.4864 - acc: 0.8520 - gini_normalized: nan - val_loss: 0.5010 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.4684 - acc: 0.8532 - gini_normalized: nan - val_loss: 0.4995 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.4657 - acc: 0.8500 - gini_normalized: nan - val_loss: 0.4567 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.4561 - acc: 0.8496 - gini_normalized: nan - val_loss: 0.4812 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.4576 - acc: 0.8468 - gini_normalized: nan - val_loss: 0.5044 - val_acc: 0.8100 - val_gini_normalized: nan\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4537 - acc: 0.8488 - gini_normalized: nan - val_loss: 0.4609 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.4512 - acc: 0.8472 - gini_normalized: nan - val_loss: 0.4775 - val_acc: 0.8160 - val_gini_normalized: nan\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.4429 - acc: 0.8512 - gini_normalized: nan - val_loss: 0.4699 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4355 - acc: 0.8500 - gini_normalized: nan - val_loss: 0.4796 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 0s 84us/step - loss: 0.4444 - acc: 0.8524 - gini_normalized: nan - val_loss: 0.4986 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.4349 - acc: 0.8492 - gini_normalized: nan - val_loss: 0.4251 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.4342 - acc: 0.8548 - gini_normalized: nan - val_loss: 0.4746 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.4350 - acc: 0.8536 - gini_normalized: nan - val_loss: 0.4861 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 0s 79us/step - loss: 0.4250 - acc: 0.8608 - gini_normalized: nan - val_loss: 0.4544 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 30/50\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.4204 - acc: 0.8580 - gini_normalized: nan - val_loss: 0.4715 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 31/50\n",
      "2500/2500 [==============================] - 0s 79us/step - loss: 0.4213 - acc: 0.8572 - gini_normalized: nan - val_loss: 0.4331 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.4188 - acc: 0.8584 - gini_normalized: nan - val_loss: 0.4392 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.4171 - acc: 0.8560 - gini_normalized: nan - val_loss: 0.4154 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.4069 - acc: 0.8596 - gini_normalized: nan - val_loss: 0.4176 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 35/50\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.4118 - acc: 0.8532 - gini_normalized: nan - val_loss: 0.4811 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 36/50\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.4223 - acc: 0.8548 - gini_normalized: nan - val_loss: 0.4848 - val_acc: 0.8260 - val_gini_normalized: nan\n",
      "Epoch 37/50\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.4173 - acc: 0.8552 - gini_normalized: nan - val_loss: 0.4695 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 38/50\n",
      "2500/2500 [==============================] - 0s 79us/step - loss: 0.4003 - acc: 0.8540 - gini_normalized: nan - val_loss: 0.4536 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 39/50\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.4010 - acc: 0.8604 - gini_normalized: nan - val_loss: 0.4122 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 40/50\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.3995 - acc: 0.8556 - gini_normalized: nan - val_loss: 0.4246 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 41/50\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.3982 - acc: 0.8600 - gini_normalized: nan - val_loss: 0.4030 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 42/50\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.3912 - acc: 0.8584 - gini_normalized: nan - val_loss: 0.4068 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 43/50\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.3946 - acc: 0.8544 - gini_normalized: nan - val_loss: 0.4515 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 44/50\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.3979 - acc: 0.8556 - gini_normalized: nan - val_loss: 0.4108 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 45/50\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.3936 - acc: 0.8548 - gini_normalized: nan - val_loss: 0.4279 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 46/50\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.3886 - acc: 0.8604 - gini_normalized: nan - val_loss: 0.4505 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 47/50\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.3911 - acc: 0.8548 - gini_normalized: nan - val_loss: 0.4283 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 48/50\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.3965 - acc: 0.8580 - gini_normalized: nan - val_loss: 0.4366 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 49/50\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.3856 - acc: 0.8608 - gini_normalized: nan - val_loss: 0.4534 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 50/50\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.3987 - acc: 0.8596 - gini_normalized: nan - val_loss: 0.4050 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "500/500 [==============================] - 0s 56us/step\n",
      "Train on 2500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0417 - acc: 0.7716 - gini_normalized: nan - val_loss: 0.8420 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.7902 - acc: 0.8240 - gini_normalized: nan - val_loss: 0.7364 - val_acc: 0.8260 - val_gini_normalized: nan\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.6704 - acc: 0.8284 - gini_normalized: nan - val_loss: 0.6399 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.5874 - acc: 0.8328 - gini_normalized: nan - val_loss: 0.5847 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.5337 - acc: 0.8412 - gini_normalized: nan - val_loss: 0.5099 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.5029 - acc: 0.8384 - gini_normalized: nan - val_loss: 0.4755 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.4718 - acc: 0.8432 - gini_normalized: nan - val_loss: 0.4970 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4705 - acc: 0.8384 - gini_normalized: nan - val_loss: 0.4900 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4555 - acc: 0.8396 - gini_normalized: nan - val_loss: 0.4767 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4552 - acc: 0.8416 - gini_normalized: nan - val_loss: 0.4655 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4354 - acc: 0.8404 - gini_normalized: nan - val_loss: 0.4783 - val_acc: 0.8220 - val_gini_normalized: nan\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.4350 - acc: 0.8440 - gini_normalized: nan - val_loss: 0.4222 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.4326 - acc: 0.8396 - gini_normalized: nan - val_loss: 0.4587 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.4253 - acc: 0.8464 - gini_normalized: nan - val_loss: 0.4425 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4186 - acc: 0.8416 - gini_normalized: nan - val_loss: 0.4201 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4268 - acc: 0.8396 - gini_normalized: nan - val_loss: 0.4470 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4199 - acc: 0.8420 - gini_normalized: nan - val_loss: 0.4437 - val_acc: 0.8260 - val_gini_normalized: nan\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.4154 - acc: 0.8412 - gini_normalized: nan - val_loss: 0.4257 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.4107 - acc: 0.8432 - gini_normalized: nan - val_loss: 0.4358 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.4067 - acc: 0.8420 - gini_normalized: nan - val_loss: 0.3840 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.4067 - acc: 0.8452 - gini_normalized: nan - val_loss: 0.3929 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.4098 - acc: 0.8424 - gini_normalized: nan - val_loss: 0.3908 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.4038 - acc: 0.8420 - gini_normalized: nan - val_loss: 0.4185 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.4051 - acc: 0.8444 - gini_normalized: nan - val_loss: 0.4094 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.3983 - acc: 0.8432 - gini_normalized: nan - val_loss: 0.4027 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.3963 - acc: 0.8432 - gini_normalized: nan - val_loss: 0.4187 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.3992 - acc: 0.8416 - gini_normalized: nan - val_loss: 0.4088 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.3967 - acc: 0.8408 - gini_normalized: nan - val_loss: 0.3802 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.3950 - acc: 0.8484 - gini_normalized: nan - val_loss: 0.3746 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 30/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4015 - acc: 0.8460 - gini_normalized: nan - val_loss: 0.4026 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 31/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.3993 - acc: 0.8448 - gini_normalized: nan - val_loss: 0.4211 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.3822 - acc: 0.8464 - gini_normalized: nan - val_loss: 0.3923 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3906 - acc: 0.8440 - gini_normalized: nan - val_loss: 0.4081 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.3788 - acc: 0.8448 - gini_normalized: nan - val_loss: 0.3899 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 35/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3923 - acc: 0.8468 - gini_normalized: nan - val_loss: 0.4205 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 36/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3868 - acc: 0.8476 - gini_normalized: nan - val_loss: 0.4008 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 37/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3889 - acc: 0.8440 - gini_normalized: nan - val_loss: 0.3946 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 38/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.3947 - acc: 0.8436 - gini_normalized: nan - val_loss: 0.4033 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 39/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.3835 - acc: 0.8448 - gini_normalized: nan - val_loss: 0.3749 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 40/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.3808 - acc: 0.8456 - gini_normalized: nan - val_loss: 0.3638 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 41/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3773 - acc: 0.8468 - gini_normalized: nan - val_loss: 0.3989 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 42/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.3869 - acc: 0.8468 - gini_normalized: nan - val_loss: 0.4256 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 43/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3902 - acc: 0.8488 - gini_normalized: nan - val_loss: 0.3902 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 44/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.3758 - acc: 0.8444 - gini_normalized: nan - val_loss: 0.4091 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 45/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3801 - acc: 0.8488 - gini_normalized: nan - val_loss: 0.4234 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 46/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3864 - acc: 0.8448 - gini_normalized: nan - val_loss: 0.4150 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 47/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3779 - acc: 0.8480 - gini_normalized: nan - val_loss: 0.3839 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 48/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3779 - acc: 0.8460 - gini_normalized: nan - val_loss: 0.3797 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 49/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3755 - acc: 0.8468 - gini_normalized: nan - val_loss: 0.3724 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 50/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3732 - acc: 0.8540 - gini_normalized: nan - val_loss: 0.3721 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "500/500 [==============================] - 0s 40us/step\n"
     ]
    }
   ],
   "source": [
    "## with interaction but no useless predictors\n",
    "model_wide1 = Sequential()\n",
    "model_wide1.add(Dense(100, input_dim=np.shape(x_linear_true)[1]-5, kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model_wide1.add(Dense(1, activation='sigmoid'))\n",
    "model_wide1.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',gini_normalized])\n",
    "trace_wide1 = model_wide1.fit(x_linear_true[0:2500,0:12], y_linear[0:2500],epochs=50,batch_size=64, \\\n",
    "                    validation_data=(x_linear_true[2500:3000,0:12], y_linear[2500:3000]))\n",
    "score_wide1 = model_wide1.evaluate(x_linear_true[2500:3000,0:12], y_linear[2500:3000], batch_size=64)\n",
    "\n",
    "model_wide2 = Sequential()\n",
    "model_wide2.add(Dense(100, input_dim=np.shape(x_linear_true)[1]-10, kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model_wide2.add(Dense(1, activation='sigmoid'))\n",
    "model_wide2.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',gini_normalized])\n",
    "trace_wide2 = model_wide2.fit(x_linear_true[0:2500,0:7], y_linear[0:2500],epochs=50,batch_size=64, \\\n",
    "                    validation_data=(x_linear_true[2500:3000,0:7], y_linear[2500:3000]))\n",
    "score_wide2 = model_wide2.evaluate(x_linear_true[2500:3000,0:7], y_linear[2500:3000], batch_size=64)\n",
    "\n",
    "model_wide3 = Sequential()\n",
    "model_wide3.add(Dense(100, input_dim=12, kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model_wide3.add(Dense(1, activation='sigmoid'))\n",
    "model_wide3.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',gini_normalized])\n",
    "trace_wide3 = model_wide3.fit(np.concatenate((x_linear_true[0:2500,0:7],x_linear_true[0:2500,12:17]),axis=1), y_linear[0:2500],epochs=50,batch_size=64, \\\n",
    "                    validation_data=(np.concatenate((x_linear_true[2500:3000,0:7],x_linear_true[2500:3000,12:17]),axis=1), y_linear[2500:3000]))\n",
    "score_wide3 = model_wide3.evaluate(np.concatenate((x_linear_true[2500:3000,0:7],x_linear_true[2500:3000,12:17]),axis=1), y_linear[2500:3000], batch_size=64)\n",
    "\n",
    "model_wide4 = Sequential()\n",
    "model_wide4.add(Dense(100, input_dim=np.shape(x_linear_extra)[1], kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model_wide4.add(Dense(1, activation='sigmoid'))\n",
    "model_wide4.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',gini_normalized])\n",
    "trace_wide4 = model_wide4.fit(x_linear_extra[0:2500,:], y_linear[0:2500],epochs=50,batch_size=64, \\\n",
    "                    validation_data=(x_linear_extra[2500:3000,:], y_linear[2500:3000]))\n",
    "score_wide4 = model_wide4.evaluate(x_linear_extra[2500:3000,:], y_linear[2500:3000], batch_size=64)\n",
    "\n",
    "model_wide5 = Sequential()\n",
    "model_wide5.add(Dense(100, input_dim=len(selected_features), kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model_wide5.add(Dense(1, activation='sigmoid'))\n",
    "model_wide5.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',gini_normalized])\n",
    "trace_wide5 = model_wide5.fit(x_linear_extra[0:2500,selected_features], y_linear[0:2500],epochs=50,batch_size=64, \\\n",
    "                    validation_data=(x_linear_extra[2500:3000,selected_features], y_linear[2500:3000]))\n",
    "score_wide5 = model_wide5.evaluate(x_linear_extra[2500:3000,selected_features], y_linear[2500:3000], batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEOCAYAAACdLzzJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21ed6537f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10*.55,7*.55))\n",
    "plt.title('Hidden layer: (100)')\n",
    "plt.plot(trace_wide2.history['val_acc'],label='original true covariates', color=\"red\")\n",
    "plt.plot(trace_wide4.history['val_acc'],label='all engineered features', color=\"orange\")\n",
    "plt.plot(trace_wide5.history['val_acc'],label='feature selection', color=\"purple\")\n",
    "plt.plot(trace_wide1.history['val_acc'],label='true model', color=\"green\")\n",
    "plt.plot(trace_wide3.history['val_acc'],label='all original covariates', color=\"blue\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "With a single wide layer, including all engineered features performs similarly to feature selection. In the long run, including only the original covariates continues to outperform feature engineering. Including only the original covariates can achieve the same accuracy, but only after many iterations.\n",
    "\n",
    "# Non-linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Irina\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=8.709e-02, previous alpha=7.973e-02, with an active set of 14 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEXCAYAAACK4bLWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21e9a0b3470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|coef| / max|coef| 0.486945293468\n",
      "Nonzero features: 10\n",
      "Nonzero columns: \n",
      "[17 23 25 26 27 28 31 40 43 46]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>17</th>\n",
       "      <th>23</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>31</th>\n",
       "      <th>40</th>\n",
       "      <th>43</th>\n",
       "      <th>46</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.286378</td>\n",
       "      <td>5.261075</td>\n",
       "      <td>1.707692</td>\n",
       "      <td>0.361229</td>\n",
       "      <td>5.692984</td>\n",
       "      <td>1.335716</td>\n",
       "      <td>-0.525556</td>\n",
       "      <td>-0.585454</td>\n",
       "      <td>-3.517641</td>\n",
       "      <td>6.008395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.454526</td>\n",
       "      <td>5.764614</td>\n",
       "      <td>1.962434</td>\n",
       "      <td>2.631511</td>\n",
       "      <td>6.007690</td>\n",
       "      <td>0.958707</td>\n",
       "      <td>0.696791</td>\n",
       "      <td>0.539619</td>\n",
       "      <td>-22.944638</td>\n",
       "      <td>-42.520083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.665689</td>\n",
       "      <td>0.145142</td>\n",
       "      <td>0.442242</td>\n",
       "      <td>0.216815</td>\n",
       "      <td>1.691355</td>\n",
       "      <td>2.163867</td>\n",
       "      <td>0.533716</td>\n",
       "      <td>-2.908897</td>\n",
       "      <td>-1.980462</td>\n",
       "      <td>0.680829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.378909</td>\n",
       "      <td>0.664288</td>\n",
       "      <td>3.235778</td>\n",
       "      <td>0.348115</td>\n",
       "      <td>2.392982</td>\n",
       "      <td>0.678406</td>\n",
       "      <td>-1.112818</td>\n",
       "      <td>-1.209367</td>\n",
       "      <td>2.719582</td>\n",
       "      <td>-2.248765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.005486</td>\n",
       "      <td>1.180373</td>\n",
       "      <td>1.522978</td>\n",
       "      <td>1.192875</td>\n",
       "      <td>0.193737</td>\n",
       "      <td>0.394207</td>\n",
       "      <td>2.385188</td>\n",
       "      <td>-0.256309</td>\n",
       "      <td>-0.107459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         17        23        25        26        27        28        31  \\\n",
       "0  0.286378  5.261075  1.707692  0.361229  5.692984  1.335716 -0.525556   \n",
       "1  0.454526  5.764614  1.962434  2.631511  6.007690  0.958707  0.696791   \n",
       "2  0.665689  0.145142  0.442242  0.216815  1.691355  2.163867  0.533716   \n",
       "3  1.378909  0.664288  3.235778  0.348115  2.392982  0.678406 -1.112818   \n",
       "4  0.027500  0.005486  1.180373  1.522978  1.192875  0.193737  0.394207   \n",
       "\n",
       "         40         43         46  \n",
       "0 -0.585454  -3.517641   6.008395  \n",
       "1  0.539619 -22.944638 -42.520083  \n",
       "2 -2.908897  -1.980462   0.680829  \n",
       "3 -1.209367   2.719582  -2.248765  \n",
       "4  2.385188  -0.256309  -0.107459  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature selection\n",
    "from sklearn import linear_model\n",
    "alphas_nl, _, coefs_nl = linear_model.lars_path(x_nonlinear_extra[0:2500,:], y_nonlinear[0:2500], method='lasso', verbose=True)\n",
    "\n",
    "# Plot results\n",
    "xx_nl = np.sum(np.abs(coefs_nl.T), axis=1)\n",
    "xx_nl /= xx_nl[-1]\n",
    "\n",
    "plt.plot(xx_nl, coefs_nl.T)\n",
    "ymin, ymax = plt.ylim()\n",
    "#plt.vlines(xx, ymin, ymax, linestyle='dashed')\n",
    "plt.xlabel('|coef| / max|coef|')\n",
    "plt.ylabel('Coefficients')\n",
    "plt.title('LASSO Path')\n",
    "plt.axis('tight')\n",
    "plt.show()\n",
    "\n",
    "# Top 10 variables\n",
    "i = 10\n",
    "print('|coef| / max|coef|',xx_nl[i])\n",
    "print('Nonzero features:',sum(abs(coefs_nl.T[i])>0))\n",
    "print(\"Nonzero columns: \")\n",
    "print(pd.DataFrame(x_nonlinear_extra[0:2500,:]).iloc[:,abs(coefs_nl.T[i])>0].columns.values)\n",
    "pd.DataFrame(x_nonlinear_extra[0:2500,:]).iloc[:,abs(coefs_nl.T[i])>0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\negl36GZmvcT/AzYhlnQO4es1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21e988c8e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) 7                              0.081353\n",
      " 2) 29                             0.080754\n",
      " 3) 2                              0.064868\n",
      " 4) 27                             0.043589\n",
      " 5) 39                             0.042504\n",
      " 6) 33                             0.036890\n",
      " 7) 30                             0.032569\n",
      " 8) 11                             0.026663\n",
      " 9) 23                             0.026372\n",
      "10) 0                              0.025795\n",
      "11) 45                             0.025165\n",
      "12) 1                              0.024811\n",
      "13) 25                             0.023745\n",
      "14) 26                             0.022431\n",
      "15) 19                             0.020065\n",
      "16) 31                             0.019842\n",
      "17) 10                             0.018910\n",
      "18) 17                             0.018439\n",
      "19) 18                             0.018234\n",
      "20) 38                             0.018050\n",
      "21) 32                             0.016921\n",
      "22) 21                             0.016702\n",
      "23) 22                             0.016683\n",
      "24) 42                             0.016291\n",
      "25) 40                             0.016088\n",
      "26) 34                             0.016061\n",
      "27) 36                             0.015802\n",
      "28) 41                             0.014349\n",
      "29) 35                             0.013676\n",
      "30) 44                             0.013429\n",
      "31) 46                             0.013151\n",
      "32) 12                             0.013114\n",
      "33) 9                              0.013109\n",
      "34) 37                             0.012908\n",
      "35) 20                             0.012574\n",
      "36) 43                             0.012461\n",
      "37) 28                             0.012329\n",
      "38) 24                             0.011387\n",
      "39) 8                              0.010007\n",
      "40) 3                              0.009448\n",
      "41) 16                             0.008648\n",
      "42) 6                              0.008560\n",
      "43) 14                             0.008269\n",
      "44) 13                             0.007670\n",
      "45) 15                             0.007409\n",
      "46) 4                              0.006006\n",
      "47) 5                              0.005903\n"
     ]
    }
   ],
   "source": [
    "### Random forest feature importance\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "\n",
    "forest.fit(x_linear_extra[0:2500,:], y_linear[0:2500])\n",
    "\n",
    "### Plot feature importance\n",
    "# https://stackoverflow.com/questions/44511636/matplotlib-plot-feature-importance-with-feature-names\n",
    "importances_nl = forest.feature_importances_\n",
    "std_nl = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices_nl = np.argsort(importances_nl)\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.barh(range(x_linear_extra[0:2500,:].shape[1]), importances_nl[indices_nl])#,\n",
    "       #color=\"r\")#, xerr=std[indices], align=\"center\")\n",
    "# If you want to define your own labels,\n",
    "# change indices to a list of labels on the following line.\n",
    "plt.yticks(range(x_linear_extra[0:2500,:].shape[1]), indices_nl)\n",
    "plt.ylim([-1, x_linear_extra[0:2500,:].shape[1]])\n",
    "plt.show()\n",
    "\n",
    "# Selected features\n",
    "feat_labels_nl = pd.DataFrame(x_linear_extra[0:2500,:]).columns\n",
    "indices_nl = np.argsort(forest.feature_importances_)[::-1]\n",
    "\n",
    "for f in range(pd.DataFrame(x_linear_extra[0:2500,:]).shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30,feat_labels_nl[indices_nl[f]], importances_nl[indices_nl[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 7, 11, 17, 23, 25, 26, 27, 28, 29, 30, 31, 33, 39, 40, 43, 46]\n"
     ]
    }
   ],
   "source": [
    "# Selecting features based on how precipitously variable coefficients fall to zero in lasso/at jump in variable importance:\n",
    "selected_features_nl = sorted(list(set(pd.DataFrame(x_linear_extra[0:2500,:]).iloc[:,abs(coefs_nl.T[i])>0].columns.values.tolist()+ \\\n",
    "                                    indices_nl[0:8].tolist())))\n",
    "print(selected_features_nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2500 samples, validate on 500 samples\n",
      "Epoch 1/150\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.1847 - acc: 0.4616 - gini_normalized: nan - val_loss: 1.0469 - val_acc: 0.6340 - val_gini_normalized: nan\n",
      "Epoch 2/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.9591 - acc: 0.6844 - gini_normalized: nan - val_loss: 0.8799 - val_acc: 0.7520 - val_gini_normalized: nan\n",
      "Epoch 3/150\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.8195 - acc: 0.7576 - gini_normalized: nan - val_loss: 0.7709 - val_acc: 0.7540 - val_gini_normalized: nan\n",
      "Epoch 4/150\n",
      "2500/2500 [==============================] - 0s 85us/step - loss: 0.7318 - acc: 0.7732 - gini_normalized: nan - val_loss: 0.7095 - val_acc: 0.7080 - val_gini_normalized: nan\n",
      "Epoch 5/150\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.6812 - acc: 0.7724 - gini_normalized: nan - val_loss: 0.6735 - val_acc: 0.7760 - val_gini_normalized: nan\n",
      "Epoch 6/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.6534 - acc: 0.7956 - gini_normalized: nan - val_loss: 0.6498 - val_acc: 0.8260 - val_gini_normalized: nan\n",
      "Epoch 7/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.6379 - acc: 0.8108 - gini_normalized: nan - val_loss: 0.6371 - val_acc: 0.8200 - val_gini_normalized: nan\n",
      "Epoch 8/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.6267 - acc: 0.8156 - gini_normalized: nan - val_loss: 0.6279 - val_acc: 0.8180 - val_gini_normalized: nan\n",
      "Epoch 9/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.6186 - acc: 0.8188 - gini_normalized: nan - val_loss: 0.6244 - val_acc: 0.7740 - val_gini_normalized: nan\n",
      "Epoch 10/150\n",
      "2500/2500 [==============================] - 0s 85us/step - loss: 0.6106 - acc: 0.8168 - gini_normalized: nan - val_loss: 0.6150 - val_acc: 0.8260 - val_gini_normalized: nan\n",
      "Epoch 11/150\n",
      "2500/2500 [==============================] - 0s 90us/step - loss: 0.6034 - acc: 0.8276 - gini_normalized: nan - val_loss: 0.6054 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 12/150\n",
      "2500/2500 [==============================] - 0s 93us/step - loss: 0.5967 - acc: 0.8248 - gini_normalized: nan - val_loss: 0.6002 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 13/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.5898 - acc: 0.8348 - gini_normalized: nan - val_loss: 0.6010 - val_acc: 0.8080 - val_gini_normalized: nan\n",
      "Epoch 14/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.5831 - acc: 0.8360 - gini_normalized: nan - val_loss: 0.5957 - val_acc: 0.8060 - val_gini_normalized: nan\n",
      "Epoch 15/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.5774 - acc: 0.8368 - gini_normalized: nan - val_loss: 0.5847 - val_acc: 0.8140 - val_gini_normalized: nan\n",
      "Epoch 16/150\n",
      "2500/2500 [==============================] - 0s 79us/step - loss: 0.5700 - acc: 0.8416 - gini_normalized: nan - val_loss: 0.5839 - val_acc: 0.8100 - val_gini_normalized: nan\n",
      "Epoch 17/150\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.5659 - acc: 0.8408 - gini_normalized: nan - val_loss: 0.5783 - val_acc: 0.8220 - val_gini_normalized: nan\n",
      "Epoch 18/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.5600 - acc: 0.8452 - gini_normalized: nan - val_loss: 0.5685 - val_acc: 0.8260 - val_gini_normalized: nan\n",
      "Epoch 19/150\n",
      "2500/2500 [==============================] - 0s 79us/step - loss: 0.5537 - acc: 0.8452 - gini_normalized: nan - val_loss: 0.5611 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 20/150\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.5487 - acc: 0.8536 - gini_normalized: nan - val_loss: 0.5553 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 21/150\n",
      "2500/2500 [==============================] - 0s 84us/step - loss: 0.5436 - acc: 0.8464 - gini_normalized: nan - val_loss: 0.5516 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 22/150\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.5381 - acc: 0.8568 - gini_normalized: nan - val_loss: 0.5466 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 23/150\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.5339 - acc: 0.8536 - gini_normalized: nan - val_loss: 0.5389 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 24/150\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.5292 - acc: 0.8580 - gini_normalized: nan - val_loss: 0.5440 - val_acc: 0.8200 - val_gini_normalized: nan\n",
      "Epoch 25/150\n",
      "2500/2500 [==============================] - 0s 91us/step - loss: 0.5263 - acc: 0.8572 - gini_normalized: nan - val_loss: 0.5371 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 26/150\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.5222 - acc: 0.8560 - gini_normalized: nan - val_loss: 0.5429 - val_acc: 0.8120 - val_gini_normalized: nan\n",
      "Epoch 27/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.5182 - acc: 0.8512 - gini_normalized: nan - val_loss: 0.5357 - val_acc: 0.8160 - val_gini_normalized: nan\n",
      "Epoch 28/150\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.5150 - acc: 0.8584 - gini_normalized: nan - val_loss: 0.5295 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 29/150\n",
      "2500/2500 [==============================] - 0s 107us/step - loss: 0.5115 - acc: 0.8512 - gini_normalized: nan - val_loss: 0.5229 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 30/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.5071 - acc: 0.8564 - gini_normalized: nan - val_loss: 0.5192 - val_acc: 0.8520 - val_gini_normalized: nan\n",
      "Epoch 31/150\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.5036 - acc: 0.8588 - gini_normalized: nan - val_loss: 0.5130 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 32/150\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.5014 - acc: 0.8596 - gini_normalized: nan - val_loss: 0.5108 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 33/150\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.4977 - acc: 0.8600 - gini_normalized: nan - val_loss: 0.5258 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 34/150\n",
      "2500/2500 [==============================] - 0s 97us/step - loss: 0.4973 - acc: 0.8588 - gini_normalized: nan - val_loss: 0.5060 - val_acc: 0.8600 - val_gini_normalized: nan\n",
      "Epoch 35/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4939 - acc: 0.8592 - gini_normalized: nan - val_loss: 0.5118 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 36/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4904 - acc: 0.8652 - gini_normalized: nan - val_loss: 0.5074 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 37/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4881 - acc: 0.8592 - gini_normalized: nan - val_loss: 0.5054 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 38/150\n",
      "2500/2500 [==============================] - 0s 86us/step - loss: 0.4855 - acc: 0.8628 - gini_normalized: nan - val_loss: 0.5016 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 39/150\n",
      "2500/2500 [==============================] - 0s 103us/step - loss: 0.4841 - acc: 0.8660 - gini_normalized: nan - val_loss: 0.4975 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 40/150\n",
      "2500/2500 [==============================] - 0s 107us/step - loss: 0.4812 - acc: 0.8644 - gini_normalized: nan - val_loss: 0.4954 - val_acc: 0.8560 - val_gini_normalized: nan\n",
      "Epoch 41/150\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.4784 - acc: 0.8616 - gini_normalized: nan - val_loss: 0.5008 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 42/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4779 - acc: 0.8680 - gini_normalized: nan - val_loss: 0.5018 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 43/150\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4757 - acc: 0.8676 - gini_normalized: nan - val_loss: 0.4893 - val_acc: 0.8560 - val_gini_normalized: nan\n",
      "Epoch 44/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 96us/step - loss: 0.4732 - acc: 0.8656 - gini_normalized: nan - val_loss: 0.4943 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 45/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4710 - acc: 0.8680 - gini_normalized: nan - val_loss: 0.4807 - val_acc: 0.8600 - val_gini_normalized: nan\n",
      "Epoch 46/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4700 - acc: 0.8668 - gini_normalized: nan - val_loss: 0.4878 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 47/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4693 - acc: 0.8664 - gini_normalized: nan - val_loss: 0.4823 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 48/150\n",
      "2500/2500 [==============================] - 0s 84us/step - loss: 0.4680 - acc: 0.8628 - gini_normalized: nan - val_loss: 0.4858 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 49/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4655 - acc: 0.8648 - gini_normalized: nan - val_loss: 0.4752 - val_acc: 0.8580 - val_gini_normalized: nan\n",
      "Epoch 50/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4641 - acc: 0.8664 - gini_normalized: nan - val_loss: 0.4780 - val_acc: 0.8580 - val_gini_normalized: nan\n",
      "Epoch 51/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4634 - acc: 0.8680 - gini_normalized: nan - val_loss: 0.4736 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 52/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4619 - acc: 0.8716 - gini_normalized: nan - val_loss: 0.4773 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 53/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4610 - acc: 0.8660 - gini_normalized: nan - val_loss: 0.4773 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 54/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4583 - acc: 0.8708 - gini_normalized: nan - val_loss: 0.4720 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 55/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4584 - acc: 0.8704 - gini_normalized: nan - val_loss: 0.4913 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 56/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.4574 - acc: 0.8676 - gini_normalized: nan - val_loss: 0.4706 - val_acc: 0.8560 - val_gini_normalized: nan\n",
      "Epoch 57/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4558 - acc: 0.8680 - gini_normalized: nan - val_loss: 0.5044 - val_acc: 0.8180 - val_gini_normalized: nan\n",
      "Epoch 58/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4549 - acc: 0.8712 - gini_normalized: nan - val_loss: 0.4752 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 59/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4536 - acc: 0.8696 - gini_normalized: nan - val_loss: 0.4875 - val_acc: 0.8220 - val_gini_normalized: nan\n",
      "Epoch 60/150\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4516 - acc: 0.8684 - gini_normalized: nan - val_loss: 0.4792 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 61/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4521 - acc: 0.8716 - gini_normalized: nan - val_loss: 0.4647 - val_acc: 0.8600 - val_gini_normalized: nan\n",
      "Epoch 62/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4493 - acc: 0.8700 - gini_normalized: nan - val_loss: 0.4629 - val_acc: 0.8700 - val_gini_normalized: nan\n",
      "Epoch 63/150\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4475 - acc: 0.8768 - gini_normalized: nan - val_loss: 0.4705 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 64/150\n",
      "2500/2500 [==============================] - 0s 87us/step - loss: 0.4501 - acc: 0.8684 - gini_normalized: nan - val_loss: 0.4577 - val_acc: 0.8640 - val_gini_normalized: nan\n",
      "Epoch 65/150\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4471 - acc: 0.8724 - gini_normalized: nan - val_loss: 0.4605 - val_acc: 0.8640 - val_gini_normalized: nan\n",
      "Epoch 66/150\n",
      "2500/2500 [==============================] - 0s 91us/step - loss: 0.4462 - acc: 0.8688 - gini_normalized: nan - val_loss: 0.4591 - val_acc: 0.8640 - val_gini_normalized: nan\n",
      "Epoch 67/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.4446 - acc: 0.8708 - gini_normalized: nan - val_loss: 0.4776 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 68/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4449 - acc: 0.8740 - gini_normalized: nan - val_loss: 0.4572 - val_acc: 0.8660 - val_gini_normalized: nan\n",
      "Epoch 69/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4432 - acc: 0.8728 - gini_normalized: nan - val_loss: 0.4758 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 70/150\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.4434 - acc: 0.8704 - gini_normalized: nan - val_loss: 0.4575 - val_acc: 0.8620 - val_gini_normalized: nan\n",
      "Epoch 71/150\n",
      "2500/2500 [==============================] - 0s 85us/step - loss: 0.4416 - acc: 0.8716 - gini_normalized: nan - val_loss: 0.4581 - val_acc: 0.8640 - val_gini_normalized: nan\n",
      "Epoch 72/150\n",
      "2500/2500 [==============================] - 0s 79us/step - loss: 0.4406 - acc: 0.8716 - gini_normalized: nan - val_loss: 0.4576 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 73/150\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 0.4446 - acc: 0.8715 - gini_normalized: n - 0s 79us/step - loss: 0.4419 - acc: 0.8728 - gini_normalized: nan - val_loss: 0.4549 - val_acc: 0.8620 - val_gini_normalized: nan\n",
      "Epoch 74/150\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4393 - acc: 0.8732 - gini_normalized: nan - val_loss: 0.4639 - val_acc: 0.8620 - val_gini_normalized: nan\n",
      "Epoch 75/150\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4382 - acc: 0.8728 - gini_normalized: nan - val_loss: 0.4532 - val_acc: 0.8580 - val_gini_normalized: nan\n",
      "Epoch 76/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4385 - acc: 0.8764 - gini_normalized: nan - val_loss: 0.4594 - val_acc: 0.8520 - val_gini_normalized: nan\n",
      "Epoch 77/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4375 - acc: 0.8756 - gini_normalized: nan - val_loss: 0.4511 - val_acc: 0.8580 - val_gini_normalized: nan\n",
      "Epoch 78/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.4375 - acc: 0.8740 - gini_normalized: nan - val_loss: 0.4506 - val_acc: 0.8620 - val_gini_normalized: nan\n",
      "Epoch 79/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.4365 - acc: 0.8748 - gini_normalized: nan - val_loss: 0.4605 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 80/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4358 - acc: 0.8756 - gini_normalized: nan - val_loss: 0.4562 - val_acc: 0.8580 - val_gini_normalized: nan\n",
      "Epoch 81/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.4359 - acc: 0.8724 - gini_normalized: nan - val_loss: 0.4557 - val_acc: 0.8640 - val_gini_normalized: nan\n",
      "Epoch 82/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.4344 - acc: 0.8744 - gini_normalized: nan - val_loss: 0.4583 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 83/150\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.4347 - acc: 0.8752 - gini_normalized: nan - val_loss: 0.4627 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 84/150\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.4333 - acc: 0.8740 - gini_normalized: nan - val_loss: 0.4519 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 85/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4315 - acc: 0.8780 - gini_normalized: nan - val_loss: 0.4446 - val_acc: 0.8660 - val_gini_normalized: nan\n",
      "Epoch 86/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4316 - acc: 0.8732 - gini_normalized: nan - val_loss: 0.4733 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 87/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4332 - acc: 0.8712 - gini_normalized: nan - val_loss: 0.4516 - val_acc: 0.8720 - val_gini_normalized: nan\n",
      "Epoch 88/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4314 - acc: 0.8744 - gini_normalized: nan - val_loss: 0.4456 - val_acc: 0.8620 - val_gini_normalized: nan\n",
      "Epoch 89/150\n",
      "2500/2500 [==============================] - 0s 98us/step - loss: 0.4296 - acc: 0.8780 - gini_normalized: nan - val_loss: 0.4517 - val_acc: 0.8640 - val_gini_normalized: nan\n",
      "Epoch 90/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4293 - acc: 0.8780 - gini_normalized: nan - val_loss: 0.4444 - val_acc: 0.8660 - val_gini_normalized: nan\n",
      "Epoch 91/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4296 - acc: 0.8780 - gini_normalized: nan - val_loss: 0.4503 - val_acc: 0.8600 - val_gini_normalized: nan\n",
      "Epoch 92/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4291 - acc: 0.8756 - gini_normalized: nan - val_loss: 0.4440 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 93/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4260 - acc: 0.8796 - gini_normalized: nan - val_loss: 0.4506 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 94/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4277 - acc: 0.8732 - gini_normalized: nan - val_loss: 0.4397 - val_acc: 0.8600 - val_gini_normalized: nan\n",
      "Epoch 95/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4274 - acc: 0.8736 - gini_normalized: nan - val_loss: 0.4474 - val_acc: 0.8600 - val_gini_normalized: nan\n",
      "Epoch 96/150\n",
      "2500/2500 [==============================] - 0s 53us/step - loss: 0.4242 - acc: 0.8760 - gini_normalized: nan - val_loss: 0.4439 - val_acc: 0.8660 - val_gini_normalized: nan\n",
      "Epoch 97/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4258 - acc: 0.8760 - gini_normalized: nan - val_loss: 0.4595 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 98/150\n",
      "2500/2500 [==============================] - 0s 53us/step - loss: 0.4248 - acc: 0.8764 - gini_normalized: nan - val_loss: 0.4365 - val_acc: 0.8640 - val_gini_normalized: nan\n",
      "Epoch 99/150\n",
      "2500/2500 [==============================] - 0s 92us/step - loss: 0.4234 - acc: 0.8796 - gini_normalized: nan - val_loss: 0.4382 - val_acc: 0.8660 - val_gini_normalized: nan\n",
      "Epoch 100/150\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.4233 - acc: 0.8816 - gini_normalized: nan - val_loss: 0.4635 - val_acc: 0.8520 - val_gini_normalized: nan\n",
      "Epoch 101/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4236 - acc: 0.8804 - gini_normalized: nan - val_loss: 0.4586 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 102/150\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4219 - acc: 0.8752 - gini_normalized: nan - val_loss: 0.4395 - val_acc: 0.8600 - val_gini_normalized: nan\n",
      "Epoch 103/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4224 - acc: 0.8772 - gini_normalized: nan - val_loss: 0.4445 - val_acc: 0.8680 - val_gini_normalized: nan\n",
      "Epoch 104/150\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.4214 - acc: 0.8792 - gini_normalized: nan - val_loss: 0.5077 - val_acc: 0.8080 - val_gini_normalized: nan\n",
      "Epoch 105/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4232 - acc: 0.8772 - gini_normalized: nan - val_loss: 0.4431 - val_acc: 0.8640 - val_gini_normalized: nan\n",
      "Epoch 106/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.4212 - acc: 0.8784 - gini_normalized: nan - val_loss: 0.4580 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 107/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4195 - acc: 0.8788 - gini_normalized: nan - val_loss: 0.4405 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 108/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4190 - acc: 0.8788 - gini_normalized: nan - val_loss: 0.4424 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 109/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.4184 - acc: 0.8780 - gini_normalized: nan - val_loss: 0.4547 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 110/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4177 - acc: 0.8824 - gini_normalized: nan - val_loss: 0.4709 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 111/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.4188 - acc: 0.8776 - gini_normalized: nan - val_loss: 0.4436 - val_acc: 0.8640 - val_gini_normalized: nan\n",
      "Epoch 112/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4182 - acc: 0.8792 - gini_normalized: nan - val_loss: 0.4551 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 113/150\n",
      "2500/2500 [==============================] - 0s 51us/step - loss: 0.4193 - acc: 0.8740 - gini_normalized: nan - val_loss: 0.4815 - val_acc: 0.8260 - val_gini_normalized: nan\n",
      "Epoch 114/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4164 - acc: 0.8804 - gini_normalized: nan - val_loss: 0.4399 - val_acc: 0.8520 - val_gini_normalized: nan\n",
      "Epoch 115/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.4159 - acc: 0.8788 - gini_normalized: nan - val_loss: 0.4388 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 116/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4169 - acc: 0.8792 - gini_normalized: nan - val_loss: 0.4426 - val_acc: 0.8580 - val_gini_normalized: nan\n",
      "Epoch 117/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4157 - acc: 0.8792 - gini_normalized: nan - val_loss: 0.4283 - val_acc: 0.8700 - val_gini_normalized: nan\n",
      "Epoch 118/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4161 - acc: 0.8776 - gini_normalized: nan - val_loss: 0.4515 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 119/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4164 - acc: 0.8792 - gini_normalized: nan - val_loss: 0.4480 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 120/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.4140 - acc: 0.8808 - gini_normalized: nan - val_loss: 0.4891 - val_acc: 0.8180 - val_gini_normalized: nan\n",
      "Epoch 121/150\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.4135 - acc: 0.8792 - gini_normalized: nan - val_loss: 0.4490 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 122/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.4144 - acc: 0.8808 - gini_normalized: nan - val_loss: 0.4525 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 123/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.4153 - acc: 0.8788 - gini_normalized: nan - val_loss: 0.4415 - val_acc: 0.8700 - val_gini_normalized: nan\n",
      "Epoch 124/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.4132 - acc: 0.8764 - gini_normalized: nan - val_loss: 0.4321 - val_acc: 0.8640 - val_gini_normalized: nan\n",
      "Epoch 125/150\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4120 - acc: 0.8800 - gini_normalized: nan - val_loss: 0.4600 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 126/150\n",
      "2500/2500 [==============================] - 0s 86us/step - loss: 0.4117 - acc: 0.8812 - gini_normalized: nan - val_loss: 0.5120 - val_acc: 0.8020 - val_gini_normalized: nan\n",
      "Epoch 127/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4150 - acc: 0.8808 - gini_normalized: nan - val_loss: 0.4308 - val_acc: 0.8660 - val_gini_normalized: nan\n",
      "Epoch 128/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4109 - acc: 0.8804 - gini_normalized: nan - val_loss: 0.4342 - val_acc: 0.8620 - val_gini_normalized: nan\n",
      "Epoch 129/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4119 - acc: 0.8804 - gini_normalized: nan - val_loss: 0.4222 - val_acc: 0.8780 - val_gini_normalized: nan\n",
      "Epoch 130/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4100 - acc: 0.8756 - gini_normalized: nan - val_loss: 0.4367 - val_acc: 0.8560 - val_gini_normalized: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4114 - acc: 0.8812 - gini_normalized: nan - val_loss: 0.4434 - val_acc: 0.8580 - val_gini_normalized: nan\n",
      "Epoch 132/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.4094 - acc: 0.8836 - gini_normalized: nan - val_loss: 0.4388 - val_acc: 0.8580 - val_gini_normalized: nan\n",
      "Epoch 133/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4095 - acc: 0.8816 - gini_normalized: nan - val_loss: 0.4362 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 134/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4106 - acc: 0.8824 - gini_normalized: nan - val_loss: 0.4299 - val_acc: 0.8580 - val_gini_normalized: nan\n",
      "Epoch 135/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4091 - acc: 0.8800 - gini_normalized: nan - val_loss: 0.4291 - val_acc: 0.8680 - val_gini_normalized: nan\n",
      "Epoch 136/150\n",
      "2500/2500 [==============================] - 0s 89us/step - loss: 0.4090 - acc: 0.8796 - gini_normalized: nan - val_loss: 0.4657 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 137/150\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.4112 - acc: 0.8772 - gini_normalized: nan - val_loss: 0.4206 - val_acc: 0.8700 - val_gini_normalized: nan\n",
      "Epoch 138/150\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.4071 - acc: 0.8828 - gini_normalized: nan - val_loss: 0.4508 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 139/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4077 - acc: 0.8824 - gini_normalized: nan - val_loss: 0.4220 - val_acc: 0.8680 - val_gini_normalized: nan\n",
      "Epoch 140/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.4080 - acc: 0.8776 - gini_normalized: nan - val_loss: 0.4267 - val_acc: 0.8660 - val_gini_normalized: nan\n",
      "Epoch 141/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4059 - acc: 0.8860 - gini_normalized: nan - val_loss: 0.4382 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 142/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4062 - acc: 0.8808 - gini_normalized: nan - val_loss: 0.4213 - val_acc: 0.8660 - val_gini_normalized: nan\n",
      "Epoch 143/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4071 - acc: 0.8828 - gini_normalized: nan - val_loss: 0.4423 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 144/150\n",
      "2500/2500 [==============================] - 0s 91us/step - loss: 0.4064 - acc: 0.8796 - gini_normalized: nan - val_loss: 0.4191 - val_acc: 0.8780 - val_gini_normalized: nan\n",
      "Epoch 145/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.4046 - acc: 0.8792 - gini_normalized: nan - val_loss: 0.4219 - val_acc: 0.8640 - val_gini_normalized: nan\n",
      "Epoch 146/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.4057 - acc: 0.8808 - gini_normalized: nan - val_loss: 0.4521 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 147/150\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.4051 - acc: 0.8768 - gini_normalized: nan - val_loss: 0.4260 - val_acc: 0.8640 - val_gini_normalized: nan\n",
      "Epoch 148/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.4051 - acc: 0.8816 - gini_normalized: nan - val_loss: 0.4617 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 149/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.4038 - acc: 0.8784 - gini_normalized: nan - val_loss: 0.4244 - val_acc: 0.8700 - val_gini_normalized: nan\n",
      "Epoch 150/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4050 - acc: 0.8800 - gini_normalized: nan - val_loss: 0.4170 - val_acc: 0.8720 - val_gini_normalized: nan\n",
      "500/500 [==============================] - 0s 56us/step\n",
      "Train on 2500 samples, validate on 500 samples\n",
      "Epoch 1/150\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.2490 - acc: 0.6692 - gini_normalized: nan - val_loss: 1.0923 - val_acc: 0.6860 - val_gini_normalized: nan\n",
      "Epoch 2/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.9902 - acc: 0.6976 - gini_normalized: nan - val_loss: 0.8996 - val_acc: 0.7080 - val_gini_normalized: nan\n",
      "Epoch 3/150\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.8308 - acc: 0.7232 - gini_normalized: nan - val_loss: 0.7749 - val_acc: 0.6940 - val_gini_normalized: nan\n",
      "Epoch 4/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.7299 - acc: 0.7272 - gini_normalized: nan - val_loss: 0.6980 - val_acc: 0.7040 - val_gini_normalized: nan\n",
      "Epoch 5/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.6708 - acc: 0.7404 - gini_normalized: nan - val_loss: 0.6546 - val_acc: 0.7460 - val_gini_normalized: nan\n",
      "Epoch 6/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.6376 - acc: 0.7616 - gini_normalized: nan - val_loss: 0.6291 - val_acc: 0.7620 - val_gini_normalized: nan\n",
      "Epoch 7/150\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.6160 - acc: 0.7708 - gini_normalized: nan - val_loss: 0.6157 - val_acc: 0.7560 - val_gini_normalized: nan\n",
      "Epoch 8/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.6021 - acc: 0.7784 - gini_normalized: nan - val_loss: 0.6091 - val_acc: 0.7400 - val_gini_normalized: nan\n",
      "Epoch 9/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.5922 - acc: 0.7872 - gini_normalized: nan - val_loss: 0.5977 - val_acc: 0.7980 - val_gini_normalized: nan\n",
      "Epoch 10/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.5843 - acc: 0.7936 - gini_normalized: nan - val_loss: 0.6057 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 11/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.5792 - acc: 0.7944 - gini_normalized: nan - val_loss: 0.5906 - val_acc: 0.7520 - val_gini_normalized: nan\n",
      "Epoch 12/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.5724 - acc: 0.7904 - gini_normalized: nan - val_loss: 0.5783 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 13/150\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.5673 - acc: 0.7940 - gini_normalized: nan - val_loss: 0.5753 - val_acc: 0.7800 - val_gini_normalized: nan\n",
      "Epoch 14/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.5627 - acc: 0.7984 - gini_normalized: nan - val_loss: 0.5735 - val_acc: 0.7780 - val_gini_normalized: nan\n",
      "Epoch 15/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.5577 - acc: 0.7968 - gini_normalized: nan - val_loss: 0.5693 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 16/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.5526 - acc: 0.7980 - gini_normalized: nan - val_loss: 0.5650 - val_acc: 0.7780 - val_gini_normalized: nan\n",
      "Epoch 17/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.5501 - acc: 0.7976 - gini_normalized: nan - val_loss: 0.5643 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 18/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.5457 - acc: 0.8020 - gini_normalized: nan - val_loss: 0.5553 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 19/150\n",
      "2500/2500 [==============================] - 0s 52us/step - loss: 0.5426 - acc: 0.8000 - gini_normalized: nan - val_loss: 0.5523 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 20/150\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.5404 - acc: 0.8012 - gini_normalized: nan - val_loss: 0.5545 - val_acc: 0.7760 - val_gini_normalized: nan\n",
      "Epoch 21/150\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.5371 - acc: 0.8040 - gini_normalized: nan - val_loss: 0.5499 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 22/150\n",
      "2500/2500 [==============================] - 0s 52us/step - loss: 0.5337 - acc: 0.8024 - gini_normalized: nan - val_loss: 0.5623 - val_acc: 0.7980 - val_gini_normalized: nan\n",
      "Epoch 23/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.5294 - acc: 0.8116 - gini_normalized: nan - val_loss: 0.5531 - val_acc: 0.7760 - val_gini_normalized: nan\n",
      "Epoch 24/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.5282 - acc: 0.8064 - gini_normalized: nan - val_loss: 0.5584 - val_acc: 0.7640 - val_gini_normalized: nan\n",
      "Epoch 25/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.5275 - acc: 0.8080 - gini_normalized: nan - val_loss: 0.5487 - val_acc: 0.8020 - val_gini_normalized: nan\n",
      "Epoch 26/150\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.5235 - acc: 0.8060 - gini_normalized: nan - val_loss: 0.5563 - val_acc: 0.7620 - val_gini_normalized: nan\n",
      "Epoch 27/150\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.5234 - acc: 0.8080 - gini_normalized: nan - val_loss: 0.5395 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 28/150\n",
      "2500/2500 [==============================] - 0s 88us/step - loss: 0.5210 - acc: 0.8104 - gini_normalized: nan - val_loss: 0.5357 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 29/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.5195 - acc: 0.8076 - gini_normalized: nan - val_loss: 0.5804 - val_acc: 0.7780 - val_gini_normalized: nan\n",
      "Epoch 30/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.5208 - acc: 0.8136 - gini_normalized: nan - val_loss: 0.5396 - val_acc: 0.7780 - val_gini_normalized: nan\n",
      "Epoch 31/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.5152 - acc: 0.8068 - gini_normalized: nan - val_loss: 0.5489 - val_acc: 0.8000 - val_gini_normalized: nan\n",
      "Epoch 32/150\n",
      "2500/2500 [==============================] - 0s 86us/step - loss: 0.5150 - acc: 0.8076 - gini_normalized: nan - val_loss: 0.5426 - val_acc: 0.8000 - val_gini_normalized: nan\n",
      "Epoch 33/150\n",
      "2500/2500 [==============================] - 0s 94us/step - loss: 0.5122 - acc: 0.8128 - gini_normalized: nan - val_loss: 0.5357 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 34/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.5122 - acc: 0.8024 - gini_normalized: nan - val_loss: 0.5321 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 35/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.5099 - acc: 0.8104 - gini_normalized: nan - val_loss: 0.5309 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 36/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.5083 - acc: 0.8084 - gini_normalized: nan - val_loss: 0.5380 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 37/150\n",
      "2500/2500 [==============================] - 0s 86us/step - loss: 0.5070 - acc: 0.8116 - gini_normalized: nan - val_loss: 0.5384 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 38/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.5064 - acc: 0.8108 - gini_normalized: nan - val_loss: 0.5309 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 39/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.5043 - acc: 0.8052 - gini_normalized: nan - val_loss: 0.5235 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 40/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.5027 - acc: 0.8116 - gini_normalized: nan - val_loss: 0.5238 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 41/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.5020 - acc: 0.8076 - gini_normalized: nan - val_loss: 0.5250 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 42/150\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.5005 - acc: 0.8092 - gini_normalized: nan - val_loss: 0.5485 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 43/150\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.5005 - acc: 0.8084 - gini_normalized: nan - val_loss: 0.5211 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 44/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4978 - acc: 0.8152 - gini_normalized: nan - val_loss: 0.5235 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 45/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4973 - acc: 0.8156 - gini_normalized: nan - val_loss: 0.5286 - val_acc: 0.7760 - val_gini_normalized: nan\n",
      "Epoch 46/150\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.4963 - acc: 0.8112 - gini_normalized: nan - val_loss: 0.5163 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 47/150\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4943 - acc: 0.8096 - gini_normalized: nan - val_loss: 0.5177 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 48/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4936 - acc: 0.8120 - gini_normalized: nan - val_loss: 0.5269 - val_acc: 0.7760 - val_gini_normalized: nan\n",
      "Epoch 49/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4933 - acc: 0.8120 - gini_normalized: nan - val_loss: 0.5216 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 50/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4919 - acc: 0.8072 - gini_normalized: nan - val_loss: 0.5141 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 51/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.4898 - acc: 0.8104 - gini_normalized: nan - val_loss: 0.5128 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 52/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.4904 - acc: 0.8120 - gini_normalized: nan - val_loss: 0.5313 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 53/150\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.4900 - acc: 0.8140 - gini_normalized: nan - val_loss: 0.5106 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 54/150\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.4887 - acc: 0.8112 - gini_normalized: nan - val_loss: 0.5166 - val_acc: 0.8020 - val_gini_normalized: nan\n",
      "Epoch 55/150\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.4859 - acc: 0.8140 - gini_normalized: nan - val_loss: 0.5093 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 56/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4847 - acc: 0.8156 - gini_normalized: nan - val_loss: 0.5176 - val_acc: 0.8020 - val_gini_normalized: nan\n",
      "Epoch 57/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.4856 - acc: 0.8172 - gini_normalized: nan - val_loss: 0.5265 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 58/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4844 - acc: 0.8140 - gini_normalized: nan - val_loss: 0.5106 - val_acc: 0.7800 - val_gini_normalized: nan\n",
      "Epoch 59/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4821 - acc: 0.8160 - gini_normalized: nan - val_loss: 0.5141 - val_acc: 0.7720 - val_gini_normalized: nan\n",
      "Epoch 60/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4823 - acc: 0.8128 - gini_normalized: nan - val_loss: 0.5134 - val_acc: 0.8020 - val_gini_normalized: nan\n",
      "Epoch 61/150\n",
      "2500/2500 [==============================] - 0s 87us/step - loss: 0.4816 - acc: 0.8144 - gini_normalized: nan - val_loss: 0.5100 - val_acc: 0.7980 - val_gini_normalized: nan\n",
      "Epoch 62/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4807 - acc: 0.8108 - gini_normalized: nan - val_loss: 0.5102 - val_acc: 0.8000 - val_gini_normalized: nan\n",
      "Epoch 63/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.4794 - acc: 0.8088 - gini_normalized: nan - val_loss: 0.5171 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 64/150\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4791 - acc: 0.8164 - gini_normalized: nan - val_loss: 0.5094 - val_acc: 0.7980 - val_gini_normalized: nan\n",
      "Epoch 65/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4782 - acc: 0.8160 - gini_normalized: nan - val_loss: 0.5005 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 66/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.4771 - acc: 0.8128 - gini_normalized: nan - val_loss: 0.5166 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 67/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4773 - acc: 0.8104 - gini_normalized: nan - val_loss: 0.5062 - val_acc: 0.7940 - val_gini_normalized: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.4755 - acc: 0.8132 - gini_normalized: nan - val_loss: 0.5070 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 69/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.4734 - acc: 0.8140 - gini_normalized: nan - val_loss: 0.5058 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 70/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.4722 - acc: 0.8168 - gini_normalized: nan - val_loss: 0.5044 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 71/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4715 - acc: 0.8104 - gini_normalized: nan - val_loss: 0.5218 - val_acc: 0.8080 - val_gini_normalized: nan\n",
      "Epoch 72/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4719 - acc: 0.8164 - gini_normalized: nan - val_loss: 0.5004 - val_acc: 0.7800 - val_gini_normalized: nan\n",
      "Epoch 73/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.4704 - acc: 0.8148 - gini_normalized: nan - val_loss: 0.5029 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 74/150\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4697 - acc: 0.8136 - gini_normalized: nan - val_loss: 0.5020 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 75/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4691 - acc: 0.8176 - gini_normalized: nan - val_loss: 0.4930 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 76/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.4670 - acc: 0.8184 - gini_normalized: nan - val_loss: 0.4942 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 77/150\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4663 - acc: 0.8180 - gini_normalized: nan - val_loss: 0.5031 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 78/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4676 - acc: 0.8196 - gini_normalized: nan - val_loss: 0.5044 - val_acc: 0.8040 - val_gini_normalized: nan\n",
      "Epoch 79/150\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4653 - acc: 0.8268 - gini_normalized: nan - val_loss: 0.4905 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 80/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4652 - acc: 0.8192 - gini_normalized: nan - val_loss: 0.4914 - val_acc: 0.8060 - val_gini_normalized: nan\n",
      "Epoch 81/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4652 - acc: 0.8164 - gini_normalized: nan - val_loss: 0.4934 - val_acc: 0.8060 - val_gini_normalized: nan\n",
      "Epoch 82/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.4635 - acc: 0.8208 - gini_normalized: nan - val_loss: 0.4924 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 83/150\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4640 - acc: 0.8204 - gini_normalized: nan - val_loss: 0.4983 - val_acc: 0.7800 - val_gini_normalized: nan\n",
      "Epoch 84/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4643 - acc: 0.8120 - gini_normalized: nan - val_loss: 0.4940 - val_acc: 0.7760 - val_gini_normalized: nan\n",
      "Epoch 85/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4622 - acc: 0.8156 - gini_normalized: nan - val_loss: 0.4859 - val_acc: 0.8040 - val_gini_normalized: nan\n",
      "Epoch 86/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4608 - acc: 0.8220 - gini_normalized: nan - val_loss: 0.4929 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 87/150\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.4615 - acc: 0.8212 - gini_normalized: nan - val_loss: 0.4895 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 88/150\n",
      "2500/2500 [==============================] - 0s 90us/step - loss: 0.4607 - acc: 0.8192 - gini_normalized: nan - val_loss: 0.4938 - val_acc: 0.7720 - val_gini_normalized: nan\n",
      "Epoch 89/150\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4602 - acc: 0.8176 - gini_normalized: nan - val_loss: 0.4860 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 90/150\n",
      "2500/2500 [==============================] - 0s 52us/step - loss: 0.4585 - acc: 0.8228 - gini_normalized: nan - val_loss: 0.4836 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 91/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.4579 - acc: 0.8224 - gini_normalized: nan - val_loss: 0.4850 - val_acc: 0.8040 - val_gini_normalized: nan\n",
      "Epoch 92/150\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.4576 - acc: 0.8184 - gini_normalized: nan - val_loss: 0.4829 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 93/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4573 - acc: 0.8244 - gini_normalized: nan - val_loss: 0.4857 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 94/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4567 - acc: 0.8228 - gini_normalized: nan - val_loss: 0.4858 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 95/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4564 - acc: 0.8232 - gini_normalized: nan - val_loss: 0.4926 - val_acc: 0.8100 - val_gini_normalized: nan\n",
      "Epoch 96/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4547 - acc: 0.8240 - gini_normalized: nan - val_loss: 0.4836 - val_acc: 0.8120 - val_gini_normalized: nan\n",
      "Epoch 97/150\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4549 - acc: 0.8236 - gini_normalized: nan - val_loss: 0.4779 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 98/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4547 - acc: 0.8252 - gini_normalized: nan - val_loss: 0.4819 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 99/150\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4541 - acc: 0.8176 - gini_normalized: nan - val_loss: 0.4847 - val_acc: 0.8020 - val_gini_normalized: nan\n",
      "Epoch 100/150\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4538 - acc: 0.8272 - gini_normalized: nan - val_loss: 0.4777 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 101/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4531 - acc: 0.8208 - gini_normalized: nan - val_loss: 0.4777 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 102/150\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.4512 - acc: 0.8264 - gini_normalized: nan - val_loss: 0.4795 - val_acc: 0.8120 - val_gini_normalized: nan\n",
      "Epoch 103/150\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4502 - acc: 0.8248 - gini_normalized: nan - val_loss: 0.4869 - val_acc: 0.7980 - val_gini_normalized: nan\n",
      "Epoch 104/150\n",
      "2500/2500 [==============================] - 0s 84us/step - loss: 0.4503 - acc: 0.8256 - gini_normalized: nan - val_loss: 0.4783 - val_acc: 0.8060 - val_gini_normalized: nan\n",
      "Epoch 105/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4502 - acc: 0.8260 - gini_normalized: nan - val_loss: 0.4807 - val_acc: 0.8060 - val_gini_normalized: nan\n",
      "Epoch 106/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4486 - acc: 0.8236 - gini_normalized: nan - val_loss: 0.4815 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 107/150\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.4477 - acc: 0.8272 - gini_normalized: nan - val_loss: 0.4944 - val_acc: 0.8220 - val_gini_normalized: nan\n",
      "Epoch 108/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4487 - acc: 0.8272 - gini_normalized: nan - val_loss: 0.4738 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 109/150\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.4477 - acc: 0.8284 - gini_normalized: nan - val_loss: 0.4732 - val_acc: 0.8000 - val_gini_normalized: nan\n",
      "Epoch 110/150\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4463 - acc: 0.8324 - gini_normalized: nan - val_loss: 0.4736 - val_acc: 0.8080 - val_gini_normalized: nan\n",
      "Epoch 111/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4462 - acc: 0.8288 - gini_normalized: nan - val_loss: 0.4718 - val_acc: 0.8040 - val_gini_normalized: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/150\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.4440 - acc: 0.8268 - gini_normalized: nan - val_loss: 0.4728 - val_acc: 0.8000 - val_gini_normalized: nan\n",
      "Epoch 113/150\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4425 - acc: 0.8296 - gini_normalized: nan - val_loss: 0.4702 - val_acc: 0.8060 - val_gini_normalized: nan\n",
      "Epoch 114/150\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.4425 - acc: 0.8280 - gini_normalized: nan - val_loss: 0.4769 - val_acc: 0.8180 - val_gini_normalized: nan\n",
      "Epoch 115/150\n",
      "2500/2500 [==============================] - 0s 53us/step - loss: 0.4404 - acc: 0.8312 - gini_normalized: nan - val_loss: 0.4728 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 116/150\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4392 - acc: 0.8336 - gini_normalized: nan - val_loss: 0.4671 - val_acc: 0.8060 - val_gini_normalized: nan\n",
      "Epoch 117/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4374 - acc: 0.8328 - gini_normalized: nan - val_loss: 0.4731 - val_acc: 0.8120 - val_gini_normalized: nan\n",
      "Epoch 118/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4380 - acc: 0.8328 - gini_normalized: nan - val_loss: 0.4676 - val_acc: 0.8060 - val_gini_normalized: nan\n",
      "Epoch 119/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4380 - acc: 0.8384 - gini_normalized: nan - val_loss: 0.4703 - val_acc: 0.8220 - val_gini_normalized: nan\n",
      "Epoch 120/150\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.4348 - acc: 0.8384 - gini_normalized: nan - val_loss: 0.4690 - val_acc: 0.8120 - val_gini_normalized: nan\n",
      "Epoch 121/150\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4349 - acc: 0.8328 - gini_normalized: nan - val_loss: 0.4685 - val_acc: 0.8120 - val_gini_normalized: nan\n",
      "Epoch 122/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4338 - acc: 0.8396 - gini_normalized: nan - val_loss: 0.4661 - val_acc: 0.8100 - val_gini_normalized: nan\n",
      "Epoch 123/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4313 - acc: 0.8400 - gini_normalized: nan - val_loss: 0.4813 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 124/150\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4311 - acc: 0.8440 - gini_normalized: nan - val_loss: 0.4640 - val_acc: 0.8220 - val_gini_normalized: nan\n",
      "Epoch 125/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4299 - acc: 0.8468 - gini_normalized: nan - val_loss: 0.4738 - val_acc: 0.7980 - val_gini_normalized: nan\n",
      "Epoch 126/150\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4294 - acc: 0.8408 - gini_normalized: nan - val_loss: 0.4649 - val_acc: 0.8080 - val_gini_normalized: nan\n",
      "Epoch 127/150\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4283 - acc: 0.8492 - gini_normalized: nan - val_loss: 0.4623 - val_acc: 0.8260 - val_gini_normalized: nan\n",
      "Epoch 128/150\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.4282 - acc: 0.8456 - gini_normalized: nan - val_loss: 0.4633 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 129/150\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4268 - acc: 0.8448 - gini_normalized: nan - val_loss: 0.4622 - val_acc: 0.8140 - val_gini_normalized: nan\n",
      "Epoch 130/150\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4243 - acc: 0.8500 - gini_normalized: nan - val_loss: 0.4653 - val_acc: 0.8100 - val_gini_normalized: nan\n",
      "Epoch 131/150\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.4242 - acc: 0.8532 - gini_normalized: nan - val_loss: 0.4926 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 132/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4216 - acc: 0.8552 - gini_normalized: nan - val_loss: 0.4642 - val_acc: 0.8140 - val_gini_normalized: nan\n",
      "Epoch 133/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4214 - acc: 0.8496 - gini_normalized: nan - val_loss: 0.4610 - val_acc: 0.8160 - val_gini_normalized: nan\n",
      "Epoch 134/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.4222 - acc: 0.8548 - gini_normalized: nan - val_loss: 0.4667 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 135/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4198 - acc: 0.8524 - gini_normalized: nan - val_loss: 0.4622 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 136/150\n",
      "2500/2500 [==============================] - 0s 119us/step - loss: 0.4176 - acc: 0.8580 - gini_normalized: nan - val_loss: 0.4561 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 137/150\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4172 - acc: 0.8600 - gini_normalized: nan - val_loss: 0.4593 - val_acc: 0.8100 - val_gini_normalized: nan\n",
      "Epoch 138/150\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4172 - acc: 0.8524 - gini_normalized: nan - val_loss: 0.4567 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 139/150\n",
      "2500/2500 [==============================] - 0s 88us/step - loss: 0.4159 - acc: 0.8592 - gini_normalized: nan - val_loss: 0.4570 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 140/150\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.4143 - acc: 0.8580 - gini_normalized: nan - val_loss: 0.4592 - val_acc: 0.8220 - val_gini_normalized: nan\n",
      "Epoch 141/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4129 - acc: 0.8600 - gini_normalized: nan - val_loss: 0.4584 - val_acc: 0.8260 - val_gini_normalized: nan\n",
      "Epoch 142/150\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4102 - acc: 0.8572 - gini_normalized: nan - val_loss: 0.4601 - val_acc: 0.8160 - val_gini_normalized: nan\n",
      "Epoch 143/150\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4094 - acc: 0.8612 - gini_normalized: nan - val_loss: 0.4622 - val_acc: 0.8160 - val_gini_normalized: nan\n",
      "Epoch 144/150\n",
      "2500/2500 [==============================] - 0s 85us/step - loss: 0.4077 - acc: 0.8640 - gini_normalized: nan - val_loss: 0.4578 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 145/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4083 - acc: 0.8684 - gini_normalized: nan - val_loss: 0.4546 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 146/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4032 - acc: 0.8684 - gini_normalized: nan - val_loss: 0.4796 - val_acc: 0.8060 - val_gini_normalized: nan\n",
      "Epoch 147/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4097 - acc: 0.8632 - gini_normalized: nan - val_loss: 0.4592 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 148/150\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.4052 - acc: 0.8688 - gini_normalized: nan - val_loss: 0.4529 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 149/150\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4033 - acc: 0.8656 - gini_normalized: nan - val_loss: 0.4548 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 150/150\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4031 - acc: 0.8700 - gini_normalized: nan - val_loss: 0.4453 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "500/500 [==============================] - 0s 45us/step\n",
      "Train on 2500 samples, validate on 500 samples\n",
      "Epoch 1/150\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5656 - acc: 0.5744 - gini_normalized: nan - val_loss: 1.3448 - val_acc: 0.7280 - val_gini_normalized: nan\n",
      "Epoch 2/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 1.1523 - acc: 0.7952 - gini_normalized: nan - val_loss: 1.0239 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 3/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.9283 - acc: 0.8388 - gini_normalized: nan - val_loss: 0.8759 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 4/150\n",
      "2500/2500 [==============================] - 0s 91us/step - loss: 0.8016 - acc: 0.8368 - gini_normalized: nan - val_loss: 0.7616 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 5/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 101us/step - loss: 0.7164 - acc: 0.8468 - gini_normalized: nan - val_loss: 0.7207 - val_acc: 0.8520 - val_gini_normalized: nan\n",
      "Epoch 6/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.6553 - acc: 0.8536 - gini_normalized: nan - val_loss: 0.6749 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 7/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.6170 - acc: 0.8568 - gini_normalized: nan - val_loss: 0.6223 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 8/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.6057 - acc: 0.8584 - gini_normalized: nan - val_loss: 0.5959 - val_acc: 0.8620 - val_gini_normalized: nan\n",
      "Epoch 9/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.5721 - acc: 0.8628 - gini_normalized: nan - val_loss: 0.5878 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 10/150\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.5690 - acc: 0.8676 - gini_normalized: nan - val_loss: 0.5632 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 11/150\n",
      "2500/2500 [==============================] - 0s 97us/step - loss: 0.5461 - acc: 0.8672 - gini_normalized: nan - val_loss: 0.5391 - val_acc: 0.8620 - val_gini_normalized: nan\n",
      "Epoch 12/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.5397 - acc: 0.8712 - gini_normalized: nan - val_loss: 0.5550 - val_acc: 0.8660 - val_gini_normalized: nan\n",
      "Epoch 13/150\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.5236 - acc: 0.8776 - gini_normalized: nan - val_loss: 0.5397 - val_acc: 0.8720 - val_gini_normalized: nan\n",
      "Epoch 14/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.5179 - acc: 0.8780 - gini_normalized: nan - val_loss: 0.5199 - val_acc: 0.8800 - val_gini_normalized: nan\n",
      "Epoch 15/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.5041 - acc: 0.8800 - gini_normalized: nan - val_loss: 0.4936 - val_acc: 0.8760 - val_gini_normalized: nan\n",
      "Epoch 16/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.5011 - acc: 0.8796 - gini_normalized: nan - val_loss: 0.5016 - val_acc: 0.8860 - val_gini_normalized: nan\n",
      "Epoch 17/150\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4855 - acc: 0.8824 - gini_normalized: nan - val_loss: 0.4884 - val_acc: 0.8980 - val_gini_normalized: nan\n",
      "Epoch 18/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4666 - acc: 0.8916 - gini_normalized: nan - val_loss: 0.4681 - val_acc: 0.9000 - val_gini_normalized: nan\n",
      "Epoch 19/150\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4622 - acc: 0.8928 - gini_normalized: nan - val_loss: 0.4891 - val_acc: 0.8920 - val_gini_normalized: nan\n",
      "Epoch 20/150\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4576 - acc: 0.8940 - gini_normalized: nan - val_loss: 0.4732 - val_acc: 0.9080 - val_gini_normalized: nan\n",
      "Epoch 21/150\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.4479 - acc: 0.8980 - gini_normalized: nan - val_loss: 0.4783 - val_acc: 0.9020 - val_gini_normalized: nan\n",
      "Epoch 22/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4490 - acc: 0.9008 - gini_normalized: nan - val_loss: 0.4578 - val_acc: 0.9140 - val_gini_normalized: nan\n",
      "Epoch 23/150\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.4416 - acc: 0.9012 - gini_normalized: nan - val_loss: 0.4250 - val_acc: 0.9200 - val_gini_normalized: nan\n",
      "Epoch 24/150\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.4295 - acc: 0.9068 - gini_normalized: nan - val_loss: 0.4277 - val_acc: 0.9260 - val_gini_normalized: nan\n",
      "Epoch 25/150\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4293 - acc: 0.9084 - gini_normalized: nan - val_loss: 0.4461 - val_acc: 0.9240 - val_gini_normalized: nan\n",
      "Epoch 26/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4131 - acc: 0.9108 - gini_normalized: nan - val_loss: 0.4200 - val_acc: 0.9320 - val_gini_normalized: nan\n",
      "Epoch 27/150\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.4229 - acc: 0.9128 - gini_normalized: nan - val_loss: 0.4063 - val_acc: 0.9200 - val_gini_normalized: nan\n",
      "Epoch 28/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4069 - acc: 0.9112 - gini_normalized: nan - val_loss: 0.4126 - val_acc: 0.9300 - val_gini_normalized: nan\n",
      "Epoch 29/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.3977 - acc: 0.9176 - gini_normalized: nan - val_loss: 0.4372 - val_acc: 0.9320 - val_gini_normalized: nan\n",
      "Epoch 30/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4025 - acc: 0.9160 - gini_normalized: nan - val_loss: 0.4205 - val_acc: 0.9140 - val_gini_normalized: nan\n",
      "Epoch 31/150\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.3859 - acc: 0.9168 - gini_normalized: nan - val_loss: 0.3924 - val_acc: 0.9020 - val_gini_normalized: nan\n",
      "Epoch 32/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.3810 - acc: 0.9184 - gini_normalized: nan - val_loss: 0.3572 - val_acc: 0.9320 - val_gini_normalized: nan\n",
      "Epoch 33/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.3804 - acc: 0.9196 - gini_normalized: nan - val_loss: 0.3797 - val_acc: 0.9340 - val_gini_normalized: nan\n",
      "Epoch 34/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.3709 - acc: 0.9196 - gini_normalized: nan - val_loss: 0.4093 - val_acc: 0.9180 - val_gini_normalized: nan\n",
      "Epoch 35/150\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.3636 - acc: 0.9276 - gini_normalized: nan - val_loss: 0.3774 - val_acc: 0.9360 - val_gini_normalized: nan\n",
      "Epoch 36/150\n",
      "2500/2500 [==============================] - 0s 94us/step - loss: 0.3681 - acc: 0.9220 - gini_normalized: nan - val_loss: 0.3882 - val_acc: 0.9300 - val_gini_normalized: nan\n",
      "Epoch 37/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3829 - acc: 0.9220 - gini_normalized: nan - val_loss: 0.3573 - val_acc: 0.9460 - val_gini_normalized: nan\n",
      "Epoch 38/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.3632 - acc: 0.9244 - gini_normalized: nan - val_loss: 0.3650 - val_acc: 0.9460 - val_gini_normalized: nan\n",
      "Epoch 39/150\n",
      "2500/2500 [==============================] - 0s 94us/step - loss: 0.3568 - acc: 0.9256 - gini_normalized: nan - val_loss: 0.3453 - val_acc: 0.9260 - val_gini_normalized: nan\n",
      "Epoch 40/150\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.3540 - acc: 0.9240 - gini_normalized: nan - val_loss: 0.3479 - val_acc: 0.9360 - val_gini_normalized: nan\n",
      "Epoch 41/150\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.3561 - acc: 0.9224 - gini_normalized: nan - val_loss: 0.3591 - val_acc: 0.9480 - val_gini_normalized: nan\n",
      "Epoch 42/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.3446 - acc: 0.9328 - gini_normalized: nan - val_loss: 0.3855 - val_acc: 0.9360 - val_gini_normalized: nan\n",
      "Epoch 43/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3553 - acc: 0.9256 - gini_normalized: nan - val_loss: 0.3432 - val_acc: 0.9400 - val_gini_normalized: nan\n",
      "Epoch 44/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.3473 - acc: 0.9316 - gini_normalized: nan - val_loss: 0.3491 - val_acc: 0.9460 - val_gini_normalized: nan\n",
      "Epoch 45/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.3388 - acc: 0.9340 - gini_normalized: nan - val_loss: 0.3783 - val_acc: 0.9080 - val_gini_normalized: nan\n",
      "Epoch 46/150\n",
      "2500/2500 [==============================] - 0s 85us/step - loss: 0.3372 - acc: 0.9280 - gini_normalized: nan - val_loss: 0.3349 - val_acc: 0.9240 - val_gini_normalized: nan\n",
      "Epoch 47/150\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.3360 - acc: 0.9312 - gini_normalized: nan - val_loss: 0.3425 - val_acc: 0.9540 - val_gini_normalized: nan\n",
      "Epoch 48/150\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.3360 - acc: 0.9368 - gini_normalized: nan - val_loss: 0.3648 - val_acc: 0.9340 - val_gini_normalized: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/150\n",
      "2500/2500 [==============================] - 0s 97us/step - loss: 0.3337 - acc: 0.9300 - gini_normalized: nan - val_loss: 0.3287 - val_acc: 0.9160 - val_gini_normalized: nan\n",
      "Epoch 50/150\n",
      "2500/2500 [==============================] - 0s 101us/step - loss: 0.3245 - acc: 0.9332 - gini_normalized: nan - val_loss: 0.3533 - val_acc: 0.9600 - val_gini_normalized: nan\n",
      "Epoch 51/150\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.3288 - acc: 0.9332 - gini_normalized: nan - val_loss: 0.3383 - val_acc: 0.9540 - val_gini_normalized: nan\n",
      "Epoch 52/150\n",
      "2500/2500 [==============================] - 0s 88us/step - loss: 0.3238 - acc: 0.9308 - gini_normalized: nan - val_loss: 0.3097 - val_acc: 0.9400 - val_gini_normalized: nan\n",
      "Epoch 53/150\n",
      "2500/2500 [==============================] - 0s 79us/step - loss: 0.3250 - acc: 0.9296 - gini_normalized: nan - val_loss: 0.3232 - val_acc: 0.9460 - val_gini_normalized: nan\n",
      "Epoch 54/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.3439 - acc: 0.9320 - gini_normalized: nan - val_loss: 0.3135 - val_acc: 0.9320 - val_gini_normalized: nan\n",
      "Epoch 55/150\n",
      "2500/2500 [==============================] - 0s 93us/step - loss: 0.3202 - acc: 0.9320 - gini_normalized: nan - val_loss: 0.3057 - val_acc: 0.9560 - val_gini_normalized: nan\n",
      "Epoch 56/150\n",
      "2500/2500 [==============================] - 0s 86us/step - loss: 0.3147 - acc: 0.9356 - gini_normalized: nan - val_loss: 0.3310 - val_acc: 0.9400 - val_gini_normalized: nan\n",
      "Epoch 57/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.3301 - acc: 0.9320 - gini_normalized: nan - val_loss: 0.3349 - val_acc: 0.9260 - val_gini_normalized: nan\n",
      "Epoch 58/150\n",
      "2500/2500 [==============================] - 0s 86us/step - loss: 0.3279 - acc: 0.9260 - gini_normalized: nan - val_loss: 0.2996 - val_acc: 0.9580 - val_gini_normalized: nan\n",
      "Epoch 59/150\n",
      "2500/2500 [==============================] - 0s 99us/step - loss: 0.3110 - acc: 0.9356 - gini_normalized: nan - val_loss: 0.3317 - val_acc: 0.9320 - val_gini_normalized: nan\n",
      "Epoch 60/150\n",
      "2500/2500 [==============================] - 0s 113us/step - loss: 0.3287 - acc: 0.9372 - gini_normalized: nan - val_loss: 0.3105 - val_acc: 0.9560 - val_gini_normalized: nan\n",
      "Epoch 61/150\n",
      "2500/2500 [==============================] - 0s 101us/step - loss: 0.3123 - acc: 0.9400 - gini_normalized: nan - val_loss: 0.3139 - val_acc: 0.9280 - val_gini_normalized: nan\n",
      "Epoch 62/150\n",
      "2500/2500 [==============================] - 0s 87us/step - loss: 0.3135 - acc: 0.9356 - gini_normalized: nan - val_loss: 0.3036 - val_acc: 0.9240 - val_gini_normalized: nan\n",
      "Epoch 63/150\n",
      "2500/2500 [==============================] - 0s 112us/step - loss: 0.3110 - acc: 0.9364 - gini_normalized: nan - val_loss: 0.3567 - val_acc: 0.9580 - val_gini_normalized: nan\n",
      "Epoch 64/150\n",
      "2500/2500 [==============================] - 0s 88us/step - loss: 0.3037 - acc: 0.9416 - gini_normalized: nan - val_loss: 0.2914 - val_acc: 0.9500 - val_gini_normalized: nan\n",
      "Epoch 65/150\n",
      "2500/2500 [==============================] - 0s 92us/step - loss: 0.3004 - acc: 0.9420 - gini_normalized: nan - val_loss: 0.3040 - val_acc: 0.9600 - val_gini_normalized: nan\n",
      "Epoch 66/150\n",
      "2500/2500 [==============================] - 0s 88us/step - loss: 0.3029 - acc: 0.9424 - gini_normalized: nan - val_loss: 0.3215 - val_acc: 0.9500 - val_gini_normalized: nan\n",
      "Epoch 67/150\n",
      "2500/2500 [==============================] - 0s 85us/step - loss: 0.3053 - acc: 0.9388 - gini_normalized: nan - val_loss: 0.2906 - val_acc: 0.9580 - val_gini_normalized: nan\n",
      "Epoch 68/150\n",
      "2500/2500 [==============================] - 0s 88us/step - loss: 0.2963 - acc: 0.9364 - gini_normalized: nan - val_loss: 0.3170 - val_acc: 0.9460 - val_gini_normalized: nan\n",
      "Epoch 69/150\n",
      "2500/2500 [==============================] - 0s 98us/step - loss: 0.3058 - acc: 0.9436 - gini_normalized: nan - val_loss: 0.2831 - val_acc: 0.9480 - val_gini_normalized: nan\n",
      "Epoch 70/150\n",
      "2500/2500 [==============================] - 0s 88us/step - loss: 0.3078 - acc: 0.9376 - gini_normalized: nan - val_loss: 0.2851 - val_acc: 0.9440 - val_gini_normalized: nan\n",
      "Epoch 71/150\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.2951 - acc: 0.9396 - gini_normalized: nan - val_loss: 0.2869 - val_acc: 0.9500 - val_gini_normalized: nan\n",
      "Epoch 72/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.2921 - acc: 0.9444 - gini_normalized: nan - val_loss: 0.3223 - val_acc: 0.9420 - val_gini_normalized: nan\n",
      "Epoch 73/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.2892 - acc: 0.9416 - gini_normalized: nan - val_loss: 0.3113 - val_acc: 0.9260 - val_gini_normalized: nan\n",
      "Epoch 74/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.2946 - acc: 0.9364 - gini_normalized: nan - val_loss: 0.2910 - val_acc: 0.9420 - val_gini_normalized: nan\n",
      "Epoch 75/150\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.2945 - acc: 0.9368 - gini_normalized: nan - val_loss: 0.3369 - val_acc: 0.9260 - val_gini_normalized: nan\n",
      "Epoch 76/150\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.2913 - acc: 0.9408 - gini_normalized: nan - val_loss: 0.3110 - val_acc: 0.9320 - val_gini_normalized: nan\n",
      "Epoch 77/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.2954 - acc: 0.9376 - gini_normalized: nan - val_loss: 0.2732 - val_acc: 0.9600 - val_gini_normalized: nan\n",
      "Epoch 78/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.2907 - acc: 0.9424 - gini_normalized: nan - val_loss: 0.2594 - val_acc: 0.9420 - val_gini_normalized: nan\n",
      "Epoch 79/150\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.2883 - acc: 0.9444 - gini_normalized: nan - val_loss: 0.2747 - val_acc: 0.9580 - val_gini_normalized: nan\n",
      "Epoch 80/150\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.2853 - acc: 0.9388 - gini_normalized: nan - val_loss: 0.2607 - val_acc: 0.9340 - val_gini_normalized: nan\n",
      "Epoch 81/150\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.2779 - acc: 0.9460 - gini_normalized: nan - val_loss: 0.2732 - val_acc: 0.9540 - val_gini_normalized: nan\n",
      "Epoch 82/150\n",
      "2500/2500 [==============================] - 0s 86us/step - loss: 0.2816 - acc: 0.9388 - gini_normalized: nan - val_loss: 0.2546 - val_acc: 0.9460 - val_gini_normalized: nan\n",
      "Epoch 83/150\n",
      "2500/2500 [==============================] - 0s 93us/step - loss: 0.2771 - acc: 0.9408 - gini_normalized: nan - val_loss: 0.3174 - val_acc: 0.9500 - val_gini_normalized: nan\n",
      "Epoch 84/150\n",
      "2500/2500 [==============================] - 0s 96us/step - loss: 0.2823 - acc: 0.9416 - gini_normalized: nan - val_loss: 0.2497 - val_acc: 0.9540 - val_gini_normalized: nan\n",
      "Epoch 85/150\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.2719 - acc: 0.9400 - gini_normalized: nan - val_loss: 0.2641 - val_acc: 0.9300 - val_gini_normalized: nan\n",
      "Epoch 86/150\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.2750 - acc: 0.9428 - gini_normalized: nan - val_loss: 0.2728 - val_acc: 0.9300 - val_gini_normalized: nan\n",
      "Epoch 87/150\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.2776 - acc: 0.9404 - gini_normalized: nan - val_loss: 0.2785 - val_acc: 0.9440 - val_gini_normalized: nan\n",
      "Epoch 88/150\n",
      "2500/2500 [==============================] - 0s 94us/step - loss: 0.2713 - acc: 0.9452 - gini_normalized: nan - val_loss: 0.2666 - val_acc: 0.9360 - val_gini_normalized: nan\n",
      "Epoch 89/150\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.2634 - acc: 0.9496 - gini_normalized: nan - val_loss: 0.2950 - val_acc: 0.9340 - val_gini_normalized: nan\n",
      "Epoch 90/150\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.2728 - acc: 0.9460 - gini_normalized: nan - val_loss: 0.3072 - val_acc: 0.9560 - val_gini_normalized: nan\n",
      "Epoch 91/150\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.2730 - acc: 0.9484 - gini_normalized: nan - val_loss: 0.2653 - val_acc: 0.9340 - val_gini_normalized: nan\n",
      "Epoch 92/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.2680 - acc: 0.9460 - gini_normalized: nan - val_loss: 0.2565 - val_acc: 0.9540 - val_gini_normalized: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/150\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.2605 - acc: 0.9512 - gini_normalized: nan - val_loss: 0.2478 - val_acc: 0.9600 - val_gini_normalized: nan\n",
      "Epoch 94/150\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.2528 - acc: 0.9496 - gini_normalized: nan - val_loss: 0.2619 - val_acc: 0.9680 - val_gini_normalized: nan\n",
      "Epoch 95/150\n",
      "2500/2500 [==============================] - 0s 108us/step - loss: 0.2666 - acc: 0.9460 - gini_normalized: nan - val_loss: 0.2450 - val_acc: 0.9580 - val_gini_normalized: nan\n",
      "Epoch 96/150\n",
      "2500/2500 [==============================] - 0s 102us/step - loss: 0.2624 - acc: 0.9512 - gini_normalized: nan - val_loss: 0.2681 - val_acc: 0.9440 - val_gini_normalized: nan\n",
      "Epoch 97/150\n",
      "2500/2500 [==============================] - 0s 127us/step - loss: 0.2752 - acc: 0.9416 - gini_normalized: nan - val_loss: 0.2331 - val_acc: 0.9620 - val_gini_normalized: nan\n",
      "Epoch 98/150\n",
      "2500/2500 [==============================] - 0s 111us/step - loss: 0.2557 - acc: 0.9508 - gini_normalized: nan - val_loss: 0.2429 - val_acc: 0.9540 - val_gini_normalized: nan\n",
      "Epoch 99/150\n",
      "2500/2500 [==============================] - 0s 99us/step - loss: 0.2609 - acc: 0.9496 - gini_normalized: nan - val_loss: 0.2459 - val_acc: 0.9520 - val_gini_normalized: nan\n",
      "Epoch 100/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.2583 - acc: 0.9480 - gini_normalized: nan - val_loss: 0.2434 - val_acc: 0.9520 - val_gini_normalized: nan\n",
      "Epoch 101/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.2572 - acc: 0.9504 - gini_normalized: nan - val_loss: 0.2472 - val_acc: 0.9600 - val_gini_normalized: nan\n",
      "Epoch 102/150\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.2614 - acc: 0.9456 - gini_normalized: nan - val_loss: 0.2380 - val_acc: 0.9500 - val_gini_normalized: nan\n",
      "Epoch 103/150\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.2540 - acc: 0.9512 - gini_normalized: nan - val_loss: 0.2300 - val_acc: 0.9600 - val_gini_normalized: nan\n",
      "Epoch 104/150\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.2525 - acc: 0.9500 - gini_normalized: nan - val_loss: 0.2316 - val_acc: 0.9740 - val_gini_normalized: nan\n",
      "Epoch 105/150\n",
      "2500/2500 [==============================] - 0s 94us/step - loss: 0.2497 - acc: 0.9496 - gini_normalized: nan - val_loss: 0.2399 - val_acc: 0.9660 - val_gini_normalized: nan\n",
      "Epoch 106/150\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.2499 - acc: 0.9492 - gini_normalized: nan - val_loss: 0.2265 - val_acc: 0.9640 - val_gini_normalized: nan\n",
      "Epoch 107/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.2544 - acc: 0.9480 - gini_normalized: nan - val_loss: 0.2235 - val_acc: 0.9540 - val_gini_normalized: nan\n",
      "Epoch 108/150\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.2503 - acc: 0.9472 - gini_normalized: nan - val_loss: 0.2265 - val_acc: 0.9500 - val_gini_normalized: nan\n",
      "Epoch 109/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.2503 - acc: 0.9468 - gini_normalized: nan - val_loss: 0.2688 - val_acc: 0.9440 - val_gini_normalized: nan\n",
      "Epoch 110/150\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.2460 - acc: 0.9488 - gini_normalized: nan - val_loss: 0.2842 - val_acc: 0.9340 - val_gini_normalized: nan\n",
      "Epoch 111/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.2510 - acc: 0.9500 - gini_normalized: nan - val_loss: 0.2380 - val_acc: 0.9460 - val_gini_normalized: nan\n",
      "Epoch 112/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.2496 - acc: 0.9484 - gini_normalized: nan - val_loss: 0.2223 - val_acc: 0.9420 - val_gini_normalized: nan\n",
      "Epoch 113/150\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.2417 - acc: 0.9544 - gini_normalized: nan - val_loss: 0.2287 - val_acc: 0.9320 - val_gini_normalized: nan\n",
      "Epoch 114/150\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.2480 - acc: 0.9492 - gini_normalized: nan - val_loss: 0.2572 - val_acc: 0.9480 - val_gini_normalized: nan\n",
      "Epoch 115/150\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.2482 - acc: 0.9480 - gini_normalized: nan - val_loss: 0.2213 - val_acc: 0.9640 - val_gini_normalized: nan\n",
      "Epoch 116/150\n",
      "2500/2500 [==============================] - 0s 89us/step - loss: 0.2509 - acc: 0.9504 - gini_normalized: nan - val_loss: 0.2245 - val_acc: 0.9700 - val_gini_normalized: nan\n",
      "Epoch 117/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.2436 - acc: 0.9484 - gini_normalized: nan - val_loss: 0.2296 - val_acc: 0.9400 - val_gini_normalized: nan\n",
      "Epoch 118/150\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.2412 - acc: 0.9520 - gini_normalized: nan - val_loss: 0.2176 - val_acc: 0.9700 - val_gini_normalized: nan\n",
      "Epoch 119/150\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.2485 - acc: 0.9480 - gini_normalized: nan - val_loss: 0.2381 - val_acc: 0.9660 - val_gini_normalized: nan\n",
      "Epoch 120/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.2482 - acc: 0.9464 - gini_normalized: nan - val_loss: 0.2361 - val_acc: 0.9640 - val_gini_normalized: nan\n",
      "Epoch 121/150\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.2419 - acc: 0.9512 - gini_normalized: nan - val_loss: 0.2220 - val_acc: 0.9700 - val_gini_normalized: nan\n",
      "Epoch 122/150\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.2469 - acc: 0.9488 - gini_normalized: nan - val_loss: 0.2281 - val_acc: 0.9660 - val_gini_normalized: nan\n",
      "Epoch 123/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.2429 - acc: 0.9472 - gini_normalized: nan - val_loss: 0.2109 - val_acc: 0.9680 - val_gini_normalized: nan\n",
      "Epoch 124/150\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.2344 - acc: 0.9476 - gini_normalized: nan - val_loss: 0.2250 - val_acc: 0.9720 - val_gini_normalized: nan\n",
      "Epoch 125/150\n",
      "2500/2500 [==============================] - 0s 86us/step - loss: 0.2302 - acc: 0.9496 - gini_normalized: nan - val_loss: 0.2209 - val_acc: 0.9580 - val_gini_normalized: nan\n",
      "Epoch 126/150\n",
      "2500/2500 [==============================] - 0s 89us/step - loss: 0.2387 - acc: 0.9520 - gini_normalized: nan - val_loss: 0.2134 - val_acc: 0.9540 - val_gini_normalized: nan\n",
      "Epoch 127/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.2405 - acc: 0.9472 - gini_normalized: nan - val_loss: 0.2318 - val_acc: 0.9520 - val_gini_normalized: nan\n",
      "Epoch 128/150\n",
      "2500/2500 [==============================] - 0s 112us/step - loss: 0.2485 - acc: 0.9508 - gini_normalized: nan - val_loss: 0.2079 - val_acc: 0.9640 - val_gini_normalized: nan\n",
      "Epoch 129/150\n",
      "2500/2500 [==============================] - 0s 89us/step - loss: 0.2456 - acc: 0.9488 - gini_normalized: nan - val_loss: 0.2393 - val_acc: 0.9640 - val_gini_normalized: nan\n",
      "Epoch 130/150\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.2308 - acc: 0.9528 - gini_normalized: nan - val_loss: 0.2153 - val_acc: 0.9420 - val_gini_normalized: nan\n",
      "Epoch 131/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.2459 - acc: 0.9460 - gini_normalized: nan - val_loss: 0.2141 - val_acc: 0.9580 - val_gini_normalized: nan\n",
      "Epoch 132/150\n",
      "2500/2500 [==============================] - 0s 91us/step - loss: 0.2369 - acc: 0.9492 - gini_normalized: nan - val_loss: 0.2213 - val_acc: 0.9640 - val_gini_normalized: nan\n",
      "Epoch 133/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.2303 - acc: 0.9516 - gini_normalized: nan - val_loss: 0.2404 - val_acc: 0.9540 - val_gini_normalized: nan\n",
      "Epoch 134/150\n",
      "2500/2500 [==============================] - 0s 90us/step - loss: 0.2536 - acc: 0.9480 - gini_normalized: nan - val_loss: 0.2216 - val_acc: 0.9620 - val_gini_normalized: nan\n",
      "Epoch 135/150\n",
      "2500/2500 [==============================] - 0s 91us/step - loss: 0.2347 - acc: 0.9504 - gini_normalized: nan - val_loss: 0.2439 - val_acc: 0.9520 - val_gini_normalized: nan\n",
      "Epoch 136/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 102us/step - loss: 0.2342 - acc: 0.9484 - gini_normalized: nan - val_loss: 0.2062 - val_acc: 0.9680 - val_gini_normalized: nan\n",
      "Epoch 137/150\n",
      "2500/2500 [==============================] - 0s 100us/step - loss: 0.2490 - acc: 0.9492 - gini_normalized: nan - val_loss: 0.2181 - val_acc: 0.9460 - val_gini_normalized: nan\n",
      "Epoch 138/150\n",
      "2500/2500 [==============================] - 0s 84us/step - loss: 0.2398 - acc: 0.9500 - gini_normalized: nan - val_loss: 0.2073 - val_acc: 0.9700 - val_gini_normalized: nan\n",
      "Epoch 139/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.2536 - acc: 0.9480 - gini_normalized: nan - val_loss: 0.2347 - val_acc: 0.9700 - val_gini_normalized: nan\n",
      "Epoch 140/150\n",
      "2500/2500 [==============================] - 0s 106us/step - loss: 0.2496 - acc: 0.9488 - gini_normalized: nan - val_loss: 0.2054 - val_acc: 0.9600 - val_gini_normalized: nan\n",
      "Epoch 141/150\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.2377 - acc: 0.9516 - gini_normalized: nan - val_loss: 0.2030 - val_acc: 0.9580 - val_gini_normalized: nan\n",
      "Epoch 142/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.2276 - acc: 0.9500 - gini_normalized: nan - val_loss: 0.2170 - val_acc: 0.9620 - val_gini_normalized: nan\n",
      "Epoch 143/150\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.2301 - acc: 0.9532 - gini_normalized: nan - val_loss: 0.2310 - val_acc: 0.9600 - val_gini_normalized: nan\n",
      "Epoch 144/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.2421 - acc: 0.9512 - gini_normalized: nan - val_loss: 0.2108 - val_acc: 0.9540 - val_gini_normalized: nan\n",
      "Epoch 145/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.2365 - acc: 0.9496 - gini_normalized: nan - val_loss: 0.2104 - val_acc: 0.9380 - val_gini_normalized: nan\n",
      "Epoch 146/150\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.2292 - acc: 0.9532 - gini_normalized: nan - val_loss: 0.2204 - val_acc: 0.9400 - val_gini_normalized: nan\n",
      "Epoch 147/150\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.2300 - acc: 0.9516 - gini_normalized: nan - val_loss: 0.2020 - val_acc: 0.9660 - val_gini_normalized: nan\n",
      "Epoch 148/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.2283 - acc: 0.9520 - gini_normalized: nan - val_loss: 0.2266 - val_acc: 0.9660 - val_gini_normalized: nan\n",
      "Epoch 149/150\n",
      "2500/2500 [==============================] - 0s 84us/step - loss: 0.2373 - acc: 0.9524 - gini_normalized: nan - val_loss: 0.2248 - val_acc: 0.9600 - val_gini_normalized: nan\n",
      "Epoch 150/150\n",
      "2500/2500 [==============================] - 0s 79us/step - loss: 0.2297 - acc: 0.9516 - gini_normalized: nan - val_loss: 0.2088 - val_acc: 0.9640 - val_gini_normalized: nan\n",
      "500/500 [==============================] - 0s 51us/step\n",
      "Train on 2500 samples, validate on 500 samples\n",
      "Epoch 1/150\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 2.1338 - acc: 0.6992 - gini_normalized: nan - val_loss: 1.8175 - val_acc: 0.7600 - val_gini_normalized: nan\n",
      "Epoch 2/150\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 1.6544 - acc: 0.7872 - gini_normalized: nan - val_loss: 1.5049 - val_acc: 0.8000 - val_gini_normalized: nan\n",
      "Epoch 3/150\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 1.3819 - acc: 0.8192 - gini_normalized: nan - val_loss: 1.3254 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 4/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 1.1857 - acc: 0.8268 - gini_normalized: nan - val_loss: 1.1238 - val_acc: 0.8200 - val_gini_normalized: nan\n",
      "Epoch 5/150\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 1.0594 - acc: 0.8460 - gini_normalized: nan - val_loss: 1.0164 - val_acc: 0.8160 - val_gini_normalized: nan\n",
      "Epoch 6/150\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.9565 - acc: 0.8480 - gini_normalized: nan - val_loss: 0.9729 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 7/150\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.8854 - acc: 0.8468 - gini_normalized: nan - val_loss: 0.9136 - val_acc: 0.8120 - val_gini_normalized: nan\n",
      "Epoch 8/150\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.8258 - acc: 0.8524 - gini_normalized: nan - val_loss: 0.8248 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 9/150\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.7855 - acc: 0.8616 - gini_normalized: nan - val_loss: 0.7951 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 10/150\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.7435 - acc: 0.8632 - gini_normalized: nan - val_loss: 0.7817 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 11/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.7139 - acc: 0.8648 - gini_normalized: nan - val_loss: 0.7051 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 12/150\n",
      "2500/2500 [==============================] - 0s 151us/step - loss: 0.6753 - acc: 0.8664 - gini_normalized: nan - val_loss: 0.6826 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 13/150\n",
      "2500/2500 [==============================] - 0s 123us/step - loss: 0.6591 - acc: 0.8696 - gini_normalized: nan - val_loss: 0.6965 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 14/150\n",
      "2500/2500 [==============================] - 0s 135us/step - loss: 0.6441 - acc: 0.8664 - gini_normalized: nan - val_loss: 0.6528 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 15/150\n",
      "2500/2500 [==============================] - 0s 110us/step - loss: 0.6126 - acc: 0.8732 - gini_normalized: nan - val_loss: 0.6341 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 16/150\n",
      "2500/2500 [==============================] - 0s 100us/step - loss: 0.5977 - acc: 0.8760 - gini_normalized: nan - val_loss: 0.6480 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 17/150\n",
      "2500/2500 [==============================] - 0s 100us/step - loss: 0.5928 - acc: 0.8804 - gini_normalized: nan - val_loss: 0.6016 - val_acc: 0.8640 - val_gini_normalized: nan\n",
      "Epoch 18/150\n",
      "2500/2500 [==============================] - 0s 96us/step - loss: 0.5627 - acc: 0.8836 - gini_normalized: nan - val_loss: 0.5957 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 19/150\n",
      "2500/2500 [==============================] - 0s 86us/step - loss: 0.5544 - acc: 0.8820 - gini_normalized: nan - val_loss: 0.5758 - val_acc: 0.8660 - val_gini_normalized: nan\n",
      "Epoch 20/150\n",
      "2500/2500 [==============================] - 0s 99us/step - loss: 0.5419 - acc: 0.8832 - gini_normalized: nan - val_loss: 0.6676 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 21/150\n",
      "2500/2500 [==============================] - 0s 102us/step - loss: 0.5348 - acc: 0.8856 - gini_normalized: nan - val_loss: 0.5624 - val_acc: 0.8740 - val_gini_normalized: nan\n",
      "Epoch 22/150\n",
      "2500/2500 [==============================] - 0s 90us/step - loss: 0.5164 - acc: 0.8840 - gini_normalized: nan - val_loss: 0.5343 - val_acc: 0.8840 - val_gini_normalized: nan\n",
      "Epoch 23/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.5106 - acc: 0.8868 - gini_normalized: nan - val_loss: 0.5047 - val_acc: 0.8940 - val_gini_normalized: nan\n",
      "Epoch 24/150\n",
      "2500/2500 [==============================] - 0s 87us/step - loss: 0.4926 - acc: 0.8924 - gini_normalized: nan - val_loss: 0.5328 - val_acc: 0.8860 - val_gini_normalized: nan\n",
      "Epoch 25/150\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.4822 - acc: 0.8936 - gini_normalized: nan - val_loss: 0.5104 - val_acc: 0.8720 - val_gini_normalized: nan\n",
      "Epoch 26/150\n",
      "2500/2500 [==============================] - 0s 84us/step - loss: 0.4795 - acc: 0.8916 - gini_normalized: nan - val_loss: 0.4678 - val_acc: 0.9000 - val_gini_normalized: nan\n",
      "Epoch 27/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4621 - acc: 0.8972 - gini_normalized: nan - val_loss: 0.4941 - val_acc: 0.8960 - val_gini_normalized: nan\n",
      "Epoch 28/150\n",
      "2500/2500 [==============================] - 0s 103us/step - loss: 0.4603 - acc: 0.9016 - gini_normalized: nan - val_loss: 0.4782 - val_acc: 0.8980 - val_gini_normalized: nan\n",
      "Epoch 29/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 114us/step - loss: 0.4522 - acc: 0.9012 - gini_normalized: nan - val_loss: 0.5692 - val_acc: 0.8680 - val_gini_normalized: nan\n",
      "Epoch 30/150\n",
      "2500/2500 [==============================] - 0s 109us/step - loss: 0.4655 - acc: 0.9012 - gini_normalized: nan - val_loss: 0.4730 - val_acc: 0.8920 - val_gini_normalized: nan\n",
      "Epoch 31/150\n",
      "2500/2500 [==============================] - 0s 89us/step - loss: 0.4297 - acc: 0.9092 - gini_normalized: nan - val_loss: 0.4704 - val_acc: 0.9080 - val_gini_normalized: nan\n",
      "Epoch 32/150\n",
      "2500/2500 [==============================] - 0s 115us/step - loss: 0.4220 - acc: 0.9052 - gini_normalized: nan - val_loss: 0.4488 - val_acc: 0.9080 - val_gini_normalized: nan\n",
      "Epoch 33/150\n",
      "2500/2500 [==============================] - 0s 86us/step - loss: 0.4280 - acc: 0.9044 - gini_normalized: nan - val_loss: 0.4798 - val_acc: 0.9000 - val_gini_normalized: nan\n",
      "Epoch 34/150\n",
      "2500/2500 [==============================] - 0s 95us/step - loss: 0.4108 - acc: 0.9144 - gini_normalized: nan - val_loss: 0.4588 - val_acc: 0.8780 - val_gini_normalized: nan\n",
      "Epoch 35/150\n",
      "2500/2500 [==============================] - 0s 90us/step - loss: 0.4263 - acc: 0.9068 - gini_normalized: nan - val_loss: 0.4550 - val_acc: 0.8940 - val_gini_normalized: nan\n",
      "Epoch 36/150\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.4071 - acc: 0.9116 - gini_normalized: nan - val_loss: 0.4392 - val_acc: 0.9140 - val_gini_normalized: nan\n",
      "Epoch 37/150\n",
      "2500/2500 [==============================] - 0s 93us/step - loss: 0.3917 - acc: 0.9168 - gini_normalized: nan - val_loss: 0.4264 - val_acc: 0.9100 - val_gini_normalized: nan\n",
      "Epoch 38/150\n",
      "2500/2500 [==============================] - 0s 98us/step - loss: 0.3809 - acc: 0.9172 - gini_normalized: nan - val_loss: 0.4389 - val_acc: 0.9060 - val_gini_normalized: nan\n",
      "Epoch 39/150\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.3787 - acc: 0.9180 - gini_normalized: nan - val_loss: 0.3816 - val_acc: 0.9180 - val_gini_normalized: nan\n",
      "Epoch 40/150\n",
      "2500/2500 [==============================] - 0s 105us/step - loss: 0.3709 - acc: 0.9240 - gini_normalized: nan - val_loss: 0.4235 - val_acc: 0.9220 - val_gini_normalized: nan\n",
      "Epoch 41/150\n",
      "2500/2500 [==============================] - 0s 98us/step - loss: 0.3717 - acc: 0.9204 - gini_normalized: nan - val_loss: 0.4414 - val_acc: 0.9080 - val_gini_normalized: nan\n",
      "Epoch 42/150\n",
      "2500/2500 [==============================] - 0s 105us/step - loss: 0.3622 - acc: 0.9212 - gini_normalized: nan - val_loss: 0.4196 - val_acc: 0.9100 - val_gini_normalized: nan\n",
      "Epoch 43/150\n",
      "2500/2500 [==============================] - 0s 142us/step - loss: 0.3608 - acc: 0.9264 - gini_normalized: nan - val_loss: 0.4088 - val_acc: 0.9320 - val_gini_normalized: nan\n",
      "Epoch 44/150\n",
      "2500/2500 [==============================] - 0s 89us/step - loss: 0.3815 - acc: 0.9268 - gini_normalized: nan - val_loss: 0.3596 - val_acc: 0.9340 - val_gini_normalized: nan\n",
      "Epoch 45/150\n",
      "2500/2500 [==============================] - 0s 95us/step - loss: 0.3562 - acc: 0.9248 - gini_normalized: nan - val_loss: 0.3921 - val_acc: 0.9280 - val_gini_normalized: nan\n",
      "Epoch 46/150\n",
      "2500/2500 [==============================] - 0s 91us/step - loss: 0.3506 - acc: 0.9276 - gini_normalized: nan - val_loss: 0.3494 - val_acc: 0.9440 - val_gini_normalized: nan\n",
      "Epoch 47/150\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.3480 - acc: 0.9272 - gini_normalized: nan - val_loss: 0.3977 - val_acc: 0.9100 - val_gini_normalized: nan\n",
      "Epoch 48/150\n",
      "2500/2500 [==============================] - 0s 88us/step - loss: 0.3535 - acc: 0.9292 - gini_normalized: nan - val_loss: 0.3712 - val_acc: 0.9360 - val_gini_normalized: nan\n",
      "Epoch 49/150\n",
      "2500/2500 [==============================] - 0s 89us/step - loss: 0.3533 - acc: 0.9240 - gini_normalized: nan - val_loss: 0.3765 - val_acc: 0.9260 - val_gini_normalized: nan\n",
      "Epoch 50/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.3366 - acc: 0.9300 - gini_normalized: nan - val_loss: 0.3469 - val_acc: 0.9260 - val_gini_normalized: nan\n",
      "Epoch 51/150\n",
      "2500/2500 [==============================] - 0s 86us/step - loss: 0.3319 - acc: 0.9272 - gini_normalized: nan - val_loss: 0.3731 - val_acc: 0.9140 - val_gini_normalized: nan\n",
      "Epoch 52/150\n",
      "2500/2500 [==============================] - 0s 84us/step - loss: 0.3243 - acc: 0.9300 - gini_normalized: nan - val_loss: 0.3487 - val_acc: 0.9240 - val_gini_normalized: nan\n",
      "Epoch 53/150\n",
      "2500/2500 [==============================] - 0s 84us/step - loss: 0.3351 - acc: 0.9300 - gini_normalized: nan - val_loss: 0.3478 - val_acc: 0.9180 - val_gini_normalized: nan\n",
      "Epoch 54/150\n",
      "2500/2500 [==============================] - 0s 85us/step - loss: 0.3297 - acc: 0.9260 - gini_normalized: nan - val_loss: 0.3260 - val_acc: 0.9340 - val_gini_normalized: nan\n",
      "Epoch 55/150\n",
      "2500/2500 [==============================] - 0s 93us/step - loss: 0.3178 - acc: 0.9328 - gini_normalized: nan - val_loss: 0.3223 - val_acc: 0.9260 - val_gini_normalized: nan\n",
      "Epoch 56/150\n",
      "2500/2500 [==============================] - 0s 90us/step - loss: 0.3142 - acc: 0.9340 - gini_normalized: nan - val_loss: 0.3440 - val_acc: 0.9160 - val_gini_normalized: nan\n",
      "Epoch 57/150\n",
      "2500/2500 [==============================] - 0s 90us/step - loss: 0.3412 - acc: 0.9316 - gini_normalized: nan - val_loss: 0.3331 - val_acc: 0.9320 - val_gini_normalized: nan\n",
      "Epoch 58/150\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.3018 - acc: 0.9332 - gini_normalized: nan - val_loss: 0.3356 - val_acc: 0.9320 - val_gini_normalized: nan\n",
      "Epoch 59/150\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.3105 - acc: 0.9304 - gini_normalized: nan - val_loss: 0.3419 - val_acc: 0.9260 - val_gini_normalized: nan\n",
      "Epoch 60/150\n",
      "2500/2500 [==============================] - 0s 101us/step - loss: 0.3047 - acc: 0.9320 - gini_normalized: nan - val_loss: 0.3059 - val_acc: 0.9260 - val_gini_normalized: nan\n",
      "Epoch 61/150\n",
      "2500/2500 [==============================] - 0s 90us/step - loss: 0.3064 - acc: 0.9352 - gini_normalized: nan - val_loss: 0.3232 - val_acc: 0.9260 - val_gini_normalized: nan\n",
      "Epoch 62/150\n",
      "2500/2500 [==============================] - 0s 86us/step - loss: 0.3057 - acc: 0.9368 - gini_normalized: nan - val_loss: 0.3194 - val_acc: 0.9260 - val_gini_normalized: nan\n",
      "Epoch 63/150\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.3015 - acc: 0.9356 - gini_normalized: nan - val_loss: 0.2940 - val_acc: 0.9340 - val_gini_normalized: nan\n",
      "Epoch 64/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.2982 - acc: 0.9348 - gini_normalized: nan - val_loss: 0.3413 - val_acc: 0.9280 - val_gini_normalized: nan\n",
      "Epoch 65/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.2942 - acc: 0.9376 - gini_normalized: nan - val_loss: 0.3367 - val_acc: 0.9040 - val_gini_normalized: nan\n",
      "Epoch 66/150\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.2875 - acc: 0.9380 - gini_normalized: nan - val_loss: 0.3080 - val_acc: 0.9200 - val_gini_normalized: nan\n",
      "Epoch 67/150\n",
      "2500/2500 [==============================] - 0s 91us/step - loss: 0.2907 - acc: 0.9356 - gini_normalized: nan - val_loss: 0.3080 - val_acc: 0.9400 - val_gini_normalized: nan\n",
      "Epoch 68/150\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.2927 - acc: 0.9408 - gini_normalized: nan - val_loss: 0.3558 - val_acc: 0.9280 - val_gini_normalized: nan\n",
      "Epoch 69/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.2845 - acc: 0.9404 - gini_normalized: nan - val_loss: 0.2772 - val_acc: 0.9420 - val_gini_normalized: nan\n",
      "Epoch 70/150\n",
      "2500/2500 [==============================] - 0s 79us/step - loss: 0.2912 - acc: 0.9412 - gini_normalized: nan - val_loss: 0.2736 - val_acc: 0.9380 - val_gini_normalized: nan\n",
      "Epoch 71/150\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.2792 - acc: 0.9452 - gini_normalized: nan - val_loss: 0.3355 - val_acc: 0.9260 - val_gini_normalized: nan\n",
      "Epoch 72/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.2776 - acc: 0.9400 - gini_normalized: nan - val_loss: 0.3241 - val_acc: 0.9360 - val_gini_normalized: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.2799 - acc: 0.9360 - gini_normalized: nan - val_loss: 0.2867 - val_acc: 0.9360 - val_gini_normalized: nan\n",
      "Epoch 74/150\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.2690 - acc: 0.9432 - gini_normalized: nan - val_loss: 0.3088 - val_acc: 0.9240 - val_gini_normalized: nan\n",
      "Epoch 75/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.2722 - acc: 0.9396 - gini_normalized: nan - val_loss: 0.3432 - val_acc: 0.9060 - val_gini_normalized: nan\n",
      "Epoch 76/150\n",
      "2500/2500 [==============================] - 0s 94us/step - loss: 0.2663 - acc: 0.9444 - gini_normalized: nan - val_loss: 0.3187 - val_acc: 0.9200 - val_gini_normalized: nan\n",
      "Epoch 77/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.2778 - acc: 0.9424 - gini_normalized: nan - val_loss: 0.3356 - val_acc: 0.9240 - val_gini_normalized: nan\n",
      "Epoch 78/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.2643 - acc: 0.9468 - gini_normalized: nan - val_loss: 0.3060 - val_acc: 0.9320 - val_gini_normalized: nan\n",
      "Epoch 79/150\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.2658 - acc: 0.9424 - gini_normalized: nan - val_loss: 0.3100 - val_acc: 0.9120 - val_gini_normalized: nan\n",
      "Epoch 80/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.2650 - acc: 0.9436 - gini_normalized: nan - val_loss: 0.2795 - val_acc: 0.9380 - val_gini_normalized: nan\n",
      "Epoch 81/150\n",
      "2500/2500 [==============================] - 0s 90us/step - loss: 0.2626 - acc: 0.9432 - gini_normalized: nan - val_loss: 0.3087 - val_acc: 0.9320 - val_gini_normalized: nan\n",
      "Epoch 82/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.2670 - acc: 0.9440 - gini_normalized: nan - val_loss: 0.2804 - val_acc: 0.9520 - val_gini_normalized: nan\n",
      "Epoch 83/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.2570 - acc: 0.9456 - gini_normalized: nan - val_loss: 0.2639 - val_acc: 0.9460 - val_gini_normalized: nan\n",
      "Epoch 84/150\n",
      "2500/2500 [==============================] - 0s 96us/step - loss: 0.2544 - acc: 0.9444 - gini_normalized: nan - val_loss: 0.3006 - val_acc: 0.9220 - val_gini_normalized: nan\n",
      "Epoch 85/150\n",
      "2500/2500 [==============================] - 0s 104us/step - loss: 0.2592 - acc: 0.9420 - gini_normalized: nan - val_loss: 0.2738 - val_acc: 0.9240 - val_gini_normalized: nan\n",
      "Epoch 86/150\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.2576 - acc: 0.9436 - gini_normalized: nan - val_loss: 0.2688 - val_acc: 0.9440 - val_gini_normalized: nan\n",
      "Epoch 87/150\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.2507 - acc: 0.9464 - gini_normalized: nan - val_loss: 0.3046 - val_acc: 0.9420 - val_gini_normalized: nan\n",
      "Epoch 88/150\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.2525 - acc: 0.9464 - gini_normalized: nan - val_loss: 0.2888 - val_acc: 0.9400 - val_gini_normalized: nan\n",
      "Epoch 89/150\n",
      "2500/2500 [==============================] - 0s 108us/step - loss: 0.2595 - acc: 0.9456 - gini_normalized: nan - val_loss: 0.2587 - val_acc: 0.9400 - val_gini_normalized: nan\n",
      "Epoch 90/150\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.2540 - acc: 0.9500 - gini_normalized: nan - val_loss: 0.2603 - val_acc: 0.9420 - val_gini_normalized: nan\n",
      "Epoch 91/150\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.2410 - acc: 0.9460 - gini_normalized: nan - val_loss: 0.2412 - val_acc: 0.9520 - val_gini_normalized: nan\n",
      "Epoch 92/150\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.2484 - acc: 0.9452 - gini_normalized: nan - val_loss: 0.2484 - val_acc: 0.9360 - val_gini_normalized: nan\n",
      "Epoch 93/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.2413 - acc: 0.9480 - gini_normalized: nan - val_loss: 0.2644 - val_acc: 0.9440 - val_gini_normalized: nan\n",
      "Epoch 94/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.2401 - acc: 0.9476 - gini_normalized: nan - val_loss: 0.2528 - val_acc: 0.9440 - val_gini_normalized: nan\n",
      "Epoch 95/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.2393 - acc: 0.9452 - gini_normalized: nan - val_loss: 0.2680 - val_acc: 0.9280 - val_gini_normalized: nan\n",
      "Epoch 96/150\n",
      "2500/2500 [==============================] - 0s 79us/step - loss: 0.2374 - acc: 0.9476 - gini_normalized: nan - val_loss: 0.2532 - val_acc: 0.9460 - val_gini_normalized: nan\n",
      "Epoch 97/150\n",
      "2500/2500 [==============================] - 0s 86us/step - loss: 0.2383 - acc: 0.9496 - gini_normalized: nan - val_loss: 0.2428 - val_acc: 0.9500 - val_gini_normalized: nan\n",
      "Epoch 98/150\n",
      "2500/2500 [==============================] - 0s 107us/step - loss: 0.2432 - acc: 0.9484 - gini_normalized: nan - val_loss: 0.2380 - val_acc: 0.9500 - val_gini_normalized: nan\n",
      "Epoch 99/150\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.2343 - acc: 0.9520 - gini_normalized: nan - val_loss: 0.2344 - val_acc: 0.9580 - val_gini_normalized: nan\n",
      "Epoch 100/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.2382 - acc: 0.9516 - gini_normalized: nan - val_loss: 0.2215 - val_acc: 0.9540 - val_gini_normalized: nan\n",
      "Epoch 101/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.2314 - acc: 0.9480 - gini_normalized: nan - val_loss: 0.2422 - val_acc: 0.9440 - val_gini_normalized: nan\n",
      "Epoch 102/150\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.2315 - acc: 0.9496 - gini_normalized: nan - val_loss: 0.2280 - val_acc: 0.9460 - val_gini_normalized: nan\n",
      "Epoch 103/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.2371 - acc: 0.9540 - gini_normalized: nan - val_loss: 0.2815 - val_acc: 0.9380 - val_gini_normalized: nan\n",
      "Epoch 104/150\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.2456 - acc: 0.9464 - gini_normalized: nan - val_loss: 0.2455 - val_acc: 0.9360 - val_gini_normalized: nan\n",
      "Epoch 105/150\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.2269 - acc: 0.9524 - gini_normalized: nan - val_loss: 0.2362 - val_acc: 0.9440 - val_gini_normalized: nan\n",
      "Epoch 106/150\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.2406 - acc: 0.9500 - gini_normalized: nan - val_loss: 0.2313 - val_acc: 0.9480 - val_gini_normalized: nan\n",
      "Epoch 107/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.2257 - acc: 0.9528 - gini_normalized: nan - val_loss: 0.2289 - val_acc: 0.9520 - val_gini_normalized: nan\n",
      "Epoch 108/150\n",
      "2500/2500 [==============================] - 0s 79us/step - loss: 0.2195 - acc: 0.9532 - gini_normalized: nan - val_loss: 0.2377 - val_acc: 0.9480 - val_gini_normalized: nan\n",
      "Epoch 109/150\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.2208 - acc: 0.9516 - gini_normalized: nan - val_loss: 0.2626 - val_acc: 0.9300 - val_gini_normalized: nan\n",
      "Epoch 110/150\n",
      "2500/2500 [==============================] - 0s 79us/step - loss: 0.2237 - acc: 0.9552 - gini_normalized: nan - val_loss: 0.2453 - val_acc: 0.9500 - val_gini_normalized: nan\n",
      "Epoch 111/150\n",
      "2500/2500 [==============================] - 0s 84us/step - loss: 0.2269 - acc: 0.9524 - gini_normalized: nan - val_loss: 0.2603 - val_acc: 0.9280 - val_gini_normalized: nan\n",
      "Epoch 112/150\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.2206 - acc: 0.9512 - gini_normalized: nan - val_loss: 0.2184 - val_acc: 0.9460 - val_gini_normalized: nan\n",
      "Epoch 113/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.2178 - acc: 0.9580 - gini_normalized: nan - val_loss: 0.2593 - val_acc: 0.9240 - val_gini_normalized: nan\n",
      "Epoch 114/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.2188 - acc: 0.9504 - gini_normalized: nan - val_loss: 0.2504 - val_acc: 0.9320 - val_gini_normalized: nan\n",
      "Epoch 115/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.2160 - acc: 0.9488 - gini_normalized: nan - val_loss: 0.2350 - val_acc: 0.9320 - val_gini_normalized: nan\n",
      "Epoch 116/150\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.2134 - acc: 0.9500 - gini_normalized: nan - val_loss: 0.2174 - val_acc: 0.9440 - val_gini_normalized: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/150\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.2136 - acc: 0.9504 - gini_normalized: nan - val_loss: 0.2656 - val_acc: 0.9420 - val_gini_normalized: nan\n",
      "Epoch 118/150\n",
      "2500/2500 [==============================] - 0s 92us/step - loss: 0.2093 - acc: 0.9520 - gini_normalized: nan - val_loss: 0.2440 - val_acc: 0.9460 - val_gini_normalized: nan\n",
      "Epoch 119/150\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.2211 - acc: 0.9532 - gini_normalized: nan - val_loss: 0.2381 - val_acc: 0.9420 - val_gini_normalized: nan\n",
      "Epoch 120/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.2178 - acc: 0.9520 - gini_normalized: nan - val_loss: 0.2139 - val_acc: 0.9560 - val_gini_normalized: nan\n",
      "Epoch 121/150\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.2111 - acc: 0.9540 - gini_normalized: nan - val_loss: 0.2781 - val_acc: 0.9180 - val_gini_normalized: nan\n",
      "Epoch 122/150\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.2175 - acc: 0.9548 - gini_normalized: nan - val_loss: 0.2274 - val_acc: 0.9360 - val_gini_normalized: nan\n",
      "Epoch 123/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.2122 - acc: 0.9548 - gini_normalized: nan - val_loss: 0.2307 - val_acc: 0.9420 - val_gini_normalized: nan\n",
      "Epoch 124/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.2120 - acc: 0.9524 - gini_normalized: nan - val_loss: 0.2406 - val_acc: 0.9400 - val_gini_normalized: nan\n",
      "Epoch 125/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.2132 - acc: 0.9520 - gini_normalized: nan - val_loss: 0.2192 - val_acc: 0.9580 - val_gini_normalized: nan\n",
      "Epoch 126/150\n",
      "2500/2500 [==============================] - 0s 79us/step - loss: 0.2056 - acc: 0.9568 - gini_normalized: nan - val_loss: 0.2321 - val_acc: 0.9520 - val_gini_normalized: nan\n",
      "Epoch 127/150\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.2055 - acc: 0.9508 - gini_normalized: nan - val_loss: 0.2302 - val_acc: 0.9420 - val_gini_normalized: nan\n",
      "Epoch 128/150\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.2101 - acc: 0.9532 - gini_normalized: nan - val_loss: 0.2262 - val_acc: 0.9440 - val_gini_normalized: nan\n",
      "Epoch 129/150\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.2027 - acc: 0.9540 - gini_normalized: nan - val_loss: 0.2050 - val_acc: 0.9500 - val_gini_normalized: nan\n",
      "Epoch 130/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.2054 - acc: 0.9552 - gini_normalized: nan - val_loss: 0.2201 - val_acc: 0.9480 - val_gini_normalized: nan\n",
      "Epoch 131/150\n",
      "2500/2500 [==============================] - 0s 79us/step - loss: 0.2113 - acc: 0.9528 - gini_normalized: nan - val_loss: 0.2115 - val_acc: 0.9500 - val_gini_normalized: nan\n",
      "Epoch 132/150\n",
      "2500/2500 [==============================] - 0s 104us/step - loss: 0.2085 - acc: 0.9516 - gini_normalized: nan - val_loss: 0.2256 - val_acc: 0.9500 - val_gini_normalized: nan\n",
      "Epoch 133/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.2009 - acc: 0.9504 - gini_normalized: nan - val_loss: 0.2182 - val_acc: 0.9460 - val_gini_normalized: nan\n",
      "Epoch 134/150\n",
      "2500/2500 [==============================] - 0s 86us/step - loss: 0.1997 - acc: 0.9504 - gini_normalized: nan - val_loss: 0.2433 - val_acc: 0.9400 - val_gini_normalized: nan\n",
      "Epoch 135/150\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.2018 - acc: 0.9552 - gini_normalized: nan - val_loss: 0.2107 - val_acc: 0.9500 - val_gini_normalized: nan\n",
      "Epoch 136/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.2072 - acc: 0.9568 - gini_normalized: nan - val_loss: 0.2087 - val_acc: 0.9460 - val_gini_normalized: nan\n",
      "Epoch 137/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.2005 - acc: 0.9516 - gini_normalized: nan - val_loss: 0.2191 - val_acc: 0.9420 - val_gini_normalized: nan\n",
      "Epoch 138/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.1968 - acc: 0.9524 - gini_normalized: nan - val_loss: 0.2009 - val_acc: 0.9660 - val_gini_normalized: nan\n",
      "Epoch 139/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.2030 - acc: 0.9592 - gini_normalized: nan - val_loss: 0.2356 - val_acc: 0.9480 - val_gini_normalized: nan\n",
      "Epoch 140/150\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.2041 - acc: 0.9512 - gini_normalized: nan - val_loss: 0.2010 - val_acc: 0.9620 - val_gini_normalized: nan\n",
      "Epoch 141/150\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.2004 - acc: 0.9576 - gini_normalized: nan - val_loss: 0.2119 - val_acc: 0.9500 - val_gini_normalized: nan\n",
      "Epoch 142/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.2055 - acc: 0.9528 - gini_normalized: nan - val_loss: 0.2207 - val_acc: 0.9540 - val_gini_normalized: nan\n",
      "Epoch 143/150\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.2031 - acc: 0.9556 - gini_normalized: nan - val_loss: 0.2060 - val_acc: 0.9540 - val_gini_normalized: nan\n",
      "Epoch 144/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.2022 - acc: 0.9528 - gini_normalized: nan - val_loss: 0.2131 - val_acc: 0.9540 - val_gini_normalized: nan\n",
      "Epoch 145/150\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.2032 - acc: 0.9572 - gini_normalized: nan - val_loss: 0.2153 - val_acc: 0.9500 - val_gini_normalized: nan\n",
      "Epoch 146/150\n",
      "2500/2500 [==============================] - 0s 110us/step - loss: 0.2007 - acc: 0.9532 - gini_normalized: nan - val_loss: 0.1992 - val_acc: 0.9560 - val_gini_normalized: nan\n",
      "Epoch 147/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.1968 - acc: 0.9556 - gini_normalized: nan - val_loss: 0.2392 - val_acc: 0.9380 - val_gini_normalized: nan\n",
      "Epoch 148/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.1958 - acc: 0.9512 - gini_normalized: nan - val_loss: 0.2147 - val_acc: 0.9440 - val_gini_normalized: nan\n",
      "Epoch 149/150\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.1938 - acc: 0.9568 - gini_normalized: nan - val_loss: 0.2044 - val_acc: 0.9480 - val_gini_normalized: nan\n",
      "Epoch 150/150\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.1949 - acc: 0.9520 - gini_normalized: nan - val_loss: 0.2066 - val_acc: 0.9540 - val_gini_normalized: nan\n",
      "500/500 [==============================] - 0s 57us/step\n",
      "Train on 2500 samples, validate on 500 samples\n",
      "Epoch 1/150\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.5409 - acc: 0.6744 - gini_normalized: nan - val_loss: 1.4075 - val_acc: 0.6960 - val_gini_normalized: nan\n",
      "Epoch 2/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 1.2907 - acc: 0.7732 - gini_normalized: nan - val_loss: 1.2437 - val_acc: 0.7680 - val_gini_normalized: nan\n",
      "Epoch 3/150\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 1.1348 - acc: 0.8004 - gini_normalized: nan - val_loss: 1.1236 - val_acc: 0.7780 - val_gini_normalized: nan\n",
      "Epoch 4/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 1.0388 - acc: 0.8104 - gini_normalized: nan - val_loss: 1.0013 - val_acc: 0.8040 - val_gini_normalized: nan\n",
      "Epoch 5/150\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.9493 - acc: 0.8232 - gini_normalized: nan - val_loss: 0.9416 - val_acc: 0.8060 - val_gini_normalized: nan\n",
      "Epoch 6/150\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.8731 - acc: 0.8256 - gini_normalized: nan - val_loss: 0.8625 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 7/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.8247 - acc: 0.8340 - gini_normalized: nan - val_loss: 0.8709 - val_acc: 0.8060 - val_gini_normalized: nan\n",
      "Epoch 8/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.7941 - acc: 0.8332 - gini_normalized: nan - val_loss: 0.8247 - val_acc: 0.8180 - val_gini_normalized: nan\n",
      "Epoch 9/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.7648 - acc: 0.8428 - gini_normalized: nan - val_loss: 0.7641 - val_acc: 0.8260 - val_gini_normalized: nan\n",
      "Epoch 10/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.7268 - acc: 0.8404 - gini_normalized: nan - val_loss: 0.7411 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 11/150\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.7110 - acc: 0.8416 - gini_normalized: nan - val_loss: 0.7147 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 12/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.6749 - acc: 0.8460 - gini_normalized: nan - val_loss: 0.6976 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 13/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.6480 - acc: 0.8480 - gini_normalized: nan - val_loss: 0.6711 - val_acc: 0.8520 - val_gini_normalized: nan\n",
      "Epoch 14/150\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.6436 - acc: 0.8552 - gini_normalized: nan - val_loss: 0.6378 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 15/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.6222 - acc: 0.8560 - gini_normalized: nan - val_loss: 0.6464 - val_acc: 0.8600 - val_gini_normalized: nan\n",
      "Epoch 16/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.6181 - acc: 0.8528 - gini_normalized: nan - val_loss: 0.6212 - val_acc: 0.8780 - val_gini_normalized: nan\n",
      "Epoch 17/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.5971 - acc: 0.8632 - gini_normalized: nan - val_loss: 0.6224 - val_acc: 0.8600 - val_gini_normalized: nan\n",
      "Epoch 18/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.5878 - acc: 0.8612 - gini_normalized: nan - val_loss: 0.6104 - val_acc: 0.8720 - val_gini_normalized: nan\n",
      "Epoch 19/150\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.5771 - acc: 0.8684 - gini_normalized: nan - val_loss: 0.6083 - val_acc: 0.8600 - val_gini_normalized: nan\n",
      "Epoch 20/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.5681 - acc: 0.8672 - gini_normalized: nan - val_loss: 0.5884 - val_acc: 0.8720 - val_gini_normalized: nan\n",
      "Epoch 21/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.5525 - acc: 0.8776 - gini_normalized: nan - val_loss: 0.5678 - val_acc: 0.8740 - val_gini_normalized: nan\n",
      "Epoch 22/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.5691 - acc: 0.8724 - gini_normalized: nan - val_loss: 0.5472 - val_acc: 0.8840 - val_gini_normalized: nan\n",
      "Epoch 23/150\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.5510 - acc: 0.8708 - gini_normalized: nan - val_loss: 0.5912 - val_acc: 0.8660 - val_gini_normalized: nan\n",
      "Epoch 24/150\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.5475 - acc: 0.8756 - gini_normalized: nan - val_loss: 0.5388 - val_acc: 0.8780 - val_gini_normalized: nan\n",
      "Epoch 25/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.5280 - acc: 0.8720 - gini_normalized: nan - val_loss: 0.5356 - val_acc: 0.8740 - val_gini_normalized: nan\n",
      "Epoch 26/150\n",
      "2500/2500 [==============================] - 0s 98us/step - loss: 0.5317 - acc: 0.8760 - gini_normalized: nan - val_loss: 0.5334 - val_acc: 0.8820 - val_gini_normalized: nan\n",
      "Epoch 27/150\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.5229 - acc: 0.8756 - gini_normalized: nan - val_loss: 0.4963 - val_acc: 0.8960 - val_gini_normalized: nan\n",
      "Epoch 28/150\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.5034 - acc: 0.8776 - gini_normalized: nan - val_loss: 0.4991 - val_acc: 0.8920 - val_gini_normalized: nan\n",
      "Epoch 29/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.4937 - acc: 0.8812 - gini_normalized: nan - val_loss: 0.4843 - val_acc: 0.8820 - val_gini_normalized: nan\n",
      "Epoch 30/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4854 - acc: 0.8812 - gini_normalized: nan - val_loss: 0.4923 - val_acc: 0.9060 - val_gini_normalized: nan\n",
      "Epoch 31/150\n",
      "2500/2500 [==============================] - 0s 91us/step - loss: 0.4804 - acc: 0.8844 - gini_normalized: nan - val_loss: 0.5324 - val_acc: 0.8940 - val_gini_normalized: nan\n",
      "Epoch 32/150\n",
      "2500/2500 [==============================] - 0s 88us/step - loss: 0.4926 - acc: 0.8796 - gini_normalized: nan - val_loss: 0.5058 - val_acc: 0.8800 - val_gini_normalized: nan\n",
      "Epoch 33/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4731 - acc: 0.8852 - gini_normalized: nan - val_loss: 0.4609 - val_acc: 0.8980 - val_gini_normalized: nan\n",
      "Epoch 34/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.4685 - acc: 0.8888 - gini_normalized: nan - val_loss: 0.4517 - val_acc: 0.9100 - val_gini_normalized: nan\n",
      "Epoch 35/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4673 - acc: 0.8828 - gini_normalized: nan - val_loss: 0.4770 - val_acc: 0.8940 - val_gini_normalized: nan\n",
      "Epoch 36/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4582 - acc: 0.8912 - gini_normalized: nan - val_loss: 0.5035 - val_acc: 0.8840 - val_gini_normalized: nan\n",
      "Epoch 37/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4452 - acc: 0.8888 - gini_normalized: nan - val_loss: 0.4726 - val_acc: 0.8940 - val_gini_normalized: nan\n",
      "Epoch 38/150\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.4642 - acc: 0.8852 - gini_normalized: nan - val_loss: 0.4248 - val_acc: 0.9080 - val_gini_normalized: nan\n",
      "Epoch 39/150\n",
      "2500/2500 [==============================] - 0s 86us/step - loss: 0.4428 - acc: 0.8912 - gini_normalized: nan - val_loss: 0.4310 - val_acc: 0.9020 - val_gini_normalized: nan\n",
      "Epoch 40/150\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.4461 - acc: 0.8924 - gini_normalized: nan - val_loss: 0.4304 - val_acc: 0.8980 - val_gini_normalized: nan\n",
      "Epoch 41/150\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.4474 - acc: 0.8868 - gini_normalized: nan - val_loss: 0.4409 - val_acc: 0.9040 - val_gini_normalized: nan\n",
      "Epoch 42/150\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4255 - acc: 0.8956 - gini_normalized: nan - val_loss: 0.4360 - val_acc: 0.9060 - val_gini_normalized: nan\n",
      "Epoch 43/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4185 - acc: 0.8916 - gini_normalized: nan - val_loss: 0.4329 - val_acc: 0.9120 - val_gini_normalized: nan\n",
      "Epoch 44/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4202 - acc: 0.8928 - gini_normalized: nan - val_loss: 0.4171 - val_acc: 0.9100 - val_gini_normalized: nan\n",
      "Epoch 45/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4224 - acc: 0.8960 - gini_normalized: nan - val_loss: 0.4423 - val_acc: 0.9020 - val_gini_normalized: nan\n",
      "Epoch 46/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4256 - acc: 0.8944 - gini_normalized: nan - val_loss: 0.4021 - val_acc: 0.9060 - val_gini_normalized: nan\n",
      "Epoch 47/150\n",
      "2500/2500 [==============================] - 0s 85us/step - loss: 0.4193 - acc: 0.8912 - gini_normalized: nan - val_loss: 0.4013 - val_acc: 0.9120 - val_gini_normalized: nan\n",
      "Epoch 48/150\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.4038 - acc: 0.8956 - gini_normalized: nan - val_loss: 0.4605 - val_acc: 0.9040 - val_gini_normalized: nan\n",
      "Epoch 49/150\n",
      "2500/2500 [==============================] - 0s 88us/step - loss: 0.4232 - acc: 0.8924 - gini_normalized: nan - val_loss: 0.4071 - val_acc: 0.9240 - val_gini_normalized: nan\n",
      "Epoch 50/150\n",
      "2500/2500 [==============================] - 0s 85us/step - loss: 0.4143 - acc: 0.8944 - gini_normalized: nan - val_loss: 0.4258 - val_acc: 0.9080 - val_gini_normalized: nan\n",
      "Epoch 51/150\n",
      "2500/2500 [==============================] - 0s 88us/step - loss: 0.4178 - acc: 0.8924 - gini_normalized: nan - val_loss: 0.4058 - val_acc: 0.9160 - val_gini_normalized: nan\n",
      "Epoch 52/150\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.4109 - acc: 0.8952 - gini_normalized: nan - val_loss: 0.3872 - val_acc: 0.9120 - val_gini_normalized: nan\n",
      "Epoch 53/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4082 - acc: 0.8952 - gini_normalized: nan - val_loss: 0.3912 - val_acc: 0.9200 - val_gini_normalized: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/150\n",
      "2500/2500 [==============================] - 0s 94us/step - loss: 0.4105 - acc: 0.8960 - gini_normalized: nan - val_loss: 0.3765 - val_acc: 0.9140 - val_gini_normalized: nan\n",
      "Epoch 55/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.4023 - acc: 0.8980 - gini_normalized: nan - val_loss: 0.3777 - val_acc: 0.9080 - val_gini_normalized: nan\n",
      "Epoch 56/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3960 - acc: 0.8944 - gini_normalized: nan - val_loss: 0.3753 - val_acc: 0.9160 - val_gini_normalized: nan\n",
      "Epoch 57/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.3924 - acc: 0.9016 - gini_normalized: nan - val_loss: 0.3909 - val_acc: 0.8980 - val_gini_normalized: nan\n",
      "Epoch 58/150\n",
      "2500/2500 [==============================] - 0s 52us/step - loss: 0.4013 - acc: 0.8968 - gini_normalized: nan - val_loss: 0.4102 - val_acc: 0.9080 - val_gini_normalized: nan\n",
      "Epoch 59/150\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3912 - acc: 0.8984 - gini_normalized: nan - val_loss: 0.3813 - val_acc: 0.9140 - val_gini_normalized: nan\n",
      "Epoch 60/150\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.3782 - acc: 0.9008 - gini_normalized: nan - val_loss: 0.3623 - val_acc: 0.9220 - val_gini_normalized: nan\n",
      "Epoch 61/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.3794 - acc: 0.8976 - gini_normalized: nan - val_loss: 0.3663 - val_acc: 0.9160 - val_gini_normalized: nan\n",
      "Epoch 62/150\n",
      "2500/2500 [==============================] - 0s 79us/step - loss: 0.3857 - acc: 0.8996 - gini_normalized: nan - val_loss: 0.3690 - val_acc: 0.9120 - val_gini_normalized: nan\n",
      "Epoch 63/150\n",
      "2500/2500 [==============================] - 0s 91us/step - loss: 0.3801 - acc: 0.8992 - gini_normalized: nan - val_loss: 0.3568 - val_acc: 0.9300 - val_gini_normalized: nan\n",
      "Epoch 64/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.3706 - acc: 0.8984 - gini_normalized: nan - val_loss: 0.3767 - val_acc: 0.9160 - val_gini_normalized: nan\n",
      "Epoch 65/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.3767 - acc: 0.9028 - gini_normalized: nan - val_loss: 0.3608 - val_acc: 0.9160 - val_gini_normalized: nan\n",
      "Epoch 66/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.3703 - acc: 0.8988 - gini_normalized: nan - val_loss: 0.3658 - val_acc: 0.9200 - val_gini_normalized: nan\n",
      "Epoch 67/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.3642 - acc: 0.9016 - gini_normalized: nan - val_loss: 0.3479 - val_acc: 0.9120 - val_gini_normalized: nan\n",
      "Epoch 68/150\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.3755 - acc: 0.9000 - gini_normalized: nan - val_loss: 0.3501 - val_acc: 0.9220 - val_gini_normalized: nan\n",
      "Epoch 69/150\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3924 - acc: 0.8948 - gini_normalized: nan - val_loss: 0.4300 - val_acc: 0.9040 - val_gini_normalized: nan\n",
      "Epoch 70/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.3790 - acc: 0.9044 - gini_normalized: nan - val_loss: 0.4433 - val_acc: 0.8840 - val_gini_normalized: nan\n",
      "Epoch 71/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3786 - acc: 0.9024 - gini_normalized: nan - val_loss: 0.3591 - val_acc: 0.9160 - val_gini_normalized: nan\n",
      "Epoch 72/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.3613 - acc: 0.9040 - gini_normalized: nan - val_loss: 0.3406 - val_acc: 0.9320 - val_gini_normalized: nan\n",
      "Epoch 73/150\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.3613 - acc: 0.9016 - gini_normalized: nan - val_loss: 0.3499 - val_acc: 0.9160 - val_gini_normalized: nan\n",
      "Epoch 74/150\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.3544 - acc: 0.9080 - gini_normalized: nan - val_loss: 0.3539 - val_acc: 0.9100 - val_gini_normalized: nan\n",
      "Epoch 75/150\n",
      "2500/2500 [==============================] - 0s 99us/step - loss: 0.3663 - acc: 0.9020 - gini_normalized: nan - val_loss: 0.3310 - val_acc: 0.9200 - val_gini_normalized: nan\n",
      "Epoch 76/150\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.3650 - acc: 0.9056 - gini_normalized: nan - val_loss: 0.3335 - val_acc: 0.9260 - val_gini_normalized: nan\n",
      "Epoch 77/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.3532 - acc: 0.9092 - gini_normalized: nan - val_loss: 0.3361 - val_acc: 0.9220 - val_gini_normalized: nan\n",
      "Epoch 78/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.3548 - acc: 0.9060 - gini_normalized: nan - val_loss: 0.3301 - val_acc: 0.9160 - val_gini_normalized: nan\n",
      "Epoch 79/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.3687 - acc: 0.9032 - gini_normalized: nan - val_loss: 0.3309 - val_acc: 0.9120 - val_gini_normalized: nan\n",
      "Epoch 80/150\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.3501 - acc: 0.9056 - gini_normalized: nan - val_loss: 0.3296 - val_acc: 0.9280 - val_gini_normalized: nan\n",
      "Epoch 81/150\n",
      "2500/2500 [==============================] - 0s 96us/step - loss: 0.3489 - acc: 0.9088 - gini_normalized: nan - val_loss: 0.3362 - val_acc: 0.9160 - val_gini_normalized: nan\n",
      "Epoch 82/150\n",
      "2500/2500 [==============================] - 0s 92us/step - loss: 0.3337 - acc: 0.9032 - gini_normalized: nan - val_loss: 0.3513 - val_acc: 0.9040 - val_gini_normalized: nan\n",
      "Epoch 83/150\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.3434 - acc: 0.9008 - gini_normalized: nan - val_loss: 0.3312 - val_acc: 0.9140 - val_gini_normalized: nan\n",
      "Epoch 84/150\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.3423 - acc: 0.9028 - gini_normalized: nan - val_loss: 0.3361 - val_acc: 0.9160 - val_gini_normalized: nan\n",
      "Epoch 85/150\n",
      "2500/2500 [==============================] - 0s 102us/step - loss: 0.3327 - acc: 0.9044 - gini_normalized: nan - val_loss: 0.3366 - val_acc: 0.9080 - val_gini_normalized: nan\n",
      "Epoch 86/150\n",
      "2500/2500 [==============================] - 0s 98us/step - loss: 0.3497 - acc: 0.9052 - gini_normalized: nan - val_loss: 0.3260 - val_acc: 0.9120 - val_gini_normalized: nan\n",
      "Epoch 87/150\n",
      "2500/2500 [==============================] - 0s 106us/step - loss: 0.3484 - acc: 0.9020 - gini_normalized: nan - val_loss: 0.3348 - val_acc: 0.9220 - val_gini_normalized: nan\n",
      "Epoch 88/150\n",
      "2500/2500 [==============================] - 0s 88us/step - loss: 0.3242 - acc: 0.9052 - gini_normalized: nan - val_loss: 0.3135 - val_acc: 0.9280 - val_gini_normalized: nan\n",
      "Epoch 89/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.3445 - acc: 0.9044 - gini_normalized: nan - val_loss: 0.3404 - val_acc: 0.9180 - val_gini_normalized: nan\n",
      "Epoch 90/150\n",
      "2500/2500 [==============================] - 0s 84us/step - loss: 0.3263 - acc: 0.9084 - gini_normalized: nan - val_loss: 0.3307 - val_acc: 0.9200 - val_gini_normalized: nan\n",
      "Epoch 91/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.3430 - acc: 0.9060 - gini_normalized: nan - val_loss: 0.3245 - val_acc: 0.9200 - val_gini_normalized: nan\n",
      "Epoch 92/150\n",
      "2500/2500 [==============================] - 0s 104us/step - loss: 0.3282 - acc: 0.9052 - gini_normalized: nan - val_loss: 0.3542 - val_acc: 0.8940 - val_gini_normalized: nan\n",
      "Epoch 93/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.3262 - acc: 0.9068 - gini_normalized: nan - val_loss: 0.3214 - val_acc: 0.9220 - val_gini_normalized: nan\n",
      "Epoch 94/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.3213 - acc: 0.9056 - gini_normalized: nan - val_loss: 0.3393 - val_acc: 0.9100 - val_gini_normalized: nan\n",
      "Epoch 95/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3372 - acc: 0.9032 - gini_normalized: nan - val_loss: 0.3076 - val_acc: 0.9260 - val_gini_normalized: nan\n",
      "Epoch 96/150\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.3178 - acc: 0.9100 - gini_normalized: nan - val_loss: 0.3284 - val_acc: 0.9060 - val_gini_normalized: nan\n",
      "Epoch 97/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.3208 - acc: 0.9084 - gini_normalized: nan - val_loss: 0.3035 - val_acc: 0.9260 - val_gini_normalized: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/150\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.3161 - acc: 0.9060 - gini_normalized: nan - val_loss: 0.3432 - val_acc: 0.8960 - val_gini_normalized: nan\n",
      "Epoch 99/150\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.3202 - acc: 0.9088 - gini_normalized: nan - val_loss: 0.3006 - val_acc: 0.9280 - val_gini_normalized: nan\n",
      "Epoch 100/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.3156 - acc: 0.9104 - gini_normalized: nan - val_loss: 0.3620 - val_acc: 0.9180 - val_gini_normalized: nan\n",
      "Epoch 101/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.3153 - acc: 0.9096 - gini_normalized: nan - val_loss: 0.3064 - val_acc: 0.9240 - val_gini_normalized: nan\n",
      "Epoch 102/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3068 - acc: 0.9068 - gini_normalized: nan - val_loss: 0.3032 - val_acc: 0.9280 - val_gini_normalized: nan\n",
      "Epoch 103/150\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.3105 - acc: 0.9116 - gini_normalized: nan - val_loss: 0.3075 - val_acc: 0.9260 - val_gini_normalized: nan\n",
      "Epoch 104/150\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3115 - acc: 0.9064 - gini_normalized: nan - val_loss: 0.3142 - val_acc: 0.9020 - val_gini_normalized: nan\n",
      "Epoch 105/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.3006 - acc: 0.9136 - gini_normalized: nan - val_loss: 0.2970 - val_acc: 0.9220 - val_gini_normalized: nan\n",
      "Epoch 106/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.3000 - acc: 0.9080 - gini_normalized: nan - val_loss: 0.2985 - val_acc: 0.9240 - val_gini_normalized: nan\n",
      "Epoch 107/150\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3025 - acc: 0.9080 - gini_normalized: nan - val_loss: 0.3091 - val_acc: 0.9300 - val_gini_normalized: nan\n",
      "Epoch 108/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.3056 - acc: 0.9080 - gini_normalized: nan - val_loss: 0.2915 - val_acc: 0.9260 - val_gini_normalized: nan\n",
      "Epoch 109/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.3050 - acc: 0.9076 - gini_normalized: nan - val_loss: 0.3123 - val_acc: 0.9160 - val_gini_normalized: nan\n",
      "Epoch 110/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.2978 - acc: 0.9124 - gini_normalized: nan - val_loss: 0.3233 - val_acc: 0.9160 - val_gini_normalized: nan\n",
      "Epoch 111/150\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.2988 - acc: 0.9100 - gini_normalized: nan - val_loss: 0.3165 - val_acc: 0.9100 - val_gini_normalized: nan\n",
      "Epoch 112/150\n",
      "2500/2500 [==============================] - 0s 87us/step - loss: 0.2947 - acc: 0.9160 - gini_normalized: nan - val_loss: 0.2981 - val_acc: 0.9180 - val_gini_normalized: nan\n",
      "Epoch 113/150\n",
      "2500/2500 [==============================] - 0s 96us/step - loss: 0.3084 - acc: 0.9084 - gini_normalized: nan - val_loss: 0.2800 - val_acc: 0.9360 - val_gini_normalized: nan\n",
      "Epoch 114/150\n",
      "2500/2500 [==============================] - 0s 86us/step - loss: 0.2969 - acc: 0.9124 - gini_normalized: nan - val_loss: 0.2890 - val_acc: 0.9360 - val_gini_normalized: nan\n",
      "Epoch 115/150\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.2959 - acc: 0.9076 - gini_normalized: nan - val_loss: 0.3007 - val_acc: 0.9120 - val_gini_normalized: nan\n",
      "Epoch 116/150\n",
      "2500/2500 [==============================] - 0s 108us/step - loss: 0.2964 - acc: 0.9100 - gini_normalized: nan - val_loss: 0.3407 - val_acc: 0.8900 - val_gini_normalized: nan\n",
      "Epoch 117/150\n",
      "2500/2500 [==============================] - 0s 102us/step - loss: 0.2926 - acc: 0.9108 - gini_normalized: nan - val_loss: 0.3026 - val_acc: 0.9140 - val_gini_normalized: nan\n",
      "Epoch 118/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.2887 - acc: 0.9120 - gini_normalized: nan - val_loss: 0.3159 - val_acc: 0.9040 - val_gini_normalized: nan\n",
      "Epoch 119/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.2939 - acc: 0.9136 - gini_normalized: nan - val_loss: 0.2808 - val_acc: 0.9340 - val_gini_normalized: nan\n",
      "Epoch 120/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.3065 - acc: 0.9108 - gini_normalized: nan - val_loss: 0.3079 - val_acc: 0.9100 - val_gini_normalized: nan\n",
      "Epoch 121/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.2892 - acc: 0.9092 - gini_normalized: nan - val_loss: 0.2835 - val_acc: 0.9300 - val_gini_normalized: nan\n",
      "Epoch 122/150\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.3030 - acc: 0.9108 - gini_normalized: nan - val_loss: 0.2857 - val_acc: 0.9280 - val_gini_normalized: nan\n",
      "Epoch 123/150\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.2846 - acc: 0.9128 - gini_normalized: nan - val_loss: 0.3018 - val_acc: 0.9220 - val_gini_normalized: nan\n",
      "Epoch 124/150\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.2925 - acc: 0.9124 - gini_normalized: nan - val_loss: 0.2876 - val_acc: 0.9280 - val_gini_normalized: nan\n",
      "Epoch 125/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.2910 - acc: 0.9124 - gini_normalized: nan - val_loss: 0.2821 - val_acc: 0.9300 - val_gini_normalized: nan\n",
      "Epoch 126/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.2852 - acc: 0.9112 - gini_normalized: nan - val_loss: 0.2742 - val_acc: 0.9360 - val_gini_normalized: nan\n",
      "Epoch 127/150\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.2875 - acc: 0.9164 - gini_normalized: nan - val_loss: 0.2728 - val_acc: 0.9360 - val_gini_normalized: nan\n",
      "Epoch 128/150\n",
      "2500/2500 [==============================] - 0s 117us/step - loss: 0.2840 - acc: 0.9112 - gini_normalized: nan - val_loss: 0.3032 - val_acc: 0.9140 - val_gini_normalized: nan\n",
      "Epoch 129/150\n",
      "2500/2500 [==============================] - 0s 87us/step - loss: 0.2890 - acc: 0.9120 - gini_normalized: nan - val_loss: 0.2756 - val_acc: 0.9240 - val_gini_normalized: nan\n",
      "Epoch 130/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.2848 - acc: 0.9152 - gini_normalized: nan - val_loss: 0.2883 - val_acc: 0.9260 - val_gini_normalized: nan\n",
      "Epoch 131/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.2790 - acc: 0.9104 - gini_normalized: nan - val_loss: 0.2829 - val_acc: 0.9240 - val_gini_normalized: nan\n",
      "Epoch 132/150\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.2873 - acc: 0.9124 - gini_normalized: nan - val_loss: 0.2669 - val_acc: 0.9340 - val_gini_normalized: nan\n",
      "Epoch 133/150\n",
      "2500/2500 [==============================] - 0s 106us/step - loss: 0.2843 - acc: 0.9140 - gini_normalized: nan - val_loss: 0.2945 - val_acc: 0.9100 - val_gini_normalized: nan\n",
      "Epoch 134/150\n",
      "2500/2500 [==============================] - 0s 94us/step - loss: 0.2792 - acc: 0.9148 - gini_normalized: nan - val_loss: 0.2792 - val_acc: 0.9300 - val_gini_normalized: nan\n",
      "Epoch 135/150\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.2840 - acc: 0.9124 - gini_normalized: nan - val_loss: 0.2772 - val_acc: 0.9280 - val_gini_normalized: nan\n",
      "Epoch 136/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.2849 - acc: 0.9164 - gini_normalized: nan - val_loss: 0.2903 - val_acc: 0.9140 - val_gini_normalized: nan\n",
      "Epoch 137/150\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.2767 - acc: 0.9168 - gini_normalized: nan - val_loss: 0.2772 - val_acc: 0.9340 - val_gini_normalized: nan\n",
      "Epoch 138/150\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.2747 - acc: 0.9160 - gini_normalized: nan - val_loss: 0.2711 - val_acc: 0.9300 - val_gini_normalized: nan\n",
      "Epoch 139/150\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.2889 - acc: 0.9152 - gini_normalized: nan - val_loss: 0.2695 - val_acc: 0.9300 - val_gini_normalized: nan\n",
      "Epoch 140/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.2751 - acc: 0.9164 - gini_normalized: nan - val_loss: 0.2652 - val_acc: 0.9400 - val_gini_normalized: nan\n",
      "Epoch 141/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.2776 - acc: 0.9160 - gini_normalized: nan - val_loss: 0.2708 - val_acc: 0.9340 - val_gini_normalized: nan\n",
      "Epoch 142/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.2752 - acc: 0.9156 - gini_normalized: nan - val_loss: 0.2659 - val_acc: 0.9420 - val_gini_normalized: nan\n",
      "Epoch 143/150\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 0.2798 - acc: 0.9113 - gini_normalized: n - 0s 64us/step - loss: 0.2734 - acc: 0.9164 - gini_normalized: nan - val_loss: 0.2685 - val_acc: 0.9340 - val_gini_normalized: nan\n",
      "Epoch 144/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.2760 - acc: 0.9132 - gini_normalized: nan - val_loss: 0.2814 - val_acc: 0.9200 - val_gini_normalized: nan\n",
      "Epoch 145/150\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.2774 - acc: 0.9144 - gini_normalized: nan - val_loss: 0.2596 - val_acc: 0.9340 - val_gini_normalized: nan\n",
      "Epoch 146/150\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.2737 - acc: 0.9160 - gini_normalized: nan - val_loss: 0.2658 - val_acc: 0.9340 - val_gini_normalized: nan\n",
      "Epoch 147/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.2749 - acc: 0.9152 - gini_normalized: nan - val_loss: 0.2730 - val_acc: 0.9260 - val_gini_normalized: nan\n",
      "Epoch 148/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.2724 - acc: 0.9104 - gini_normalized: nan - val_loss: 0.2729 - val_acc: 0.9200 - val_gini_normalized: nan\n",
      "Epoch 149/150\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.2722 - acc: 0.9176 - gini_normalized: nan - val_loss: 0.2630 - val_acc: 0.9400 - val_gini_normalized: nan\n",
      "Epoch 150/150\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.2760 - acc: 0.9176 - gini_normalized: nan - val_loss: 0.3174 - val_acc: 0.9000 - val_gini_normalized: nan\n",
      "500/500 [==============================] - 0s 40us/step\n"
     ]
    }
   ],
   "source": [
    "## original true covariates\n",
    "model_nl1 = Sequential()\n",
    "model_nl1.add(Dense(100, input_dim=7, kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model_nl1.add(Dense(10, kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model_nl1.add(Dense(1, activation='sigmoid'))\n",
    "model_nl1.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',gini_normalized])\n",
    "trace_nl1 = model_nl1.fit(x_nonlinear_true[0:2500,0:7], y_nonlinear[0:2500],epochs=150,batch_size=64, \\\n",
    "                    validation_data=(x_nonlinear_true[2500:3000,0:7], y_nonlinear[2500:3000]))\n",
    "score_nl1 = model_nl1.evaluate(x_nonlinear_true[2500:3000,0:7], y_nonlinear[2500:3000], batch_size=64)\n",
    "\n",
    "## all original covariates: 0:7,15:20\n",
    "model_nl5 = Sequential()\n",
    "model_nl5.add(Dense(100, input_dim=12, kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model_nl5.add(Dense(10, kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model_nl5.add(Dense(1, activation='sigmoid'))\n",
    "model_nl5.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',gini_normalized])\n",
    "trace_nl5 = model_nl5.fit(np.concatenate((x_nonlinear_true[0:2500,0:7],x_nonlinear_true[0:2500,15:20]), axis=1), y_nonlinear[0:2500],epochs=150,batch_size=64, \\\n",
    "                    validation_data=(np.concatenate((x_nonlinear_true[2500:3000,0:7],x_nonlinear_true[2500:3000,15:20]), axis=1), y_nonlinear[2500:3000]))\n",
    "score_nl5 = model_nl5.evaluate(np.concatenate((x_nonlinear_true[2500:3000,0:7],x_nonlinear_true[2500:3000,15:20]), axis=1), y_nonlinear[2500:3000], batch_size=64)\n",
    "\n",
    "## true features used to create nonlinear relationships\n",
    "model_nl2 = Sequential()\n",
    "model_nl2.add(Dense(100, input_dim=np.shape(x_nonlinear_true)[1], kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model_nl2.add(Dense(10, kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model_nl2.add(Dense(1, activation='sigmoid'))\n",
    "model_nl2.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',gini_normalized])\n",
    "trace_nl2 = model_nl2.fit(x_nonlinear_true[0:2500,:], y_nonlinear[0:2500],epochs=150,batch_size=64, \\\n",
    "                    validation_data=(x_nonlinear_true[2500:3000,:], y_nonlinear[2500:3000]))\n",
    "score_nl2 = model_nl2.evaluate(x_nonlinear_true[2500:3000,:], y_nonlinear[2500:3000], batch_size=64)\n",
    "\n",
    "## all extra features\n",
    "model_nl3 = Sequential()\n",
    "model_nl3.add(Dense(100, input_dim=np.shape(x_nonlinear_extra)[1], kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model_nl3.add(Dense(10, kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model_nl3.add(Dense(1, activation='sigmoid'))\n",
    "model_nl3.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',gini_normalized])\n",
    "trace_nl3 = model_nl3.fit(x_nonlinear_extra[0:2500,:], y_nonlinear[0:2500],epochs=150,batch_size=64, \\\n",
    "                    validation_data=(x_nonlinear_extra[2500:3000,:], y_nonlinear[2500:3000]))\n",
    "score_nl3 = model_nl3.evaluate(x_nonlinear_extra[2500:3000,:], y_nonlinear[2500:3000], batch_size=64)\n",
    "\n",
    "## selected features\n",
    "model_nl4 = Sequential()\n",
    "model_nl4.add(Dense(100, input_dim=len(selected_features_nl), kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model_nl4.add(Dense(10, kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model_nl4.add(Dense(1, activation='sigmoid'))\n",
    "model_nl4.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',gini_normalized])\n",
    "trace_nl4 = model_nl4.fit(x_nonlinear_extra[0:2500,selected_features_nl], y_nonlinear[0:2500],epochs=150,batch_size=64, \\\n",
    "                    validation_data=(x_nonlinear_extra[2500:3000,selected_features_nl], y_nonlinear[2500:3000]))\n",
    "score_nl4 = model_nl4.evaluate(x_nonlinear_extra[2500:3000,selected_features_nl], y_nonlinear[2500:3000], batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-linear model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEOCAYAAACQMUyOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsgJujDExygq4McbEqP8Dzmvg43rDlZMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21eb8b962e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Non-linear model\")\n",
    "fig = plt.figure(figsize=(10*.55,7*.55))\n",
    "plt.title('Hidden layers: (100,10)')\n",
    "#plt.plot(trace_nl1.history['val_acc'],label='true features', color=\"green\")\n",
    "plt.plot(trace_nl2.history['val_acc'],label='original true covariates', color=\"red\")\n",
    "plt.plot(trace_nl3.history['val_acc'],label='all engineered features', color=\"orange\")\n",
    "plt.plot(trace_nl4.history['val_acc'],label='feature selection', color=\"purple\")\n",
    "plt.plot(trace_nl5.history['val_acc'],label='all original covariates', color=\"blue\")\n",
    "plt.legend(loc=4)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For complex, non-linear models, feature engineering as well as removing irrelevant covariates can greatly improve neural network performance. The best performance was seen using original true covariates (no feature engineering, but removing irrelevant covariates). This was closely followed by using feature selection and using all engineered features, suggesting that when the true underlying relevant covariates are difficult to discern, feature engineering may be helpful. Surprisingly, including only the true features (that were then used in a non-linear model) resulted in worse performance, potentially because the neural network found it difficult to construct the non-linear underlying relationships.  \n",
    "\n",
    "Compared to a linear model, the neural network was actually able to achieve higher overall validation accuracy with a nonlinear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2500 samples, validate on 500 samples\n",
      "Epoch 1/150\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8523 - acc: 0.6124 - gini_normalized: nan - val_loss: 0.8210 - val_acc: 0.6560 - val_gini_normalized: nan\n",
      "Epoch 2/150\n",
      "2500/2500 [==============================] - 0s 85us/step - loss: 0.7968 - acc: 0.6700 - gini_normalized: nan - val_loss: 0.7743 - val_acc: 0.6940 - val_gini_normalized: nan\n",
      "Epoch 3/150\n",
      "2500/2500 [==============================] - 0s 89us/step - loss: 0.7537 - acc: 0.7072 - gini_normalized: nan - val_loss: 0.7346 - val_acc: 0.7220 - val_gini_normalized: nan\n",
      "Epoch 4/150\n",
      "2500/2500 [==============================] - 0s 86us/step - loss: 0.7173 - acc: 0.7328 - gini_normalized: nan - val_loss: 0.7019 - val_acc: 0.7300 - val_gini_normalized: nan\n",
      "Epoch 5/150\n",
      "2500/2500 [==============================] - 0s 84us/step - loss: 0.6875 - acc: 0.7404 - gini_normalized: nan - val_loss: 0.6760 - val_acc: 0.7440 - val_gini_normalized: nan\n",
      "Epoch 6/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.6633 - acc: 0.7472 - gini_normalized: nan - val_loss: 0.6539 - val_acc: 0.7360 - val_gini_normalized: nan\n",
      "Epoch 7/150\n",
      "2500/2500 [==============================] - 0s 89us/step - loss: 0.6433 - acc: 0.7488 - gini_normalized: nan - val_loss: 0.6359 - val_acc: 0.7580 - val_gini_normalized: nan\n",
      "Epoch 8/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.6277 - acc: 0.7524 - gini_normalized: nan - val_loss: 0.6226 - val_acc: 0.7540 - val_gini_normalized: nan\n",
      "Epoch 9/150\n",
      "2500/2500 [==============================] - 0s 87us/step - loss: 0.6151 - acc: 0.7548 - gini_normalized: nan - val_loss: 0.6114 - val_acc: 0.7540 - val_gini_normalized: nan\n",
      "Epoch 10/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.6052 - acc: 0.7584 - gini_normalized: nan - val_loss: 0.6027 - val_acc: 0.7620 - val_gini_normalized: nan\n",
      "Epoch 11/150\n",
      "2500/2500 [==============================] - 0s 86us/step - loss: 0.5974 - acc: 0.7632 - gini_normalized: nan - val_loss: 0.5953 - val_acc: 0.7740 - val_gini_normalized: nan\n",
      "Epoch 12/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.5906 - acc: 0.7672 - gini_normalized: nan - val_loss: 0.5889 - val_acc: 0.7760 - val_gini_normalized: nan\n",
      "Epoch 13/150\n",
      "2500/2500 [==============================] - 0s 86us/step - loss: 0.5849 - acc: 0.7760 - gini_normalized: nan - val_loss: 0.5841 - val_acc: 0.7800 - val_gini_normalized: nan\n",
      "Epoch 14/150\n",
      "2500/2500 [==============================] - 0s 84us/step - loss: 0.5800 - acc: 0.7764 - gini_normalized: nan - val_loss: 0.5794 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 15/150\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.5750 - acc: 0.7832 - gini_normalized: nan - val_loss: 0.5752 - val_acc: 0.7740 - val_gini_normalized: nan\n",
      "Epoch 16/150\n",
      "2500/2500 [==============================] - 0s 86us/step - loss: 0.5703 - acc: 0.7784 - gini_normalized: nan - val_loss: 0.5704 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 17/150\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.5657 - acc: 0.7864 - gini_normalized: nan - val_loss: 0.5662 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 18/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.5614 - acc: 0.7828 - gini_normalized: nan - val_loss: 0.5618 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 19/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.5573 - acc: 0.7900 - gini_normalized: nan - val_loss: 0.5580 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 20/150\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.5537 - acc: 0.7896 - gini_normalized: nan - val_loss: 0.5556 - val_acc: 0.7780 - val_gini_normalized: nan\n",
      "Epoch 21/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.5503 - acc: 0.7876 - gini_normalized: nan - val_loss: 0.5517 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 22/150\n",
      "2500/2500 [==============================] - 0s 84us/step - loss: 0.5466 - acc: 0.7928 - gini_normalized: nan - val_loss: 0.5486 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 23/150\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.5437 - acc: 0.7944 - gini_normalized: nan - val_loss: 0.5461 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 24/150\n",
      "2500/2500 [==============================] - 0s 84us/step - loss: 0.5405 - acc: 0.7980 - gini_normalized: nan - val_loss: 0.5441 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 25/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.5376 - acc: 0.7952 - gini_normalized: nan - val_loss: 0.5411 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 26/150\n",
      "2500/2500 [==============================] - 0s 85us/step - loss: 0.5344 - acc: 0.7968 - gini_normalized: nan - val_loss: 0.5382 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 27/150\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.5313 - acc: 0.7952 - gini_normalized: nan - val_loss: 0.5361 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 28/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.5284 - acc: 0.7972 - gini_normalized: nan - val_loss: 0.5329 - val_acc: 0.7760 - val_gini_normalized: nan\n",
      "Epoch 29/150\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.5259 - acc: 0.7952 - gini_normalized: nan - val_loss: 0.5314 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 30/150\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.5232 - acc: 0.7976 - gini_normalized: nan - val_loss: 0.5290 - val_acc: 0.7760 - val_gini_normalized: nan\n",
      "Epoch 31/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.5208 - acc: 0.7984 - gini_normalized: nan - val_loss: 0.5273 - val_acc: 0.7780 - val_gini_normalized: nan\n",
      "Epoch 32/150\n",
      "2500/2500 [==============================] - 0s 87us/step - loss: 0.5183 - acc: 0.7976 - gini_normalized: nan - val_loss: 0.5244 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 33/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.5164 - acc: 0.7992 - gini_normalized: nan - val_loss: 0.5228 - val_acc: 0.7780 - val_gini_normalized: nan\n",
      "Epoch 34/150\n",
      "2500/2500 [==============================] - 0s 85us/step - loss: 0.5138 - acc: 0.7980 - gini_normalized: nan - val_loss: 0.5207 - val_acc: 0.7780 - val_gini_normalized: nan\n",
      "Epoch 35/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.5118 - acc: 0.8016 - gini_normalized: nan - val_loss: 0.5198 - val_acc: 0.7740 - val_gini_normalized: nan\n",
      "Epoch 36/150\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.5101 - acc: 0.8004 - gini_normalized: nan - val_loss: 0.5184 - val_acc: 0.7740 - val_gini_normalized: nan\n",
      "Epoch 37/150\n",
      "2500/2500 [==============================] - 0s 85us/step - loss: 0.5079 - acc: 0.8020 - gini_normalized: nan - val_loss: 0.5151 - val_acc: 0.7760 - val_gini_normalized: nan\n",
      "Epoch 38/150\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.5061 - acc: 0.8008 - gini_normalized: nan - val_loss: 0.5144 - val_acc: 0.7680 - val_gini_normalized: nan\n",
      "Epoch 39/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.5045 - acc: 0.8012 - gini_normalized: nan - val_loss: 0.5124 - val_acc: 0.7760 - val_gini_normalized: nan\n",
      "Epoch 40/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.5028 - acc: 0.7972 - gini_normalized: nan - val_loss: 0.5130 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 41/150\n",
      "2500/2500 [==============================] - 0s 79us/step - loss: 0.5015 - acc: 0.8052 - gini_normalized: nan - val_loss: 0.5108 - val_acc: 0.7740 - val_gini_normalized: nan\n",
      "Epoch 42/150\n",
      "2500/2500 [==============================] - 0s 85us/step - loss: 0.5001 - acc: 0.8020 - gini_normalized: nan - val_loss: 0.5091 - val_acc: 0.7760 - val_gini_normalized: nan\n",
      "Epoch 43/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.4983 - acc: 0.8016 - gini_normalized: nan - val_loss: 0.5079 - val_acc: 0.7800 - val_gini_normalized: nan\n",
      "Epoch 44/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 85us/step - loss: 0.4972 - acc: 0.8040 - gini_normalized: nan - val_loss: 0.5064 - val_acc: 0.7800 - val_gini_normalized: nan\n",
      "Epoch 45/150\n",
      "2500/2500 [==============================] - 0s 87us/step - loss: 0.4960 - acc: 0.8088 - gini_normalized: nan - val_loss: 0.5055 - val_acc: 0.7800 - val_gini_normalized: nan\n",
      "Epoch 46/150\n",
      "2500/2500 [==============================] - 0s 88us/step - loss: 0.4945 - acc: 0.8072 - gini_normalized: nan - val_loss: 0.5055 - val_acc: 0.7760 - val_gini_normalized: nan\n",
      "Epoch 47/150\n",
      "2500/2500 [==============================] - 0s 86us/step - loss: 0.4933 - acc: 0.8056 - gini_normalized: nan - val_loss: 0.5037 - val_acc: 0.7740 - val_gini_normalized: nan\n",
      "Epoch 48/150\n",
      "2500/2500 [==============================] - 0s 87us/step - loss: 0.4918 - acc: 0.8040 - gini_normalized: nan - val_loss: 0.5027 - val_acc: 0.7740 - val_gini_normalized: nan\n",
      "Epoch 49/150\n",
      "2500/2500 [==============================] - 0s 93us/step - loss: 0.4911 - acc: 0.8120 - gini_normalized: nan - val_loss: 0.5027 - val_acc: 0.7780 - val_gini_normalized: nan\n",
      "Epoch 50/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.4901 - acc: 0.8076 - gini_normalized: nan - val_loss: 0.5012 - val_acc: 0.7760 - val_gini_normalized: nan\n",
      "Epoch 51/150\n",
      "2500/2500 [==============================] - 0s 85us/step - loss: 0.4885 - acc: 0.8080 - gini_normalized: nan - val_loss: 0.5008 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 52/150\n",
      "2500/2500 [==============================] - 0s 84us/step - loss: 0.4877 - acc: 0.8080 - gini_normalized: nan - val_loss: 0.5000 - val_acc: 0.7800 - val_gini_normalized: nan\n",
      "Epoch 53/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4863 - acc: 0.8056 - gini_normalized: nan - val_loss: 0.4978 - val_acc: 0.7760 - val_gini_normalized: nan\n",
      "Epoch 54/150\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 0.4850 - acc: 0.8089 - gini_normalized: n - 0s 81us/step - loss: 0.4852 - acc: 0.8088 - gini_normalized: nan - val_loss: 0.4975 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 55/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4841 - acc: 0.8064 - gini_normalized: nan - val_loss: 0.4962 - val_acc: 0.7760 - val_gini_normalized: nan\n",
      "Epoch 56/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.4833 - acc: 0.8012 - gini_normalized: nan - val_loss: 0.4943 - val_acc: 0.7760 - val_gini_normalized: nan\n",
      "Epoch 57/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4822 - acc: 0.8064 - gini_normalized: nan - val_loss: 0.4946 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 58/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4812 - acc: 0.8104 - gini_normalized: nan - val_loss: 0.4938 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 59/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.4797 - acc: 0.8072 - gini_normalized: nan - val_loss: 0.4925 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 60/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4794 - acc: 0.8072 - gini_normalized: nan - val_loss: 0.4928 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 61/150\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.4780 - acc: 0.8092 - gini_normalized: nan - val_loss: 0.4913 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 62/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4775 - acc: 0.8060 - gini_normalized: nan - val_loss: 0.4906 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 63/150\n",
      "2500/2500 [==============================] - 0s 84us/step - loss: 0.4764 - acc: 0.8064 - gini_normalized: nan - val_loss: 0.4898 - val_acc: 0.7780 - val_gini_normalized: nan\n",
      "Epoch 64/150\n",
      "2500/2500 [==============================] - 0s 85us/step - loss: 0.4756 - acc: 0.8100 - gini_normalized: nan - val_loss: 0.4903 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 65/150\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.4745 - acc: 0.8108 - gini_normalized: nan - val_loss: 0.4882 - val_acc: 0.7720 - val_gini_normalized: nan\n",
      "Epoch 66/150\n",
      "2500/2500 [==============================] - 0s 79us/step - loss: 0.4740 - acc: 0.8080 - gini_normalized: nan - val_loss: 0.4866 - val_acc: 0.7800 - val_gini_normalized: nan\n",
      "Epoch 67/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4730 - acc: 0.8076 - gini_normalized: nan - val_loss: 0.4864 - val_acc: 0.7780 - val_gini_normalized: nan\n",
      "Epoch 68/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4722 - acc: 0.8084 - gini_normalized: nan - val_loss: 0.4850 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 69/150\n",
      "2500/2500 [==============================] - 0s 84us/step - loss: 0.4714 - acc: 0.8060 - gini_normalized: nan - val_loss: 0.4869 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 70/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.4704 - acc: 0.8112 - gini_normalized: nan - val_loss: 0.4847 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 71/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.4695 - acc: 0.8072 - gini_normalized: nan - val_loss: 0.4850 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 72/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4683 - acc: 0.8136 - gini_normalized: nan - val_loss: 0.4856 - val_acc: 0.7760 - val_gini_normalized: nan\n",
      "Epoch 73/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.4680 - acc: 0.8060 - gini_normalized: nan - val_loss: 0.4834 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 74/150\n",
      "2500/2500 [==============================] - 0s 79us/step - loss: 0.4671 - acc: 0.8076 - gini_normalized: nan - val_loss: 0.4828 - val_acc: 0.7800 - val_gini_normalized: nan\n",
      "Epoch 75/150\n",
      "2500/2500 [==============================] - 0s 86us/step - loss: 0.4665 - acc: 0.8080 - gini_normalized: nan - val_loss: 0.4823 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 76/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.4652 - acc: 0.8120 - gini_normalized: nan - val_loss: 0.4823 - val_acc: 0.7780 - val_gini_normalized: nan\n",
      "Epoch 77/150\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.4653 - acc: 0.8060 - gini_normalized: nan - val_loss: 0.4820 - val_acc: 0.7760 - val_gini_normalized: nan\n",
      "Epoch 78/150\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.4645 - acc: 0.8072 - gini_normalized: nan - val_loss: 0.4799 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 79/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4640 - acc: 0.8060 - gini_normalized: nan - val_loss: 0.4789 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 80/150\n",
      "2500/2500 [==============================] - 0s 85us/step - loss: 0.4631 - acc: 0.8088 - gini_normalized: nan - val_loss: 0.4790 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 81/150\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.4629 - acc: 0.8088 - gini_normalized: nan - val_loss: 0.4787 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 82/150\n",
      "2500/2500 [==============================] - 0s 85us/step - loss: 0.4618 - acc: 0.8104 - gini_normalized: nan - val_loss: 0.4797 - val_acc: 0.7740 - val_gini_normalized: nan\n",
      "Epoch 83/150\n",
      "2500/2500 [==============================] - 0s 86us/step - loss: 0.4610 - acc: 0.8068 - gini_normalized: nan - val_loss: 0.4774 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 84/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.4614 - acc: 0.8088 - gini_normalized: nan - val_loss: 0.4763 - val_acc: 0.7800 - val_gini_normalized: nan\n",
      "Epoch 85/150\n",
      "2500/2500 [==============================] - 0s 86us/step - loss: 0.4604 - acc: 0.8084 - gini_normalized: nan - val_loss: 0.4763 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 86/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.4602 - acc: 0.8052 - gini_normalized: nan - val_loss: 0.4769 - val_acc: 0.7760 - val_gini_normalized: nan\n",
      "Epoch 87/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.4598 - acc: 0.8096 - gini_normalized: nan - val_loss: 0.4763 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 88/150\n",
      "2500/2500 [==============================] - 0s 88us/step - loss: 0.4589 - acc: 0.8088 - gini_normalized: nan - val_loss: 0.4754 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 89/150\n",
      "2500/2500 [==============================] - 0s 85us/step - loss: 0.4587 - acc: 0.8064 - gini_normalized: nan - val_loss: 0.4756 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 90/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4579 - acc: 0.8088 - gini_normalized: nan - val_loss: 0.4747 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 91/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.4579 - acc: 0.8100 - gini_normalized: nan - val_loss: 0.4744 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 92/150\n",
      "2500/2500 [==============================] - 0s 87us/step - loss: 0.4567 - acc: 0.8064 - gini_normalized: nan - val_loss: 0.4744 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 93/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4566 - acc: 0.8088 - gini_normalized: nan - val_loss: 0.4741 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 94/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4559 - acc: 0.8104 - gini_normalized: nan - val_loss: 0.4756 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 95/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4559 - acc: 0.8108 - gini_normalized: nan - val_loss: 0.4736 - val_acc: 0.7780 - val_gini_normalized: nan\n",
      "Epoch 96/150\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.4546 - acc: 0.8076 - gini_normalized: nan - val_loss: 0.4744 - val_acc: 0.7980 - val_gini_normalized: nan\n",
      "Epoch 97/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4547 - acc: 0.8104 - gini_normalized: nan - val_loss: 0.4742 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 98/150\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.4544 - acc: 0.8124 - gini_normalized: nan - val_loss: 0.4731 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 99/150\n",
      "2500/2500 [==============================] - 0s 86us/step - loss: 0.4536 - acc: 0.8128 - gini_normalized: nan - val_loss: 0.4722 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 100/150\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.4533 - acc: 0.8104 - gini_normalized: nan - val_loss: 0.4722 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 101/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.4528 - acc: 0.8116 - gini_normalized: nan - val_loss: 0.4710 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 102/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.4523 - acc: 0.8092 - gini_normalized: nan - val_loss: 0.4740 - val_acc: 0.8020 - val_gini_normalized: nan\n",
      "Epoch 103/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.4519 - acc: 0.8140 - gini_normalized: nan - val_loss: 0.4717 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 104/150\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.4513 - acc: 0.8120 - gini_normalized: nan - val_loss: 0.4717 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 105/150\n",
      "2500/2500 [==============================] - 0s 85us/step - loss: 0.4512 - acc: 0.8100 - gini_normalized: nan - val_loss: 0.4711 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 106/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4505 - acc: 0.8124 - gini_normalized: nan - val_loss: 0.4697 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 107/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.4504 - acc: 0.8096 - gini_normalized: nan - val_loss: 0.4694 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 108/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.4497 - acc: 0.8100 - gini_normalized: nan - val_loss: 0.4684 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 109/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.4497 - acc: 0.8096 - gini_normalized: nan - val_loss: 0.4692 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 110/150\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.4491 - acc: 0.8164 - gini_normalized: nan - val_loss: 0.4701 - val_acc: 0.8000 - val_gini_normalized: nan\n",
      "Epoch 111/150\n",
      "2500/2500 [==============================] - 0s 86us/step - loss: 0.4487 - acc: 0.8132 - gini_normalized: nan - val_loss: 0.4708 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 112/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4484 - acc: 0.8120 - gini_normalized: nan - val_loss: 0.4678 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 113/150\n",
      "2500/2500 [==============================] - 0s 84us/step - loss: 0.4478 - acc: 0.8116 - gini_normalized: nan - val_loss: 0.4670 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 114/150\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.4470 - acc: 0.8128 - gini_normalized: nan - val_loss: 0.4651 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 115/150\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.4467 - acc: 0.8132 - gini_normalized: nan - val_loss: 0.4656 - val_acc: 0.7780 - val_gini_normalized: nan\n",
      "Epoch 116/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.4464 - acc: 0.8092 - gini_normalized: nan - val_loss: 0.4654 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 117/150\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.4463 - acc: 0.8144 - gini_normalized: nan - val_loss: 0.4659 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 118/150\n",
      "2500/2500 [==============================] - 0s 79us/step - loss: 0.4456 - acc: 0.8160 - gini_normalized: nan - val_loss: 0.4632 - val_acc: 0.7800 - val_gini_normalized: nan\n",
      "Epoch 119/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.4451 - acc: 0.8128 - gini_normalized: nan - val_loss: 0.4641 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 120/150\n",
      "2500/2500 [==============================] - 0s 79us/step - loss: 0.4447 - acc: 0.8132 - gini_normalized: nan - val_loss: 0.4632 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 121/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4442 - acc: 0.8152 - gini_normalized: nan - val_loss: 0.4652 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 122/150\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.4444 - acc: 0.8144 - gini_normalized: nan - val_loss: 0.4630 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 123/150\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.4439 - acc: 0.8176 - gini_normalized: nan - val_loss: 0.4633 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 124/150\n",
      "2500/2500 [==============================] - 0s 86us/step - loss: 0.4436 - acc: 0.8120 - gini_normalized: nan - val_loss: 0.4620 - val_acc: 0.7980 - val_gini_normalized: nan\n",
      "Epoch 125/150\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.4435 - acc: 0.8152 - gini_normalized: nan - val_loss: 0.4620 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 126/150\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.4428 - acc: 0.8136 - gini_normalized: nan - val_loss: 0.4619 - val_acc: 0.7980 - val_gini_normalized: nan\n",
      "Epoch 127/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4422 - acc: 0.8176 - gini_normalized: nan - val_loss: 0.4601 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 128/150\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.4419 - acc: 0.8160 - gini_normalized: nan - val_loss: 0.4615 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 129/150\n",
      "2500/2500 [==============================] - 0s 79us/step - loss: 0.4407 - acc: 0.8148 - gini_normalized: nan - val_loss: 0.4597 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 130/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.4412 - acc: 0.8144 - gini_normalized: nan - val_loss: 0.4621 - val_acc: 0.7980 - val_gini_normalized: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/150\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.4409 - acc: 0.8192 - gini_normalized: nan - val_loss: 0.4605 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 132/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4406 - acc: 0.8120 - gini_normalized: nan - val_loss: 0.4602 - val_acc: 0.7980 - val_gini_normalized: nan\n",
      "Epoch 133/150\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.4401 - acc: 0.8176 - gini_normalized: nan - val_loss: 0.4617 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 134/150\n",
      "2500/2500 [==============================] - 0s 85us/step - loss: 0.4398 - acc: 0.8164 - gini_normalized: nan - val_loss: 0.4599 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 135/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4397 - acc: 0.8164 - gini_normalized: nan - val_loss: 0.4595 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 136/150\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.4393 - acc: 0.8160 - gini_normalized: nan - val_loss: 0.4587 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 137/150\n",
      "2500/2500 [==============================] - 0s 86us/step - loss: 0.4390 - acc: 0.8180 - gini_normalized: nan - val_loss: 0.4576 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 138/150\n",
      "2500/2500 [==============================] - 0s 89us/step - loss: 0.4384 - acc: 0.8176 - gini_normalized: nan - val_loss: 0.4582 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 139/150\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.4385 - acc: 0.8160 - gini_normalized: nan - val_loss: 0.4566 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 140/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4377 - acc: 0.8152 - gini_normalized: nan - val_loss: 0.4573 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 141/150\n",
      "2500/2500 [==============================] - 0s 84us/step - loss: 0.4376 - acc: 0.8160 - gini_normalized: nan - val_loss: 0.4564 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 142/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4370 - acc: 0.8172 - gini_normalized: nan - val_loss: 0.4539 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 143/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.4365 - acc: 0.8204 - gini_normalized: nan - val_loss: 0.4541 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 144/150\n",
      "2500/2500 [==============================] - 0s 85us/step - loss: 0.4365 - acc: 0.8160 - gini_normalized: nan - val_loss: 0.4554 - val_acc: 0.8020 - val_gini_normalized: nan\n",
      "Epoch 145/150\n",
      "2500/2500 [==============================] - 0s 90us/step - loss: 0.4364 - acc: 0.8180 - gini_normalized: nan - val_loss: 0.4540 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 146/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.4361 - acc: 0.8200 - gini_normalized: nan - val_loss: 0.4558 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 147/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4354 - acc: 0.8220 - gini_normalized: nan - val_loss: 0.4580 - val_acc: 0.7980 - val_gini_normalized: nan\n",
      "Epoch 148/150\n",
      "2500/2500 [==============================] - 0s 91us/step - loss: 0.4351 - acc: 0.8204 - gini_normalized: nan - val_loss: 0.4562 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 149/150\n",
      "2500/2500 [==============================] - 0s 86us/step - loss: 0.4352 - acc: 0.8220 - gini_normalized: nan - val_loss: 0.4539 - val_acc: 0.8000 - val_gini_normalized: nan\n",
      "Epoch 150/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4343 - acc: 0.8228 - gini_normalized: nan - val_loss: 0.4549 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "500/500 [==============================] - 0s 56us/step\n",
      "Train on 2500 samples, validate on 500 samples\n",
      "Epoch 1/150\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0142 - acc: 0.4632 - gini_normalized: nan - val_loss: 0.9309 - val_acc: 0.5040 - val_gini_normalized: nan\n",
      "Epoch 2/150\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.8859 - acc: 0.5684 - gini_normalized: nan - val_loss: 0.8382 - val_acc: 0.6340 - val_gini_normalized: nan\n",
      "Epoch 3/150\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.8056 - acc: 0.6696 - gini_normalized: nan - val_loss: 0.7752 - val_acc: 0.6900 - val_gini_normalized: nan\n",
      "Epoch 4/150\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.7490 - acc: 0.7156 - gini_normalized: nan - val_loss: 0.7287 - val_acc: 0.7180 - val_gini_normalized: nan\n",
      "Epoch 5/150\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.7065 - acc: 0.7300 - gini_normalized: nan - val_loss: 0.6932 - val_acc: 0.7400 - val_gini_normalized: nan\n",
      "Epoch 6/150\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.6729 - acc: 0.7528 - gini_normalized: nan - val_loss: 0.6643 - val_acc: 0.7480 - val_gini_normalized: nan\n",
      "Epoch 7/150\n",
      "2500/2500 [==============================] - 0s 90us/step - loss: 0.6458 - acc: 0.7640 - gini_normalized: nan - val_loss: 0.6410 - val_acc: 0.7560 - val_gini_normalized: nan\n",
      "Epoch 8/150\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.6250 - acc: 0.7668 - gini_normalized: nan - val_loss: 0.6235 - val_acc: 0.7680 - val_gini_normalized: nan\n",
      "Epoch 9/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.6096 - acc: 0.7740 - gini_normalized: nan - val_loss: 0.6104 - val_acc: 0.7780 - val_gini_normalized: nan\n",
      "Epoch 10/150\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.5984 - acc: 0.7788 - gini_normalized: nan - val_loss: 0.6007 - val_acc: 0.7720 - val_gini_normalized: nan\n",
      "Epoch 11/150\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.5891 - acc: 0.7780 - gini_normalized: nan - val_loss: 0.5919 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 12/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.5811 - acc: 0.7804 - gini_normalized: nan - val_loss: 0.5849 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 13/150\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.5743 - acc: 0.7884 - gini_normalized: nan - val_loss: 0.5802 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 14/150\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.5692 - acc: 0.7884 - gini_normalized: nan - val_loss: 0.5746 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 15/150\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.5637 - acc: 0.7892 - gini_normalized: nan - val_loss: 0.5688 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 16/150\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.5593 - acc: 0.7932 - gini_normalized: nan - val_loss: 0.5645 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 17/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.5550 - acc: 0.7940 - gini_normalized: nan - val_loss: 0.5611 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 18/150\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.5508 - acc: 0.7948 - gini_normalized: nan - val_loss: 0.5570 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 19/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.5467 - acc: 0.7980 - gini_normalized: nan - val_loss: 0.5547 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 20/150\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.5430 - acc: 0.7980 - gini_normalized: nan - val_loss: 0.5513 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 21/150\n",
      "2500/2500 [==============================] - 0s 79us/step - loss: 0.5392 - acc: 0.7996 - gini_normalized: nan - val_loss: 0.5469 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 22/150\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.5356 - acc: 0.7980 - gini_normalized: nan - val_loss: 0.5448 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 23/150\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.5324 - acc: 0.7980 - gini_normalized: nan - val_loss: 0.5418 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 24/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.5295 - acc: 0.7992 - gini_normalized: nan - val_loss: 0.5391 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 25/150\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.5264 - acc: 0.8004 - gini_normalized: nan - val_loss: 0.5354 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 26/150\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.5231 - acc: 0.8012 - gini_normalized: nan - val_loss: 0.5342 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 27/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.5203 - acc: 0.8020 - gini_normalized: nan - val_loss: 0.5311 - val_acc: 0.7980 - val_gini_normalized: nan\n",
      "Epoch 28/150\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.5178 - acc: 0.8040 - gini_normalized: nan - val_loss: 0.5274 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 29/150\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.5152 - acc: 0.8020 - gini_normalized: nan - val_loss: 0.5246 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 30/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.5125 - acc: 0.8028 - gini_normalized: nan - val_loss: 0.5225 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 31/150\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.5100 - acc: 0.8016 - gini_normalized: nan - val_loss: 0.5215 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 32/150\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.5080 - acc: 0.8040 - gini_normalized: nan - val_loss: 0.5204 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 33/150\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.5062 - acc: 0.8064 - gini_normalized: nan - val_loss: 0.5176 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 34/150\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.5039 - acc: 0.8008 - gini_normalized: nan - val_loss: 0.5169 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 35/150\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.5020 - acc: 0.8048 - gini_normalized: nan - val_loss: 0.5153 - val_acc: 0.7800 - val_gini_normalized: nan\n",
      "Epoch 36/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.5000 - acc: 0.8052 - gini_normalized: nan - val_loss: 0.5127 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 37/150\n",
      "2500/2500 [==============================] - 0s 89us/step - loss: 0.4982 - acc: 0.8048 - gini_normalized: nan - val_loss: 0.5125 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 38/150\n",
      "2500/2500 [==============================] - 0s 94us/step - loss: 0.4966 - acc: 0.8088 - gini_normalized: nan - val_loss: 0.5112 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 39/150\n",
      "2500/2500 [==============================] - 0s 95us/step - loss: 0.4948 - acc: 0.8064 - gini_normalized: nan - val_loss: 0.5083 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 40/150\n",
      "2500/2500 [==============================] - 0s 88us/step - loss: 0.4931 - acc: 0.8080 - gini_normalized: nan - val_loss: 0.5078 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 41/150\n",
      "2500/2500 [==============================] - 0s 85us/step - loss: 0.4917 - acc: 0.8064 - gini_normalized: nan - val_loss: 0.5066 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 42/150\n",
      "2500/2500 [==============================] - 0s 93us/step - loss: 0.4901 - acc: 0.8084 - gini_normalized: nan - val_loss: 0.5055 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 43/150\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.4892 - acc: 0.8068 - gini_normalized: nan - val_loss: 0.5056 - val_acc: 0.8000 - val_gini_normalized: nan\n",
      "Epoch 44/150\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.4875 - acc: 0.8084 - gini_normalized: nan - val_loss: 0.5036 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 45/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4864 - acc: 0.8100 - gini_normalized: nan - val_loss: 0.5032 - val_acc: 0.7980 - val_gini_normalized: nan\n",
      "Epoch 46/150\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.4848 - acc: 0.8108 - gini_normalized: nan - val_loss: 0.5032 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 47/150\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.4844 - acc: 0.8108 - gini_normalized: nan - val_loss: 0.5009 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 48/150\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 0.4823 - acc: 0.8092 - gini_normalized: n - 0s 77us/step - loss: 0.4831 - acc: 0.8088 - gini_normalized: nan - val_loss: 0.5021 - val_acc: 0.8000 - val_gini_normalized: nan\n",
      "Epoch 49/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4822 - acc: 0.8124 - gini_normalized: nan - val_loss: 0.4987 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 50/150\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.4809 - acc: 0.8096 - gini_normalized: nan - val_loss: 0.4999 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 51/150\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4801 - acc: 0.8100 - gini_normalized: nan - val_loss: 0.5008 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 52/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4794 - acc: 0.8084 - gini_normalized: nan - val_loss: 0.4982 - val_acc: 0.8020 - val_gini_normalized: nan\n",
      "Epoch 53/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4783 - acc: 0.8120 - gini_normalized: nan - val_loss: 0.4967 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 54/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4777 - acc: 0.8080 - gini_normalized: nan - val_loss: 0.4950 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 55/150\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.4765 - acc: 0.8136 - gini_normalized: nan - val_loss: 0.4944 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 56/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4753 - acc: 0.8084 - gini_normalized: nan - val_loss: 0.4973 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 57/150\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4749 - acc: 0.8128 - gini_normalized: nan - val_loss: 0.4976 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 58/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4746 - acc: 0.8136 - gini_normalized: nan - val_loss: 0.4933 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 59/150\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.4735 - acc: 0.8092 - gini_normalized: nan - val_loss: 0.4921 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 60/150\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.4728 - acc: 0.8088 - gini_normalized: nan - val_loss: 0.4926 - val_acc: 0.8000 - val_gini_normalized: nan\n",
      "Epoch 61/150\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.4723 - acc: 0.8096 - gini_normalized: nan - val_loss: 0.4931 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 62/150\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4713 - acc: 0.8116 - gini_normalized: nan - val_loss: 0.4916 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 63/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4706 - acc: 0.8092 - gini_normalized: nan - val_loss: 0.4922 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 64/150\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.4703 - acc: 0.8132 - gini_normalized: nan - val_loss: 0.4903 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 65/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4691 - acc: 0.8116 - gini_normalized: nan - val_loss: 0.4918 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 66/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4687 - acc: 0.8116 - gini_normalized: nan - val_loss: 0.4930 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 67/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.4682 - acc: 0.8108 - gini_normalized: nan - val_loss: 0.4925 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 68/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4673 - acc: 0.8108 - gini_normalized: nan - val_loss: 0.4899 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 69/150\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.4668 - acc: 0.8124 - gini_normalized: nan - val_loss: 0.4904 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 70/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4659 - acc: 0.8116 - gini_normalized: nan - val_loss: 0.4885 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 71/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4649 - acc: 0.8096 - gini_normalized: nan - val_loss: 0.4885 - val_acc: 0.7980 - val_gini_normalized: nan\n",
      "Epoch 72/150\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.4647 - acc: 0.8112 - gini_normalized: nan - val_loss: 0.4885 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 73/150\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.4640 - acc: 0.8104 - gini_normalized: nan - val_loss: 0.4891 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 74/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4638 - acc: 0.8100 - gini_normalized: nan - val_loss: 0.4863 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 75/150\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.4632 - acc: 0.8128 - gini_normalized: nan - val_loss: 0.4853 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 76/150\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.4628 - acc: 0.8116 - gini_normalized: nan - val_loss: 0.4833 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 77/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4621 - acc: 0.8128 - gini_normalized: nan - val_loss: 0.4856 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 78/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4617 - acc: 0.8116 - gini_normalized: nan - val_loss: 0.4845 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 79/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4606 - acc: 0.8120 - gini_normalized: nan - val_loss: 0.4862 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 80/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4602 - acc: 0.8092 - gini_normalized: nan - val_loss: 0.4823 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 81/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4590 - acc: 0.8144 - gini_normalized: nan - val_loss: 0.4835 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 82/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4591 - acc: 0.8124 - gini_normalized: nan - val_loss: 0.4839 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 83/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4581 - acc: 0.8100 - gini_normalized: nan - val_loss: 0.4839 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 84/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4577 - acc: 0.8128 - gini_normalized: nan - val_loss: 0.4814 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 85/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4576 - acc: 0.8108 - gini_normalized: nan - val_loss: 0.4809 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 86/150\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.4570 - acc: 0.8120 - gini_normalized: nan - val_loss: 0.4828 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 87/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4560 - acc: 0.8124 - gini_normalized: nan - val_loss: 0.4844 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 88/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4555 - acc: 0.8124 - gini_normalized: nan - val_loss: 0.4792 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 89/150\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.4556 - acc: 0.8100 - gini_normalized: nan - val_loss: 0.4791 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 90/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4542 - acc: 0.8120 - gini_normalized: nan - val_loss: 0.4829 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 91/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4548 - acc: 0.8136 - gini_normalized: nan - val_loss: 0.4796 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 92/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4542 - acc: 0.8092 - gini_normalized: nan - val_loss: 0.4788 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 93/150\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4534 - acc: 0.8116 - gini_normalized: nan - val_loss: 0.4777 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 94/150\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4530 - acc: 0.8152 - gini_normalized: nan - val_loss: 0.4752 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 95/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4521 - acc: 0.8140 - gini_normalized: nan - val_loss: 0.4770 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 96/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4519 - acc: 0.8092 - gini_normalized: nan - val_loss: 0.4741 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 97/150\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.4510 - acc: 0.8104 - gini_normalized: nan - val_loss: 0.4787 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 98/150\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.4511 - acc: 0.8120 - gini_normalized: nan - val_loss: 0.4773 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 99/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4506 - acc: 0.8124 - gini_normalized: nan - val_loss: 0.4739 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 100/150\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.4502 - acc: 0.8100 - gini_normalized: nan - val_loss: 0.4745 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 101/150\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.4498 - acc: 0.8124 - gini_normalized: nan - val_loss: 0.4745 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 102/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4493 - acc: 0.8156 - gini_normalized: nan - val_loss: 0.4745 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 103/150\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.4485 - acc: 0.8128 - gini_normalized: nan - val_loss: 0.4717 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 104/150\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4484 - acc: 0.8132 - gini_normalized: nan - val_loss: 0.4742 - val_acc: 0.7980 - val_gini_normalized: nan\n",
      "Epoch 105/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4478 - acc: 0.8136 - gini_normalized: nan - val_loss: 0.4721 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 106/150\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4475 - acc: 0.8112 - gini_normalized: nan - val_loss: 0.4707 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 107/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4472 - acc: 0.8108 - gini_normalized: nan - val_loss: 0.4697 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 108/150\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4468 - acc: 0.8104 - gini_normalized: nan - val_loss: 0.4709 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 109/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4466 - acc: 0.8096 - gini_normalized: nan - val_loss: 0.4713 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 110/150\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4460 - acc: 0.8104 - gini_normalized: nan - val_loss: 0.4704 - val_acc: 0.7960 - val_gini_normalized: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4451 - acc: 0.8112 - gini_normalized: nan - val_loss: 0.4708 - val_acc: 0.7980 - val_gini_normalized: nan\n",
      "Epoch 112/150\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.4452 - acc: 0.8120 - gini_normalized: nan - val_loss: 0.4693 - val_acc: 0.8020 - val_gini_normalized: nan\n",
      "Epoch 113/150\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.4443 - acc: 0.8100 - gini_normalized: nan - val_loss: 0.4668 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 114/150\n",
      "2500/2500 [==============================] - 0s 86us/step - loss: 0.4442 - acc: 0.8092 - gini_normalized: nan - val_loss: 0.4693 - val_acc: 0.7980 - val_gini_normalized: nan\n",
      "Epoch 115/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.4437 - acc: 0.8140 - gini_normalized: nan - val_loss: 0.4668 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 116/150\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.4434 - acc: 0.8108 - gini_normalized: nan - val_loss: 0.4673 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 117/150\n",
      "2500/2500 [==============================] - 0s 94us/step - loss: 0.4421 - acc: 0.8128 - gini_normalized: nan - val_loss: 0.4693 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 118/150\n",
      "2500/2500 [==============================] - 0s 46us/step - loss: 0.4422 - acc: 0.8116 - gini_normalized: nan - val_loss: 0.4642 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 119/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.4423 - acc: 0.8088 - gini_normalized: nan - val_loss: 0.4655 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 120/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4415 - acc: 0.8112 - gini_normalized: nan - val_loss: 0.4640 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 121/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4408 - acc: 0.8132 - gini_normalized: nan - val_loss: 0.4640 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 122/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.4407 - acc: 0.8140 - gini_normalized: nan - val_loss: 0.4627 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 123/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4403 - acc: 0.8104 - gini_normalized: nan - val_loss: 0.4640 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 124/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.4394 - acc: 0.8116 - gini_normalized: nan - val_loss: 0.4611 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 125/150\n",
      "2500/2500 [==============================] - 0s 51us/step - loss: 0.4389 - acc: 0.8168 - gini_normalized: nan - val_loss: 0.4616 - val_acc: 0.7980 - val_gini_normalized: nan\n",
      "Epoch 126/150\n",
      "2500/2500 [==============================] - 0s 51us/step - loss: 0.4388 - acc: 0.8156 - gini_normalized: nan - val_loss: 0.4610 - val_acc: 0.7980 - val_gini_normalized: nan\n",
      "Epoch 127/150\n",
      "2500/2500 [==============================] - 0s 51us/step - loss: 0.4392 - acc: 0.8160 - gini_normalized: nan - val_loss: 0.4615 - val_acc: 0.8020 - val_gini_normalized: nan\n",
      "Epoch 128/150\n",
      "2500/2500 [==============================] - 0s 53us/step - loss: 0.4381 - acc: 0.8152 - gini_normalized: nan - val_loss: 0.4617 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 129/150\n",
      "2500/2500 [==============================] - 0s 51us/step - loss: 0.4379 - acc: 0.8124 - gini_normalized: nan - val_loss: 0.4607 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 130/150\n",
      "2500/2500 [==============================] - 0s 48us/step - loss: 0.4373 - acc: 0.8128 - gini_normalized: nan - val_loss: 0.4624 - val_acc: 0.8000 - val_gini_normalized: nan\n",
      "Epoch 131/150\n",
      "2500/2500 [==============================] - 0s 51us/step - loss: 0.4366 - acc: 0.8136 - gini_normalized: nan - val_loss: 0.4634 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 132/150\n",
      "2500/2500 [==============================] - 0s 53us/step - loss: 0.4367 - acc: 0.8152 - gini_normalized: nan - val_loss: 0.4594 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 133/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4365 - acc: 0.8148 - gini_normalized: nan - val_loss: 0.4634 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 134/150\n",
      "2500/2500 [==============================] - 0s 52us/step - loss: 0.4368 - acc: 0.8172 - gini_normalized: nan - val_loss: 0.4584 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 135/150\n",
      "2500/2500 [==============================] - 0s 53us/step - loss: 0.4362 - acc: 0.8164 - gini_normalized: nan - val_loss: 0.4590 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 136/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.4356 - acc: 0.8180 - gini_normalized: nan - val_loss: 0.4599 - val_acc: 0.8000 - val_gini_normalized: nan\n",
      "Epoch 137/150\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4351 - acc: 0.8172 - gini_normalized: nan - val_loss: 0.4579 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 138/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4352 - acc: 0.8148 - gini_normalized: nan - val_loss: 0.4616 - val_acc: 0.8000 - val_gini_normalized: nan\n",
      "Epoch 139/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.4343 - acc: 0.8160 - gini_normalized: nan - val_loss: 0.4607 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 140/150\n",
      "2500/2500 [==============================] - 0s 52us/step - loss: 0.4344 - acc: 0.8160 - gini_normalized: nan - val_loss: 0.4582 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 141/150\n",
      "2500/2500 [==============================] - 0s 48us/step - loss: 0.4334 - acc: 0.8168 - gini_normalized: nan - val_loss: 0.4558 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 142/150\n",
      "2500/2500 [==============================] - 0s 53us/step - loss: 0.4331 - acc: 0.8160 - gini_normalized: nan - val_loss: 0.4584 - val_acc: 0.8000 - val_gini_normalized: nan\n",
      "Epoch 143/150\n",
      "2500/2500 [==============================] - 0s 51us/step - loss: 0.4337 - acc: 0.8188 - gini_normalized: nan - val_loss: 0.4563 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 144/150\n",
      "2500/2500 [==============================] - 0s 52us/step - loss: 0.4327 - acc: 0.8160 - gini_normalized: nan - val_loss: 0.4598 - val_acc: 0.8000 - val_gini_normalized: nan\n",
      "Epoch 145/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.4333 - acc: 0.8180 - gini_normalized: nan - val_loss: 0.4568 - val_acc: 0.7980 - val_gini_normalized: nan\n",
      "Epoch 146/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.4326 - acc: 0.8164 - gini_normalized: nan - val_loss: 0.4543 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 147/150\n",
      "2500/2500 [==============================] - 0s 47us/step - loss: 0.4322 - acc: 0.8176 - gini_normalized: nan - val_loss: 0.4553 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 148/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.4314 - acc: 0.8180 - gini_normalized: nan - val_loss: 0.4581 - val_acc: 0.8020 - val_gini_normalized: nan\n",
      "Epoch 149/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.4318 - acc: 0.8200 - gini_normalized: nan - val_loss: 0.4539 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 150/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.4317 - acc: 0.8188 - gini_normalized: nan - val_loss: 0.4545 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "500/500 [==============================] - 0s 40us/step\n",
      "Train on 2500 samples, validate on 500 samples\n",
      "Epoch 1/150\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.1270 - acc: 0.5584 - gini_normalized: nan - val_loss: 1.0035 - val_acc: 0.6020 - val_gini_normalized: nan\n",
      "Epoch 2/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.9187 - acc: 0.6992 - gini_normalized: nan - val_loss: 0.8717 - val_acc: 0.7220 - val_gini_normalized: nan\n",
      "Epoch 3/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.8137 - acc: 0.7712 - gini_normalized: nan - val_loss: 0.8110 - val_acc: 0.7620 - val_gini_normalized: nan\n",
      "Epoch 4/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 53us/step - loss: 0.7421 - acc: 0.8040 - gini_normalized: nan - val_loss: 0.7318 - val_acc: 0.7800 - val_gini_normalized: nan\n",
      "Epoch 5/150\n",
      "2500/2500 [==============================] - 0s 52us/step - loss: 0.6876 - acc: 0.8040 - gini_normalized: nan - val_loss: 0.6924 - val_acc: 0.8020 - val_gini_normalized: nan\n",
      "Epoch 6/150\n",
      "2500/2500 [==============================] - 0s 53us/step - loss: 0.6474 - acc: 0.8164 - gini_normalized: nan - val_loss: 0.6475 - val_acc: 0.8180 - val_gini_normalized: nan\n",
      "Epoch 7/150\n",
      "2500/2500 [==============================] - 0s 51us/step - loss: 0.6092 - acc: 0.8284 - gini_normalized: nan - val_loss: 0.6209 - val_acc: 0.8220 - val_gini_normalized: nan\n",
      "Epoch 8/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.5826 - acc: 0.8300 - gini_normalized: nan - val_loss: 0.5946 - val_acc: 0.8260 - val_gini_normalized: nan\n",
      "Epoch 9/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.5611 - acc: 0.8416 - gini_normalized: nan - val_loss: 0.5750 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 10/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.5486 - acc: 0.8412 - gini_normalized: nan - val_loss: 0.5594 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 11/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.5339 - acc: 0.8452 - gini_normalized: nan - val_loss: 0.5419 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 12/150\n",
      "2500/2500 [==============================] - 0s 53us/step - loss: 0.5110 - acc: 0.8524 - gini_normalized: nan - val_loss: 0.5364 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 13/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.5077 - acc: 0.8528 - gini_normalized: nan - val_loss: 0.5239 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 14/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.4933 - acc: 0.8572 - gini_normalized: nan - val_loss: 0.5305 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 15/150\n",
      "2500/2500 [==============================] - 0s 51us/step - loss: 0.4922 - acc: 0.8596 - gini_normalized: nan - val_loss: 0.5053 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 16/150\n",
      "2500/2500 [==============================] - 0s 53us/step - loss: 0.4895 - acc: 0.8604 - gini_normalized: nan - val_loss: 0.5200 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 17/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4846 - acc: 0.8664 - gini_normalized: nan - val_loss: 0.5040 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 18/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4817 - acc: 0.8640 - gini_normalized: nan - val_loss: 0.4907 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 19/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4678 - acc: 0.8700 - gini_normalized: nan - val_loss: 0.4865 - val_acc: 0.8560 - val_gini_normalized: nan\n",
      "Epoch 20/150\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.4678 - acc: 0.8716 - gini_normalized: nan - val_loss: 0.4714 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 21/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.4501 - acc: 0.8716 - gini_normalized: nan - val_loss: 0.4821 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 22/150\n",
      "2500/2500 [==============================] - 0s 84us/step - loss: 0.4502 - acc: 0.8744 - gini_normalized: nan - val_loss: 0.4780 - val_acc: 0.8580 - val_gini_normalized: nan\n",
      "Epoch 23/150\n",
      "2500/2500 [==============================] - 0s 100us/step - loss: 0.4496 - acc: 0.8768 - gini_normalized: nan - val_loss: 0.4673 - val_acc: 0.8580 - val_gini_normalized: nan\n",
      "Epoch 24/150\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4445 - acc: 0.8768 - gini_normalized: nan - val_loss: 0.4523 - val_acc: 0.8660 - val_gini_normalized: nan\n",
      "Epoch 25/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4381 - acc: 0.8792 - gini_normalized: nan - val_loss: 0.4556 - val_acc: 0.8620 - val_gini_normalized: nan\n",
      "Epoch 26/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4357 - acc: 0.8816 - gini_normalized: nan - val_loss: 0.4467 - val_acc: 0.8680 - val_gini_normalized: nan\n",
      "Epoch 27/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4334 - acc: 0.8804 - gini_normalized: nan - val_loss: 0.4402 - val_acc: 0.8640 - val_gini_normalized: nan\n",
      "Epoch 28/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4267 - acc: 0.8776 - gini_normalized: nan - val_loss: 0.4370 - val_acc: 0.8820 - val_gini_normalized: nan\n",
      "Epoch 29/150\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.4206 - acc: 0.8896 - gini_normalized: nan - val_loss: 0.4329 - val_acc: 0.8760 - val_gini_normalized: nan\n",
      "Epoch 30/150\n",
      "2500/2500 [==============================] - 0s 100us/step - loss: 0.4255 - acc: 0.8860 - gini_normalized: nan - val_loss: 0.4293 - val_acc: 0.8760 - val_gini_normalized: nan\n",
      "Epoch 31/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.4112 - acc: 0.8864 - gini_normalized: nan - val_loss: 0.4330 - val_acc: 0.8840 - val_gini_normalized: nan\n",
      "Epoch 32/150\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.4174 - acc: 0.8888 - gini_normalized: nan - val_loss: 0.4226 - val_acc: 0.8820 - val_gini_normalized: nan\n",
      "Epoch 33/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4071 - acc: 0.8864 - gini_normalized: nan - val_loss: 0.4300 - val_acc: 0.8940 - val_gini_normalized: nan\n",
      "Epoch 34/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4032 - acc: 0.8916 - gini_normalized: nan - val_loss: 0.4128 - val_acc: 0.8900 - val_gini_normalized: nan\n",
      "Epoch 35/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4081 - acc: 0.8904 - gini_normalized: nan - val_loss: 0.4079 - val_acc: 0.8980 - val_gini_normalized: nan\n",
      "Epoch 36/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.3991 - acc: 0.8916 - gini_normalized: nan - val_loss: 0.4005 - val_acc: 0.8940 - val_gini_normalized: nan\n",
      "Epoch 37/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.4003 - acc: 0.8944 - gini_normalized: nan - val_loss: 0.4139 - val_acc: 0.9060 - val_gini_normalized: nan\n",
      "Epoch 38/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.3896 - acc: 0.8952 - gini_normalized: nan - val_loss: 0.3940 - val_acc: 0.9020 - val_gini_normalized: nan\n",
      "Epoch 39/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.3850 - acc: 0.8936 - gini_normalized: nan - val_loss: 0.3947 - val_acc: 0.8980 - val_gini_normalized: nan\n",
      "Epoch 40/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.3810 - acc: 0.8972 - gini_normalized: nan - val_loss: 0.3906 - val_acc: 0.9080 - val_gini_normalized: nan\n",
      "Epoch 41/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.3846 - acc: 0.8944 - gini_normalized: nan - val_loss: 0.3905 - val_acc: 0.9120 - val_gini_normalized: nan\n",
      "Epoch 42/150\n",
      "2500/2500 [==============================] - 0s 134us/step - loss: 0.3799 - acc: 0.8972 - gini_normalized: nan - val_loss: 0.3886 - val_acc: 0.9140 - val_gini_normalized: nan\n",
      "Epoch 43/150\n",
      "2500/2500 [==============================] - 0s 141us/step - loss: 0.3757 - acc: 0.9016 - gini_normalized: nan - val_loss: 0.3796 - val_acc: 0.9080 - val_gini_normalized: nan\n",
      "Epoch 44/150\n",
      "2500/2500 [==============================] - 0s 94us/step - loss: 0.3685 - acc: 0.9012 - gini_normalized: nan - val_loss: 0.3714 - val_acc: 0.9140 - val_gini_normalized: nan\n",
      "Epoch 45/150\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.3660 - acc: 0.9008 - gini_normalized: nan - val_loss: 0.3841 - val_acc: 0.9140 - val_gini_normalized: nan\n",
      "Epoch 46/150\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.3634 - acc: 0.9020 - gini_normalized: nan - val_loss: 0.3761 - val_acc: 0.9120 - val_gini_normalized: nan\n",
      "Epoch 47/150\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.3606 - acc: 0.8976 - gini_normalized: nan - val_loss: 0.3728 - val_acc: 0.9160 - val_gini_normalized: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.3572 - acc: 0.9016 - gini_normalized: nan - val_loss: 0.3718 - val_acc: 0.9180 - val_gini_normalized: nan\n",
      "Epoch 49/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.3596 - acc: 0.9044 - gini_normalized: nan - val_loss: 0.3748 - val_acc: 0.9240 - val_gini_normalized: nan\n",
      "Epoch 50/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.3566 - acc: 0.9072 - gini_normalized: nan - val_loss: 0.3738 - val_acc: 0.9100 - val_gini_normalized: nan\n",
      "Epoch 51/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.3520 - acc: 0.9024 - gini_normalized: nan - val_loss: 0.3663 - val_acc: 0.9260 - val_gini_normalized: nan\n",
      "Epoch 52/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.3522 - acc: 0.9072 - gini_normalized: nan - val_loss: 0.3708 - val_acc: 0.9300 - val_gini_normalized: nan\n",
      "Epoch 53/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.3513 - acc: 0.9096 - gini_normalized: nan - val_loss: 0.3519 - val_acc: 0.9320 - val_gini_normalized: nan\n",
      "Epoch 54/150\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.3442 - acc: 0.9092 - gini_normalized: nan - val_loss: 0.3465 - val_acc: 0.9240 - val_gini_normalized: nan\n",
      "Epoch 55/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.3392 - acc: 0.9100 - gini_normalized: nan - val_loss: 0.3573 - val_acc: 0.9320 - val_gini_normalized: nan\n",
      "Epoch 56/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.3365 - acc: 0.9124 - gini_normalized: nan - val_loss: 0.3373 - val_acc: 0.9320 - val_gini_normalized: nan\n",
      "Epoch 57/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.3349 - acc: 0.9192 - gini_normalized: nan - val_loss: 0.3342 - val_acc: 0.9280 - val_gini_normalized: nan\n",
      "Epoch 58/150\n",
      "2500/2500 [==============================] - 0s 82us/step - loss: 0.3394 - acc: 0.9120 - gini_normalized: nan - val_loss: 0.3375 - val_acc: 0.9280 - val_gini_normalized: nan\n",
      "Epoch 59/150\n",
      "2500/2500 [==============================] - 0s 79us/step - loss: 0.3307 - acc: 0.9144 - gini_normalized: nan - val_loss: 0.3486 - val_acc: 0.9320 - val_gini_normalized: nan\n",
      "Epoch 60/150\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.3310 - acc: 0.9132 - gini_normalized: nan - val_loss: 0.3334 - val_acc: 0.9300 - val_gini_normalized: nan\n",
      "Epoch 61/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.3314 - acc: 0.9164 - gini_normalized: nan - val_loss: 0.3255 - val_acc: 0.9320 - val_gini_normalized: nan\n",
      "Epoch 62/150\n",
      "2500/2500 [==============================] - 0s 53us/step - loss: 0.3243 - acc: 0.9156 - gini_normalized: nan - val_loss: 0.3580 - val_acc: 0.9340 - val_gini_normalized: nan\n",
      "Epoch 63/150\n",
      "2500/2500 [==============================] - 0s 51us/step - loss: 0.3274 - acc: 0.9188 - gini_normalized: nan - val_loss: 0.3234 - val_acc: 0.9340 - val_gini_normalized: nan\n",
      "Epoch 64/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.3264 - acc: 0.9176 - gini_normalized: nan - val_loss: 0.3355 - val_acc: 0.9360 - val_gini_normalized: nan\n",
      "Epoch 65/150\n",
      "2500/2500 [==============================] - 0s 47us/step - loss: 0.3354 - acc: 0.9128 - gini_normalized: nan - val_loss: 0.3338 - val_acc: 0.9360 - val_gini_normalized: nan\n",
      "Epoch 66/150\n",
      "2500/2500 [==============================] - 0s 44us/step - loss: 0.3235 - acc: 0.9140 - gini_normalized: nan - val_loss: 0.3363 - val_acc: 0.9340 - val_gini_normalized: nan\n",
      "Epoch 67/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3149 - acc: 0.9196 - gini_normalized: nan - val_loss: 0.3133 - val_acc: 0.9360 - val_gini_normalized: nan\n",
      "Epoch 68/150\n",
      "2500/2500 [==============================] - 0s 48us/step - loss: 0.3151 - acc: 0.9228 - gini_normalized: nan - val_loss: 0.3179 - val_acc: 0.9400 - val_gini_normalized: nan\n",
      "Epoch 69/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.3186 - acc: 0.9212 - gini_normalized: nan - val_loss: 0.3148 - val_acc: 0.9400 - val_gini_normalized: nan\n",
      "Epoch 70/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.3156 - acc: 0.9208 - gini_normalized: nan - val_loss: 0.3139 - val_acc: 0.9380 - val_gini_normalized: nan\n",
      "Epoch 71/150\n",
      "2500/2500 [==============================] - 0s 51us/step - loss: 0.3123 - acc: 0.9192 - gini_normalized: nan - val_loss: 0.3189 - val_acc: 0.9360 - val_gini_normalized: nan\n",
      "Epoch 72/150\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.3148 - acc: 0.9220 - gini_normalized: nan - val_loss: 0.3035 - val_acc: 0.9400 - val_gini_normalized: nan\n",
      "Epoch 73/150\n",
      "2500/2500 [==============================] - 0s 51us/step - loss: 0.3109 - acc: 0.9192 - gini_normalized: nan - val_loss: 0.3266 - val_acc: 0.9360 - val_gini_normalized: nan\n",
      "Epoch 74/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3145 - acc: 0.9212 - gini_normalized: nan - val_loss: 0.3186 - val_acc: 0.9360 - val_gini_normalized: nan\n",
      "Epoch 75/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.3028 - acc: 0.9244 - gini_normalized: nan - val_loss: 0.3091 - val_acc: 0.9360 - val_gini_normalized: nan\n",
      "Epoch 76/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3100 - acc: 0.9212 - gini_normalized: nan - val_loss: 0.3121 - val_acc: 0.9320 - val_gini_normalized: nan\n",
      "Epoch 77/150\n",
      "2500/2500 [==============================] - 0s 44us/step - loss: 0.3012 - acc: 0.9268 - gini_normalized: nan - val_loss: 0.3227 - val_acc: 0.9380 - val_gini_normalized: nan\n",
      "Epoch 78/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.3103 - acc: 0.9244 - gini_normalized: nan - val_loss: 0.3074 - val_acc: 0.9380 - val_gini_normalized: nan\n",
      "Epoch 79/150\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.3033 - acc: 0.9256 - gini_normalized: nan - val_loss: 0.3114 - val_acc: 0.9440 - val_gini_normalized: nan\n",
      "Epoch 80/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.3015 - acc: 0.9248 - gini_normalized: nan - val_loss: 0.3158 - val_acc: 0.9380 - val_gini_normalized: nan\n",
      "Epoch 81/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.2986 - acc: 0.9252 - gini_normalized: nan - val_loss: 0.3062 - val_acc: 0.9360 - val_gini_normalized: nan\n",
      "Epoch 82/150\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.3022 - acc: 0.9268 - gini_normalized: nan - val_loss: 0.3071 - val_acc: 0.9420 - val_gini_normalized: nan\n",
      "Epoch 83/150\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.3010 - acc: 0.9232 - gini_normalized: nan - val_loss: 0.3026 - val_acc: 0.9360 - val_gini_normalized: nan\n",
      "Epoch 84/150\n",
      "2500/2500 [==============================] - 0s 90us/step - loss: 0.2982 - acc: 0.9268 - gini_normalized: nan - val_loss: 0.2995 - val_acc: 0.9420 - val_gini_normalized: nan\n",
      "Epoch 85/150\n",
      "2500/2500 [==============================] - 0s 97us/step - loss: 0.2966 - acc: 0.9284 - gini_normalized: nan - val_loss: 0.2912 - val_acc: 0.9380 - val_gini_normalized: nan\n",
      "Epoch 86/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.2966 - acc: 0.9260 - gini_normalized: nan - val_loss: 0.3078 - val_acc: 0.9420 - val_gini_normalized: nan\n",
      "Epoch 87/150\n",
      "2500/2500 [==============================] - 0s 79us/step - loss: 0.2991 - acc: 0.9252 - gini_normalized: nan - val_loss: 0.2925 - val_acc: 0.9400 - val_gini_normalized: nan\n",
      "Epoch 88/150\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.2866 - acc: 0.9280 - gini_normalized: nan - val_loss: 0.3043 - val_acc: 0.9440 - val_gini_normalized: nan\n",
      "Epoch 89/150\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.2848 - acc: 0.9288 - gini_normalized: nan - val_loss: 0.2932 - val_acc: 0.9420 - val_gini_normalized: nan\n",
      "Epoch 90/150\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.2924 - acc: 0.9296 - gini_normalized: nan - val_loss: 0.3013 - val_acc: 0.9460 - val_gini_normalized: nan\n",
      "Epoch 91/150\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.2861 - acc: 0.9304 - gini_normalized: nan - val_loss: 0.2838 - val_acc: 0.9520 - val_gini_normalized: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.2908 - acc: 0.9260 - gini_normalized: nan - val_loss: 0.3097 - val_acc: 0.9440 - val_gini_normalized: nan\n",
      "Epoch 93/150\n",
      "2500/2500 [==============================] - 0s 102us/step - loss: 0.2875 - acc: 0.9256 - gini_normalized: nan - val_loss: 0.3033 - val_acc: 0.9440 - val_gini_normalized: nan\n",
      "Epoch 94/150\n",
      "2500/2500 [==============================] - 0s 109us/step - loss: 0.2897 - acc: 0.9296 - gini_normalized: nan - val_loss: 0.2797 - val_acc: 0.9400 - val_gini_normalized: nan\n",
      "Epoch 95/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.2855 - acc: 0.9268 - gini_normalized: nan - val_loss: 0.2854 - val_acc: 0.9460 - val_gini_normalized: nan\n",
      "Epoch 96/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.2811 - acc: 0.9292 - gini_normalized: nan - val_loss: 0.2771 - val_acc: 0.9400 - val_gini_normalized: nan\n",
      "Epoch 97/150\n",
      "2500/2500 [==============================] - 0s 51us/step - loss: 0.2800 - acc: 0.9284 - gini_normalized: nan - val_loss: 0.2961 - val_acc: 0.9440 - val_gini_normalized: nan\n",
      "Epoch 98/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.2840 - acc: 0.9296 - gini_normalized: nan - val_loss: 0.2918 - val_acc: 0.9480 - val_gini_normalized: nan\n",
      "Epoch 99/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.2846 - acc: 0.9320 - gini_normalized: nan - val_loss: 0.2794 - val_acc: 0.9440 - val_gini_normalized: nan\n",
      "Epoch 100/150\n",
      "2500/2500 [==============================] - 0s 93us/step - loss: 0.2757 - acc: 0.9312 - gini_normalized: nan - val_loss: 0.2910 - val_acc: 0.9460 - val_gini_normalized: nan\n",
      "Epoch 101/150\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.2806 - acc: 0.9336 - gini_normalized: nan - val_loss: 0.2844 - val_acc: 0.9460 - val_gini_normalized: nan\n",
      "Epoch 102/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.2747 - acc: 0.9316 - gini_normalized: nan - val_loss: 0.2957 - val_acc: 0.9440 - val_gini_normalized: nan\n",
      "Epoch 103/150\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.2776 - acc: 0.9296 - gini_normalized: nan - val_loss: 0.2879 - val_acc: 0.9460 - val_gini_normalized: nan\n",
      "Epoch 104/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.2712 - acc: 0.9344 - gini_normalized: nan - val_loss: 0.2728 - val_acc: 0.9520 - val_gini_normalized: nan\n",
      "Epoch 105/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.2764 - acc: 0.9300 - gini_normalized: nan - val_loss: 0.2716 - val_acc: 0.9480 - val_gini_normalized: nan\n",
      "Epoch 106/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.2790 - acc: 0.9304 - gini_normalized: nan - val_loss: 0.2694 - val_acc: 0.9480 - val_gini_normalized: nan\n",
      "Epoch 107/150\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.2738 - acc: 0.9316 - gini_normalized: nan - val_loss: 0.2615 - val_acc: 0.9380 - val_gini_normalized: nan\n",
      "Epoch 108/150\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.2676 - acc: 0.9312 - gini_normalized: nan - val_loss: 0.2585 - val_acc: 0.9480 - val_gini_normalized: nan\n",
      "Epoch 109/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.2749 - acc: 0.9288 - gini_normalized: nan - val_loss: 0.2638 - val_acc: 0.9520 - val_gini_normalized: nan\n",
      "Epoch 110/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.2701 - acc: 0.9316 - gini_normalized: nan - val_loss: 0.2626 - val_acc: 0.9520 - val_gini_normalized: nan\n",
      "Epoch 111/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.2701 - acc: 0.9352 - gini_normalized: nan - val_loss: 0.2579 - val_acc: 0.9560 - val_gini_normalized: nan\n",
      "Epoch 112/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.2704 - acc: 0.9324 - gini_normalized: nan - val_loss: 0.2707 - val_acc: 0.9500 - val_gini_normalized: nan\n",
      "Epoch 113/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.2732 - acc: 0.9336 - gini_normalized: nan - val_loss: 0.2555 - val_acc: 0.9520 - val_gini_normalized: nan\n",
      "Epoch 114/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.2686 - acc: 0.9348 - gini_normalized: nan - val_loss: 0.2617 - val_acc: 0.9520 - val_gini_normalized: nan\n",
      "Epoch 115/150\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.2664 - acc: 0.9368 - gini_normalized: nan - val_loss: 0.2680 - val_acc: 0.9480 - val_gini_normalized: nan\n",
      "Epoch 116/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.2596 - acc: 0.9340 - gini_normalized: nan - val_loss: 0.2961 - val_acc: 0.9460 - val_gini_normalized: nan\n",
      "Epoch 117/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.2619 - acc: 0.9360 - gini_normalized: nan - val_loss: 0.2705 - val_acc: 0.9500 - val_gini_normalized: nan\n",
      "Epoch 118/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.2667 - acc: 0.9348 - gini_normalized: nan - val_loss: 0.2633 - val_acc: 0.9460 - val_gini_normalized: nan\n",
      "Epoch 119/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.2630 - acc: 0.9352 - gini_normalized: nan - val_loss: 0.2619 - val_acc: 0.9480 - val_gini_normalized: nan\n",
      "Epoch 120/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.2576 - acc: 0.9320 - gini_normalized: nan - val_loss: 0.2606 - val_acc: 0.9460 - val_gini_normalized: nan\n",
      "Epoch 121/150\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.2572 - acc: 0.9332 - gini_normalized: nan - val_loss: 0.2650 - val_acc: 0.9480 - val_gini_normalized: nan\n",
      "Epoch 122/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.2657 - acc: 0.9332 - gini_normalized: nan - val_loss: 0.2784 - val_acc: 0.9420 - val_gini_normalized: nan\n",
      "Epoch 123/150\n",
      "2500/2500 [==============================] - 0s 47us/step - loss: 0.2618 - acc: 0.9368 - gini_normalized: nan - val_loss: 0.2682 - val_acc: 0.9460 - val_gini_normalized: nan\n",
      "Epoch 124/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.2581 - acc: 0.9360 - gini_normalized: nan - val_loss: 0.2540 - val_acc: 0.9520 - val_gini_normalized: nan\n",
      "Epoch 125/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.2601 - acc: 0.9336 - gini_normalized: nan - val_loss: 0.2516 - val_acc: 0.9520 - val_gini_normalized: nan\n",
      "Epoch 126/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.2574 - acc: 0.9352 - gini_normalized: nan - val_loss: 0.2569 - val_acc: 0.9500 - val_gini_normalized: nan\n",
      "Epoch 127/150\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.2576 - acc: 0.9372 - gini_normalized: nan - val_loss: 0.2333 - val_acc: 0.9520 - val_gini_normalized: nan\n",
      "Epoch 128/150\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.2590 - acc: 0.9364 - gini_normalized: nan - val_loss: 0.2422 - val_acc: 0.9540 - val_gini_normalized: nan\n",
      "Epoch 129/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.2506 - acc: 0.9348 - gini_normalized: nan - val_loss: 0.2553 - val_acc: 0.9440 - val_gini_normalized: nan\n",
      "Epoch 130/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.2615 - acc: 0.9372 - gini_normalized: nan - val_loss: 0.2458 - val_acc: 0.9540 - val_gini_normalized: nan\n",
      "Epoch 131/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.2613 - acc: 0.9340 - gini_normalized: nan - val_loss: 0.2542 - val_acc: 0.9500 - val_gini_normalized: nan\n",
      "Epoch 132/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.2533 - acc: 0.9372 - gini_normalized: nan - val_loss: 0.2638 - val_acc: 0.9540 - val_gini_normalized: nan\n",
      "Epoch 133/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.2435 - acc: 0.9376 - gini_normalized: nan - val_loss: 0.3259 - val_acc: 0.9340 - val_gini_normalized: nan\n",
      "Epoch 134/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.2460 - acc: 0.9368 - gini_normalized: nan - val_loss: 0.2814 - val_acc: 0.9480 - val_gini_normalized: nan\n",
      "Epoch 135/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.2608 - acc: 0.9320 - gini_normalized: nan - val_loss: 0.2415 - val_acc: 0.9540 - val_gini_normalized: nan\n",
      "Epoch 136/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.2501 - acc: 0.9388 - gini_normalized: nan - val_loss: 0.2474 - val_acc: 0.9500 - val_gini_normalized: nan\n",
      "Epoch 137/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.2510 - acc: 0.9384 - gini_normalized: nan - val_loss: 0.2426 - val_acc: 0.9500 - val_gini_normalized: nan\n",
      "Epoch 138/150\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.2517 - acc: 0.9364 - gini_normalized: nan - val_loss: 0.2465 - val_acc: 0.9520 - val_gini_normalized: nan\n",
      "Epoch 139/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.2508 - acc: 0.9380 - gini_normalized: nan - val_loss: 0.2388 - val_acc: 0.9480 - val_gini_normalized: nan\n",
      "Epoch 140/150\n",
      "2500/2500 [==============================] - 0s 53us/step - loss: 0.2676 - acc: 0.9316 - gini_normalized: nan - val_loss: 0.2457 - val_acc: 0.9500 - val_gini_normalized: nan\n",
      "Epoch 141/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.2514 - acc: 0.9396 - gini_normalized: nan - val_loss: 0.2389 - val_acc: 0.9520 - val_gini_normalized: nan\n",
      "Epoch 142/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.2516 - acc: 0.9384 - gini_normalized: nan - val_loss: 0.2537 - val_acc: 0.9480 - val_gini_normalized: nan\n",
      "Epoch 143/150\n",
      "2500/2500 [==============================] - 0s 53us/step - loss: 0.2536 - acc: 0.9368 - gini_normalized: nan - val_loss: 0.2275 - val_acc: 0.9560 - val_gini_normalized: nan\n",
      "Epoch 144/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.2353 - acc: 0.9404 - gini_normalized: nan - val_loss: 0.2443 - val_acc: 0.9520 - val_gini_normalized: nan\n",
      "Epoch 145/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.2452 - acc: 0.9376 - gini_normalized: nan - val_loss: 0.2434 - val_acc: 0.9520 - val_gini_normalized: nan\n",
      "Epoch 146/150\n",
      "2500/2500 [==============================] - 0s 51us/step - loss: 0.2508 - acc: 0.9404 - gini_normalized: nan - val_loss: 0.2418 - val_acc: 0.9540 - val_gini_normalized: nan\n",
      "Epoch 147/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.2460 - acc: 0.9408 - gini_normalized: nan - val_loss: 0.2271 - val_acc: 0.9580 - val_gini_normalized: nan\n",
      "Epoch 148/150\n",
      "2500/2500 [==============================] - 0s 53us/step - loss: 0.2445 - acc: 0.9428 - gini_normalized: nan - val_loss: 0.2872 - val_acc: 0.9460 - val_gini_normalized: nan\n",
      "Epoch 149/150\n",
      "2500/2500 [==============================] - 0s 44us/step - loss: 0.2397 - acc: 0.9412 - gini_normalized: nan - val_loss: 0.2275 - val_acc: 0.9520 - val_gini_normalized: nan\n",
      "Epoch 150/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.2406 - acc: 0.9400 - gini_normalized: nan - val_loss: 0.2546 - val_acc: 0.9440 - val_gini_normalized: nan\n",
      "500/500 [==============================] - 0s 63us/step\n",
      "Train on 2500 samples, validate on 500 samples\n",
      "Epoch 1/150\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.4654 - acc: 0.5648 - gini_normalized: nan - val_loss: 1.2868 - val_acc: 0.6260 - val_gini_normalized: nan\n",
      "Epoch 2/150\n",
      "2500/2500 [==============================] - 0s 51us/step - loss: 1.1439 - acc: 0.6652 - gini_normalized: nan - val_loss: 1.0905 - val_acc: 0.6900 - val_gini_normalized: nan\n",
      "Epoch 3/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.9826 - acc: 0.7280 - gini_normalized: nan - val_loss: 0.9729 - val_acc: 0.7500 - val_gini_normalized: nan\n",
      "Epoch 4/150\n",
      "2500/2500 [==============================] - 0s 53us/step - loss: 0.8752 - acc: 0.7692 - gini_normalized: nan - val_loss: 0.8904 - val_acc: 0.7760 - val_gini_normalized: nan\n",
      "Epoch 5/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.7988 - acc: 0.7972 - gini_normalized: nan - val_loss: 0.8231 - val_acc: 0.7800 - val_gini_normalized: nan\n",
      "Epoch 6/150\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.7449 - acc: 0.8064 - gini_normalized: nan - val_loss: 0.7722 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 7/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.6997 - acc: 0.8124 - gini_normalized: nan - val_loss: 0.7252 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 8/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.6645 - acc: 0.8240 - gini_normalized: nan - val_loss: 0.7002 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 9/150\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.6381 - acc: 0.8264 - gini_normalized: nan - val_loss: 0.6778 - val_acc: 0.7980 - val_gini_normalized: nan\n",
      "Epoch 10/150\n",
      "2500/2500 [==============================] - 0s 53us/step - loss: 0.6179 - acc: 0.8284 - gini_normalized: nan - val_loss: 0.6593 - val_acc: 0.8060 - val_gini_normalized: nan\n",
      "Epoch 11/150\n",
      "2500/2500 [==============================] - 0s 53us/step - loss: 0.5982 - acc: 0.8312 - gini_normalized: nan - val_loss: 0.6387 - val_acc: 0.8100 - val_gini_normalized: nan\n",
      "Epoch 12/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.5827 - acc: 0.8304 - gini_normalized: nan - val_loss: 0.6260 - val_acc: 0.8160 - val_gini_normalized: nan\n",
      "Epoch 13/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.5711 - acc: 0.8332 - gini_normalized: nan - val_loss: 0.6197 - val_acc: 0.8160 - val_gini_normalized: nan\n",
      "Epoch 14/150\n",
      "2500/2500 [==============================] - 0s 44us/step - loss: 0.5576 - acc: 0.8376 - gini_normalized: nan - val_loss: 0.6091 - val_acc: 0.8180 - val_gini_normalized: nan\n",
      "Epoch 15/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.5519 - acc: 0.8308 - gini_normalized: nan - val_loss: 0.6028 - val_acc: 0.8220 - val_gini_normalized: nan\n",
      "Epoch 16/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.5363 - acc: 0.8436 - gini_normalized: nan - val_loss: 0.5828 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 17/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.5298 - acc: 0.8412 - gini_normalized: nan - val_loss: 0.5651 - val_acc: 0.8220 - val_gini_normalized: nan\n",
      "Epoch 18/150\n",
      "2500/2500 [==============================] - 0s 52us/step - loss: 0.5253 - acc: 0.8424 - gini_normalized: nan - val_loss: 0.5598 - val_acc: 0.8260 - val_gini_normalized: nan\n",
      "Epoch 19/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.5157 - acc: 0.8444 - gini_normalized: nan - val_loss: 0.5469 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 20/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.5091 - acc: 0.8468 - gini_normalized: nan - val_loss: 0.5513 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 21/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4981 - acc: 0.8464 - gini_normalized: nan - val_loss: 0.5490 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 22/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4938 - acc: 0.8508 - gini_normalized: nan - val_loss: 0.5294 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 23/150\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4913 - acc: 0.8480 - gini_normalized: nan - val_loss: 0.5309 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 24/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4827 - acc: 0.8516 - gini_normalized: nan - val_loss: 0.5221 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 25/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.4740 - acc: 0.8556 - gini_normalized: nan - val_loss: 0.5045 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 26/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.4765 - acc: 0.8556 - gini_normalized: nan - val_loss: 0.5231 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 27/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.4652 - acc: 0.8524 - gini_normalized: nan - val_loss: 0.4890 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 28/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4689 - acc: 0.8560 - gini_normalized: nan - val_loss: 0.5016 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 29/150\n",
      "2500/2500 [==============================] - 0s 46us/step - loss: 0.4578 - acc: 0.8532 - gini_normalized: nan - val_loss: 0.5090 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 30/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4570 - acc: 0.8580 - gini_normalized: nan - val_loss: 0.4898 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 31/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.4544 - acc: 0.8592 - gini_normalized: nan - val_loss: 0.4878 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 32/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.4493 - acc: 0.8544 - gini_normalized: nan - val_loss: 0.4983 - val_acc: 0.8520 - val_gini_normalized: nan\n",
      "Epoch 33/150\n",
      "2500/2500 [==============================] - 0s 95us/step - loss: 0.4482 - acc: 0.8616 - gini_normalized: nan - val_loss: 0.4796 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 34/150\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4439 - acc: 0.8612 - gini_normalized: nan - val_loss: 0.4825 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 35/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4386 - acc: 0.8576 - gini_normalized: nan - val_loss: 0.4814 - val_acc: 0.8560 - val_gini_normalized: nan\n",
      "Epoch 36/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4343 - acc: 0.8680 - gini_normalized: nan - val_loss: 0.4899 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 37/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.4314 - acc: 0.8620 - gini_normalized: nan - val_loss: 0.4746 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 38/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.4348 - acc: 0.8648 - gini_normalized: nan - val_loss: 0.4749 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 39/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4266 - acc: 0.8652 - gini_normalized: nan - val_loss: 0.4653 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 40/150\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4234 - acc: 0.8664 - gini_normalized: nan - val_loss: 0.4619 - val_acc: 0.8560 - val_gini_normalized: nan\n",
      "Epoch 41/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4209 - acc: 0.8716 - gini_normalized: nan - val_loss: 0.4687 - val_acc: 0.8580 - val_gini_normalized: nan\n",
      "Epoch 42/150\n",
      "2500/2500 [==============================] - 0s 51us/step - loss: 0.4203 - acc: 0.8696 - gini_normalized: nan - val_loss: 0.4506 - val_acc: 0.8600 - val_gini_normalized: nan\n",
      "Epoch 43/150\n",
      "2500/2500 [==============================] - 0s 53us/step - loss: 0.4115 - acc: 0.8688 - gini_normalized: nan - val_loss: 0.4474 - val_acc: 0.8660 - val_gini_normalized: nan\n",
      "Epoch 44/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4171 - acc: 0.8748 - gini_normalized: nan - val_loss: 0.4491 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 45/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.4162 - acc: 0.8748 - gini_normalized: nan - val_loss: 0.4452 - val_acc: 0.8580 - val_gini_normalized: nan\n",
      "Epoch 46/150\n",
      "2500/2500 [==============================] - 0s 46us/step - loss: 0.4117 - acc: 0.8724 - gini_normalized: nan - val_loss: 0.4525 - val_acc: 0.8660 - val_gini_normalized: nan\n",
      "Epoch 47/150\n",
      "2500/2500 [==============================] - 0s 51us/step - loss: 0.4071 - acc: 0.8732 - gini_normalized: nan - val_loss: 0.4455 - val_acc: 0.8660 - val_gini_normalized: nan\n",
      "Epoch 48/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.4031 - acc: 0.8784 - gini_normalized: nan - val_loss: 0.4472 - val_acc: 0.8620 - val_gini_normalized: nan\n",
      "Epoch 49/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3994 - acc: 0.8764 - gini_normalized: nan - val_loss: 0.4314 - val_acc: 0.8560 - val_gini_normalized: nan\n",
      "Epoch 50/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.4009 - acc: 0.8752 - gini_normalized: nan - val_loss: 0.4360 - val_acc: 0.8620 - val_gini_normalized: nan\n",
      "Epoch 51/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3946 - acc: 0.8828 - gini_normalized: nan - val_loss: 0.4246 - val_acc: 0.8700 - val_gini_normalized: nan\n",
      "Epoch 52/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3911 - acc: 0.8764 - gini_normalized: nan - val_loss: 0.4201 - val_acc: 0.8720 - val_gini_normalized: nan\n",
      "Epoch 53/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3873 - acc: 0.8812 - gini_normalized: nan - val_loss: 0.4170 - val_acc: 0.8740 - val_gini_normalized: nan\n",
      "Epoch 54/150\n",
      "2500/2500 [==============================] - 0s 52us/step - loss: 0.3900 - acc: 0.8844 - gini_normalized: nan - val_loss: 0.4244 - val_acc: 0.8680 - val_gini_normalized: nan\n",
      "Epoch 55/150\n",
      "2500/2500 [==============================] - 0s 85us/step - loss: 0.3812 - acc: 0.8876 - gini_normalized: nan - val_loss: 0.4120 - val_acc: 0.8800 - val_gini_normalized: nan\n",
      "Epoch 56/150\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.3940 - acc: 0.8824 - gini_normalized: nan - val_loss: 0.4187 - val_acc: 0.8680 - val_gini_normalized: nan\n",
      "Epoch 57/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.3772 - acc: 0.8828 - gini_normalized: nan - val_loss: 0.4148 - val_acc: 0.8700 - val_gini_normalized: nan\n",
      "Epoch 58/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.3815 - acc: 0.8824 - gini_normalized: nan - val_loss: 0.4083 - val_acc: 0.8680 - val_gini_normalized: nan\n",
      "Epoch 59/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.3710 - acc: 0.8888 - gini_normalized: nan - val_loss: 0.4181 - val_acc: 0.8740 - val_gini_normalized: nan\n",
      "Epoch 60/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.3709 - acc: 0.8876 - gini_normalized: nan - val_loss: 0.4023 - val_acc: 0.8860 - val_gini_normalized: nan\n",
      "Epoch 61/150\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.3696 - acc: 0.8908 - gini_normalized: nan - val_loss: 0.3986 - val_acc: 0.8780 - val_gini_normalized: nan\n",
      "Epoch 62/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3689 - acc: 0.8908 - gini_normalized: nan - val_loss: 0.4051 - val_acc: 0.8820 - val_gini_normalized: nan\n",
      "Epoch 63/150\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.3628 - acc: 0.8916 - gini_normalized: nan - val_loss: 0.3917 - val_acc: 0.8880 - val_gini_normalized: nan\n",
      "Epoch 64/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.3628 - acc: 0.8916 - gini_normalized: nan - val_loss: 0.4057 - val_acc: 0.8880 - val_gini_normalized: nan\n",
      "Epoch 65/150\n",
      "2500/2500 [==============================] - 0s 52us/step - loss: 0.3637 - acc: 0.8948 - gini_normalized: nan - val_loss: 0.3830 - val_acc: 0.8940 - val_gini_normalized: nan\n",
      "Epoch 66/150\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.3567 - acc: 0.8960 - gini_normalized: nan - val_loss: 0.3893 - val_acc: 0.8920 - val_gini_normalized: nan\n",
      "Epoch 67/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.3524 - acc: 0.9004 - gini_normalized: nan - val_loss: 0.3866 - val_acc: 0.8940 - val_gini_normalized: nan\n",
      "Epoch 68/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.3569 - acc: 0.8968 - gini_normalized: nan - val_loss: 0.3910 - val_acc: 0.8820 - val_gini_normalized: nan\n",
      "Epoch 69/150\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.3474 - acc: 0.8976 - gini_normalized: nan - val_loss: 0.3762 - val_acc: 0.8960 - val_gini_normalized: nan\n",
      "Epoch 70/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.3500 - acc: 0.9024 - gini_normalized: nan - val_loss: 0.3747 - val_acc: 0.9060 - val_gini_normalized: nan\n",
      "Epoch 71/150\n",
      "2500/2500 [==============================] - 0s 53us/step - loss: 0.3424 - acc: 0.9048 - gini_normalized: nan - val_loss: 0.3868 - val_acc: 0.8940 - val_gini_normalized: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/150\n",
      "2500/2500 [==============================] - 0s 46us/step - loss: 0.3451 - acc: 0.9016 - gini_normalized: nan - val_loss: 0.3859 - val_acc: 0.8960 - val_gini_normalized: nan\n",
      "Epoch 73/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.3439 - acc: 0.9032 - gini_normalized: nan - val_loss: 0.3697 - val_acc: 0.9040 - val_gini_normalized: nan\n",
      "Epoch 74/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3370 - acc: 0.9044 - gini_normalized: nan - val_loss: 0.3632 - val_acc: 0.8940 - val_gini_normalized: nan\n",
      "Epoch 75/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.3374 - acc: 0.9036 - gini_normalized: nan - val_loss: 0.3596 - val_acc: 0.9100 - val_gini_normalized: nan\n",
      "Epoch 76/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.3339 - acc: 0.9072 - gini_normalized: nan - val_loss: 0.3631 - val_acc: 0.8980 - val_gini_normalized: nan\n",
      "Epoch 77/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3363 - acc: 0.9044 - gini_normalized: nan - val_loss: 0.3732 - val_acc: 0.9020 - val_gini_normalized: nan\n",
      "Epoch 78/150\n",
      "2500/2500 [==============================] - 0s 46us/step - loss: 0.3298 - acc: 0.9028 - gini_normalized: nan - val_loss: 0.3644 - val_acc: 0.8860 - val_gini_normalized: nan\n",
      "Epoch 79/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.3292 - acc: 0.9104 - gini_normalized: nan - val_loss: 0.3619 - val_acc: 0.8840 - val_gini_normalized: nan\n",
      "Epoch 80/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3266 - acc: 0.9068 - gini_normalized: nan - val_loss: 0.3481 - val_acc: 0.9080 - val_gini_normalized: nan\n",
      "Epoch 81/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3366 - acc: 0.9088 - gini_normalized: nan - val_loss: 0.3541 - val_acc: 0.8940 - val_gini_normalized: nan\n",
      "Epoch 82/150\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.3313 - acc: 0.9076 - gini_normalized: nan - val_loss: 0.3517 - val_acc: 0.9080 - val_gini_normalized: nan\n",
      "Epoch 83/150\n",
      "2500/2500 [==============================] - 0s 52us/step - loss: 0.3243 - acc: 0.9120 - gini_normalized: nan - val_loss: 0.3465 - val_acc: 0.9000 - val_gini_normalized: nan\n",
      "Epoch 84/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.3225 - acc: 0.9116 - gini_normalized: nan - val_loss: 0.3408 - val_acc: 0.9020 - val_gini_normalized: nan\n",
      "Epoch 85/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.3241 - acc: 0.9128 - gini_normalized: nan - val_loss: 0.3413 - val_acc: 0.9080 - val_gini_normalized: nan\n",
      "Epoch 86/150\n",
      "2500/2500 [==============================] - 0s 48us/step - loss: 0.3275 - acc: 0.9092 - gini_normalized: nan - val_loss: 0.3279 - val_acc: 0.9140 - val_gini_normalized: nan\n",
      "Epoch 87/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.3160 - acc: 0.9132 - gini_normalized: nan - val_loss: 0.3313 - val_acc: 0.9180 - val_gini_normalized: nan\n",
      "Epoch 88/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3197 - acc: 0.9136 - gini_normalized: nan - val_loss: 0.3417 - val_acc: 0.9080 - val_gini_normalized: nan\n",
      "Epoch 89/150\n",
      "2500/2500 [==============================] - 0s 92us/step - loss: 0.3120 - acc: 0.9152 - gini_normalized: nan - val_loss: 0.3386 - val_acc: 0.9180 - val_gini_normalized: nan\n",
      "Epoch 90/150\n",
      "2500/2500 [==============================] - 0s 107us/step - loss: 0.3104 - acc: 0.9132 - gini_normalized: nan - val_loss: 0.3336 - val_acc: 0.9160 - val_gini_normalized: nan\n",
      "Epoch 91/150\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.3164 - acc: 0.9172 - gini_normalized: nan - val_loss: 0.3352 - val_acc: 0.9100 - val_gini_normalized: nan\n",
      "Epoch 92/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.3088 - acc: 0.9144 - gini_normalized: nan - val_loss: 0.3407 - val_acc: 0.9100 - val_gini_normalized: nan\n",
      "Epoch 93/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.3100 - acc: 0.9172 - gini_normalized: nan - val_loss: 0.3221 - val_acc: 0.9100 - val_gini_normalized: nan\n",
      "Epoch 94/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.3103 - acc: 0.9160 - gini_normalized: nan - val_loss: 0.3255 - val_acc: 0.9180 - val_gini_normalized: nan\n",
      "Epoch 95/150\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.3097 - acc: 0.9176 - gini_normalized: nan - val_loss: 0.3348 - val_acc: 0.9080 - val_gini_normalized: nan\n",
      "Epoch 96/150\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.3101 - acc: 0.9156 - gini_normalized: nan - val_loss: 0.3155 - val_acc: 0.9160 - val_gini_normalized: nan\n",
      "Epoch 97/150\n",
      "2500/2500 [==============================] - 0s 51us/step - loss: 0.3084 - acc: 0.9204 - gini_normalized: nan - val_loss: 0.3224 - val_acc: 0.9040 - val_gini_normalized: nan\n",
      "Epoch 98/150\n",
      "2500/2500 [==============================] - 0s 52us/step - loss: 0.3093 - acc: 0.9152 - gini_normalized: nan - val_loss: 0.3116 - val_acc: 0.9200 - val_gini_normalized: nan\n",
      "Epoch 99/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.2976 - acc: 0.9184 - gini_normalized: nan - val_loss: 0.3240 - val_acc: 0.9160 - val_gini_normalized: nan\n",
      "Epoch 100/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.3016 - acc: 0.9152 - gini_normalized: nan - val_loss: 0.3162 - val_acc: 0.9220 - val_gini_normalized: nan\n",
      "Epoch 101/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.3064 - acc: 0.9184 - gini_normalized: nan - val_loss: 0.3163 - val_acc: 0.9140 - val_gini_normalized: nan\n",
      "Epoch 102/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.2969 - acc: 0.9204 - gini_normalized: nan - val_loss: 0.3146 - val_acc: 0.9160 - val_gini_normalized: nan\n",
      "Epoch 103/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.2901 - acc: 0.9196 - gini_normalized: nan - val_loss: 0.3242 - val_acc: 0.9120 - val_gini_normalized: nan\n",
      "Epoch 104/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.2995 - acc: 0.9228 - gini_normalized: nan - val_loss: 0.3122 - val_acc: 0.9220 - val_gini_normalized: nan\n",
      "Epoch 105/150\n",
      "2500/2500 [==============================] - 0s 51us/step - loss: 0.3003 - acc: 0.9208 - gini_normalized: nan - val_loss: 0.3208 - val_acc: 0.9240 - val_gini_normalized: nan\n",
      "Epoch 106/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.2881 - acc: 0.9200 - gini_normalized: nan - val_loss: 0.3073 - val_acc: 0.9260 - val_gini_normalized: nan\n",
      "Epoch 107/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.2877 - acc: 0.9192 - gini_normalized: nan - val_loss: 0.2989 - val_acc: 0.9280 - val_gini_normalized: nan\n",
      "Epoch 108/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.2993 - acc: 0.9204 - gini_normalized: nan - val_loss: 0.3250 - val_acc: 0.9200 - val_gini_normalized: nan\n",
      "Epoch 109/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.2922 - acc: 0.9220 - gini_normalized: nan - val_loss: 0.3109 - val_acc: 0.9080 - val_gini_normalized: nan\n",
      "Epoch 110/150\n",
      "2500/2500 [==============================] - 0s 88us/step - loss: 0.2944 - acc: 0.9236 - gini_normalized: nan - val_loss: 0.3053 - val_acc: 0.9300 - val_gini_normalized: nan\n",
      "Epoch 111/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.2886 - acc: 0.9208 - gini_normalized: nan - val_loss: 0.3060 - val_acc: 0.9260 - val_gini_normalized: nan\n",
      "Epoch 112/150\n",
      "2500/2500 [==============================] - 0s 90us/step - loss: 0.2807 - acc: 0.9236 - gini_normalized: nan - val_loss: 0.3189 - val_acc: 0.9100 - val_gini_normalized: nan\n",
      "Epoch 113/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.2883 - acc: 0.9232 - gini_normalized: nan - val_loss: 0.2884 - val_acc: 0.9360 - val_gini_normalized: nan\n",
      "Epoch 114/150\n",
      "2500/2500 [==============================] - 0s 87us/step - loss: 0.2827 - acc: 0.9216 - gini_normalized: nan - val_loss: 0.3096 - val_acc: 0.9200 - val_gini_normalized: nan\n",
      "Epoch 115/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.2795 - acc: 0.9244 - gini_normalized: nan - val_loss: 0.2941 - val_acc: 0.9280 - val_gini_normalized: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.2788 - acc: 0.9244 - gini_normalized: nan - val_loss: 0.3069 - val_acc: 0.9220 - val_gini_normalized: nan\n",
      "Epoch 117/150\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.2834 - acc: 0.9228 - gini_normalized: nan - val_loss: 0.2985 - val_acc: 0.9300 - val_gini_normalized: nan\n",
      "Epoch 118/150\n",
      "2500/2500 [==============================] - 0s 102us/step - loss: 0.2841 - acc: 0.9224 - gini_normalized: nan - val_loss: 0.2961 - val_acc: 0.9300 - val_gini_normalized: nan\n",
      "Epoch 119/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.2842 - acc: 0.9284 - gini_normalized: nan - val_loss: 0.2926 - val_acc: 0.9320 - val_gini_normalized: nan\n",
      "Epoch 120/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.2776 - acc: 0.9272 - gini_normalized: nan - val_loss: 0.2932 - val_acc: 0.9280 - val_gini_normalized: nan\n",
      "Epoch 121/150\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.2757 - acc: 0.9244 - gini_normalized: nan - val_loss: 0.2944 - val_acc: 0.9220 - val_gini_normalized: nan\n",
      "Epoch 122/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.2738 - acc: 0.9268 - gini_normalized: nan - val_loss: 0.2756 - val_acc: 0.9360 - val_gini_normalized: nan\n",
      "Epoch 123/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.2711 - acc: 0.9260 - gini_normalized: nan - val_loss: 0.2938 - val_acc: 0.9220 - val_gini_normalized: nan\n",
      "Epoch 124/150\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.2736 - acc: 0.9280 - gini_normalized: nan - val_loss: 0.2844 - val_acc: 0.9360 - val_gini_normalized: nan\n",
      "Epoch 125/150\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.2738 - acc: 0.9288 - gini_normalized: nan - val_loss: 0.2903 - val_acc: 0.9180 - val_gini_normalized: nan\n",
      "Epoch 126/150\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.2679 - acc: 0.9252 - gini_normalized: nan - val_loss: 0.2802 - val_acc: 0.9360 - val_gini_normalized: nan\n",
      "Epoch 127/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.2781 - acc: 0.9308 - gini_normalized: nan - val_loss: 0.2817 - val_acc: 0.9260 - val_gini_normalized: nan\n",
      "Epoch 128/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.2634 - acc: 0.9256 - gini_normalized: nan - val_loss: 0.2941 - val_acc: 0.9300 - val_gini_normalized: nan\n",
      "Epoch 129/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.2700 - acc: 0.9260 - gini_normalized: nan - val_loss: 0.2755 - val_acc: 0.9380 - val_gini_normalized: nan\n",
      "Epoch 130/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.2698 - acc: 0.9304 - gini_normalized: nan - val_loss: 0.2760 - val_acc: 0.9360 - val_gini_normalized: nan\n",
      "Epoch 131/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.2642 - acc: 0.9244 - gini_normalized: nan - val_loss: 0.2765 - val_acc: 0.9280 - val_gini_normalized: nan\n",
      "Epoch 132/150\n",
      "2500/2500 [==============================] - 0s 44us/step - loss: 0.2750 - acc: 0.9284 - gini_normalized: nan - val_loss: 0.2804 - val_acc: 0.9340 - val_gini_normalized: nan\n",
      "Epoch 133/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.2595 - acc: 0.9300 - gini_normalized: nan - val_loss: 0.2725 - val_acc: 0.9380 - val_gini_normalized: nan\n",
      "Epoch 134/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.2643 - acc: 0.9276 - gini_normalized: nan - val_loss: 0.2945 - val_acc: 0.9240 - val_gini_normalized: nan\n",
      "Epoch 135/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.2660 - acc: 0.9304 - gini_normalized: nan - val_loss: 0.2709 - val_acc: 0.9340 - val_gini_normalized: nan\n",
      "Epoch 136/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.2555 - acc: 0.9348 - gini_normalized: nan - val_loss: 0.2695 - val_acc: 0.9300 - val_gini_normalized: nan\n",
      "Epoch 137/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.2556 - acc: 0.9308 - gini_normalized: nan - val_loss: 0.2726 - val_acc: 0.9400 - val_gini_normalized: nan\n",
      "Epoch 138/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.2611 - acc: 0.9300 - gini_normalized: nan - val_loss: 0.2738 - val_acc: 0.9320 - val_gini_normalized: nan\n",
      "Epoch 139/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.2546 - acc: 0.9300 - gini_normalized: nan - val_loss: 0.2751 - val_acc: 0.9320 - val_gini_normalized: nan\n",
      "Epoch 140/150\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 0.2630 - acc: 0.9316 - gini_normalized: n - 0s 50us/step - loss: 0.2635 - acc: 0.9320 - gini_normalized: nan - val_loss: 0.2750 - val_acc: 0.9220 - val_gini_normalized: nan\n",
      "Epoch 141/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.2518 - acc: 0.9340 - gini_normalized: nan - val_loss: 0.2764 - val_acc: 0.9220 - val_gini_normalized: nan\n",
      "Epoch 142/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.2654 - acc: 0.9312 - gini_normalized: nan - val_loss: 0.2747 - val_acc: 0.9140 - val_gini_normalized: nan\n",
      "Epoch 143/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.2616 - acc: 0.9288 - gini_normalized: nan - val_loss: 0.2770 - val_acc: 0.9360 - val_gini_normalized: nan\n",
      "Epoch 144/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.2595 - acc: 0.9340 - gini_normalized: nan - val_loss: 0.2663 - val_acc: 0.9300 - val_gini_normalized: nan\n",
      "Epoch 145/150\n",
      "2500/2500 [==============================] - 0s 53us/step - loss: 0.2534 - acc: 0.9328 - gini_normalized: nan - val_loss: 0.2674 - val_acc: 0.9280 - val_gini_normalized: nan\n",
      "Epoch 146/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.2592 - acc: 0.9304 - gini_normalized: nan - val_loss: 0.2691 - val_acc: 0.9380 - val_gini_normalized: nan\n",
      "Epoch 147/150\n",
      "2500/2500 [==============================] - 0s 51us/step - loss: 0.2524 - acc: 0.9324 - gini_normalized: nan - val_loss: 0.2587 - val_acc: 0.9360 - val_gini_normalized: nan\n",
      "Epoch 148/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.2475 - acc: 0.9332 - gini_normalized: nan - val_loss: 0.2798 - val_acc: 0.9300 - val_gini_normalized: nan\n",
      "Epoch 149/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.2621 - acc: 0.9320 - gini_normalized: nan - val_loss: 0.2581 - val_acc: 0.9400 - val_gini_normalized: nan\n",
      "Epoch 150/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.2472 - acc: 0.9340 - gini_normalized: nan - val_loss: 0.2711 - val_acc: 0.9280 - val_gini_normalized: nan\n",
      "500/500 [==============================] - 0s 63us/step\n",
      "Train on 2500 samples, validate on 500 samples\n",
      "Epoch 1/150\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.4536 - acc: 0.4828 - gini_normalized: nan - val_loss: 1.2202 - val_acc: 0.5520 - val_gini_normalized: nan\n",
      "Epoch 2/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 1.2014 - acc: 0.5704 - gini_normalized: nan - val_loss: 1.0653 - val_acc: 0.6320 - val_gini_normalized: nan\n",
      "Epoch 3/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 1.0420 - acc: 0.6468 - gini_normalized: nan - val_loss: 0.9704 - val_acc: 0.6900 - val_gini_normalized: nan\n",
      "Epoch 4/150\n",
      "2500/2500 [==============================] - 0s 51us/step - loss: 0.9451 - acc: 0.6940 - gini_normalized: nan - val_loss: 0.9064 - val_acc: 0.7060 - val_gini_normalized: nan\n",
      "Epoch 5/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.8728 - acc: 0.7320 - gini_normalized: nan - val_loss: 0.8478 - val_acc: 0.7300 - val_gini_normalized: nan\n",
      "Epoch 6/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.8165 - acc: 0.7516 - gini_normalized: nan - val_loss: 0.8119 - val_acc: 0.7420 - val_gini_normalized: nan\n",
      "Epoch 7/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.7703 - acc: 0.7740 - gini_normalized: nan - val_loss: 0.7687 - val_acc: 0.7600 - val_gini_normalized: nan\n",
      "Epoch 8/150\n",
      "2500/2500 [==============================] - 0s 47us/step - loss: 0.7308 - acc: 0.7876 - gini_normalized: nan - val_loss: 0.7402 - val_acc: 0.7760 - val_gini_normalized: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.7001 - acc: 0.7984 - gini_normalized: nan - val_loss: 0.7124 - val_acc: 0.7760 - val_gini_normalized: nan\n",
      "Epoch 10/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.6747 - acc: 0.8032 - gini_normalized: nan - val_loss: 0.6993 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 11/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.6509 - acc: 0.8048 - gini_normalized: nan - val_loss: 0.6793 - val_acc: 0.7720 - val_gini_normalized: nan\n",
      "Epoch 12/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.6319 - acc: 0.8112 - gini_normalized: nan - val_loss: 0.6709 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 13/150\n",
      "2500/2500 [==============================] - 0s 52us/step - loss: 0.6180 - acc: 0.8124 - gini_normalized: nan - val_loss: 0.6562 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 14/150\n",
      "2500/2500 [==============================] - 0s 48us/step - loss: 0.6059 - acc: 0.8160 - gini_normalized: nan - val_loss: 0.6374 - val_acc: 0.7980 - val_gini_normalized: nan\n",
      "Epoch 15/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.5909 - acc: 0.8172 - gini_normalized: nan - val_loss: 0.6357 - val_acc: 0.7980 - val_gini_normalized: nan\n",
      "Epoch 16/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.5832 - acc: 0.8164 - gini_normalized: nan - val_loss: 0.6162 - val_acc: 0.8140 - val_gini_normalized: nan\n",
      "Epoch 17/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.5700 - acc: 0.8220 - gini_normalized: nan - val_loss: 0.6035 - val_acc: 0.8120 - val_gini_normalized: nan\n",
      "Epoch 18/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.5642 - acc: 0.8204 - gini_normalized: nan - val_loss: 0.6035 - val_acc: 0.8060 - val_gini_normalized: nan\n",
      "Epoch 19/150\n",
      "2500/2500 [==============================] - 0s 42us/step - loss: 0.5559 - acc: 0.8200 - gini_normalized: nan - val_loss: 0.5909 - val_acc: 0.8080 - val_gini_normalized: nan\n",
      "Epoch 20/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.5494 - acc: 0.8260 - gini_normalized: nan - val_loss: 0.5811 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 21/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.5426 - acc: 0.8256 - gini_normalized: nan - val_loss: 0.5761 - val_acc: 0.8180 - val_gini_normalized: nan\n",
      "Epoch 22/150\n",
      "2500/2500 [==============================] - 0s 44us/step - loss: 0.5331 - acc: 0.8328 - gini_normalized: nan - val_loss: 0.5694 - val_acc: 0.8140 - val_gini_normalized: nan\n",
      "Epoch 23/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.5283 - acc: 0.8280 - gini_normalized: nan - val_loss: 0.5681 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 24/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.5239 - acc: 0.8348 - gini_normalized: nan - val_loss: 0.5577 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 25/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.5164 - acc: 0.8368 - gini_normalized: nan - val_loss: 0.5526 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 26/150\n",
      "2500/2500 [==============================] - 0s 53us/step - loss: 0.5098 - acc: 0.8304 - gini_normalized: nan - val_loss: 0.5508 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 27/150\n",
      "2500/2500 [==============================] - 0s 46us/step - loss: 0.5037 - acc: 0.8364 - gini_normalized: nan - val_loss: 0.5433 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 28/150\n",
      "2500/2500 [==============================] - 0s 51us/step - loss: 0.5054 - acc: 0.8356 - gini_normalized: nan - val_loss: 0.5389 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 29/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.4978 - acc: 0.8392 - gini_normalized: nan - val_loss: 0.5422 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 30/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.4907 - acc: 0.8380 - gini_normalized: nan - val_loss: 0.5405 - val_acc: 0.8200 - val_gini_normalized: nan\n",
      "Epoch 31/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.4901 - acc: 0.8416 - gini_normalized: nan - val_loss: 0.5223 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 32/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.4826 - acc: 0.8440 - gini_normalized: nan - val_loss: 0.5158 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 33/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.4827 - acc: 0.8460 - gini_normalized: nan - val_loss: 0.5138 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 34/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.4710 - acc: 0.8448 - gini_normalized: nan - val_loss: 0.5072 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 35/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.4674 - acc: 0.8496 - gini_normalized: nan - val_loss: 0.5072 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 36/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.4630 - acc: 0.8496 - gini_normalized: nan - val_loss: 0.5026 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 37/150\n",
      "2500/2500 [==============================] - 0s 44us/step - loss: 0.4616 - acc: 0.8460 - gini_normalized: nan - val_loss: 0.5011 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 38/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.4562 - acc: 0.8540 - gini_normalized: nan - val_loss: 0.4943 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 39/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.4571 - acc: 0.8500 - gini_normalized: nan - val_loss: 0.5000 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 40/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.4551 - acc: 0.8524 - gini_normalized: nan - val_loss: 0.4896 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 41/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.4498 - acc: 0.8544 - gini_normalized: nan - val_loss: 0.4847 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 42/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.4492 - acc: 0.8512 - gini_normalized: nan - val_loss: 0.4802 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 43/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.4432 - acc: 0.8564 - gini_normalized: nan - val_loss: 0.4728 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 44/150\n",
      "2500/2500 [==============================] - 0s 52us/step - loss: 0.4430 - acc: 0.8600 - gini_normalized: nan - val_loss: 0.4683 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 45/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.4410 - acc: 0.8560 - gini_normalized: nan - val_loss: 0.4720 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 46/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.4351 - acc: 0.8564 - gini_normalized: nan - val_loss: 0.4742 - val_acc: 0.8460 - val_gini_normalized: nan\n",
      "Epoch 47/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.4297 - acc: 0.8568 - gini_normalized: nan - val_loss: 0.4578 - val_acc: 0.8660 - val_gini_normalized: nan\n",
      "Epoch 48/150\n",
      "2500/2500 [==============================] - 0s 51us/step - loss: 0.4308 - acc: 0.8564 - gini_normalized: nan - val_loss: 0.4641 - val_acc: 0.8500 - val_gini_normalized: nan\n",
      "Epoch 49/150\n",
      "2500/2500 [==============================] - 0s 46us/step - loss: 0.4270 - acc: 0.8644 - gini_normalized: nan - val_loss: 0.4632 - val_acc: 0.8520 - val_gini_normalized: nan\n",
      "Epoch 50/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.4213 - acc: 0.8612 - gini_normalized: nan - val_loss: 0.4501 - val_acc: 0.8640 - val_gini_normalized: nan\n",
      "Epoch 51/150\n",
      "2500/2500 [==============================] - 0s 53us/step - loss: 0.4213 - acc: 0.8624 - gini_normalized: nan - val_loss: 0.4500 - val_acc: 0.8600 - val_gini_normalized: nan\n",
      "Epoch 52/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.4209 - acc: 0.8656 - gini_normalized: nan - val_loss: 0.4446 - val_acc: 0.8680 - val_gini_normalized: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/150\n",
      "2500/2500 [==============================] - 0s 46us/step - loss: 0.4125 - acc: 0.8644 - gini_normalized: nan - val_loss: 0.4437 - val_acc: 0.8680 - val_gini_normalized: nan\n",
      "Epoch 54/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.4168 - acc: 0.8704 - gini_normalized: nan - val_loss: 0.4425 - val_acc: 0.8680 - val_gini_normalized: nan\n",
      "Epoch 55/150\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.4108 - acc: 0.8652 - gini_normalized: nan - val_loss: 0.4280 - val_acc: 0.8720 - val_gini_normalized: nan\n",
      "Epoch 56/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.4057 - acc: 0.8672 - gini_normalized: nan - val_loss: 0.4319 - val_acc: 0.8700 - val_gini_normalized: nan\n",
      "Epoch 57/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.4047 - acc: 0.8716 - gini_normalized: nan - val_loss: 0.4369 - val_acc: 0.8680 - val_gini_normalized: nan\n",
      "Epoch 58/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.4048 - acc: 0.8692 - gini_normalized: nan - val_loss: 0.4256 - val_acc: 0.8660 - val_gini_normalized: nan\n",
      "Epoch 59/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.4001 - acc: 0.8704 - gini_normalized: nan - val_loss: 0.4249 - val_acc: 0.8820 - val_gini_normalized: nan\n",
      "Epoch 60/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.3991 - acc: 0.8740 - gini_normalized: nan - val_loss: 0.4229 - val_acc: 0.8760 - val_gini_normalized: nan\n",
      "Epoch 61/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3961 - acc: 0.8724 - gini_normalized: nan - val_loss: 0.4187 - val_acc: 0.8740 - val_gini_normalized: nan\n",
      "Epoch 62/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3923 - acc: 0.8748 - gini_normalized: nan - val_loss: 0.4225 - val_acc: 0.8820 - val_gini_normalized: nan\n",
      "Epoch 63/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.3929 - acc: 0.8776 - gini_normalized: nan - val_loss: 0.4138 - val_acc: 0.8820 - val_gini_normalized: nan\n",
      "Epoch 64/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.3856 - acc: 0.8740 - gini_normalized: nan - val_loss: 0.4123 - val_acc: 0.8740 - val_gini_normalized: nan\n",
      "Epoch 65/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.3883 - acc: 0.8740 - gini_normalized: nan - val_loss: 0.4024 - val_acc: 0.8800 - val_gini_normalized: nan\n",
      "Epoch 66/150\n",
      "2500/2500 [==============================] - 0s 45us/step - loss: 0.3801 - acc: 0.8764 - gini_normalized: nan - val_loss: 0.3975 - val_acc: 0.8880 - val_gini_normalized: nan\n",
      "Epoch 67/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.3829 - acc: 0.8780 - gini_normalized: nan - val_loss: 0.4023 - val_acc: 0.8940 - val_gini_normalized: nan\n",
      "Epoch 68/150\n",
      "2500/2500 [==============================] - 0s 51us/step - loss: 0.3839 - acc: 0.8772 - gini_normalized: nan - val_loss: 0.4021 - val_acc: 0.8960 - val_gini_normalized: nan\n",
      "Epoch 69/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3786 - acc: 0.8840 - gini_normalized: nan - val_loss: 0.3959 - val_acc: 0.8900 - val_gini_normalized: nan\n",
      "Epoch 70/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3748 - acc: 0.8768 - gini_normalized: nan - val_loss: 0.4005 - val_acc: 0.8920 - val_gini_normalized: nan\n",
      "Epoch 71/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3743 - acc: 0.8804 - gini_normalized: nan - val_loss: 0.3884 - val_acc: 0.8960 - val_gini_normalized: nan\n",
      "Epoch 72/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3748 - acc: 0.8800 - gini_normalized: nan - val_loss: 0.3911 - val_acc: 0.9020 - val_gini_normalized: nan\n",
      "Epoch 73/150\n",
      "2500/2500 [==============================] - 0s 44us/step - loss: 0.3754 - acc: 0.8828 - gini_normalized: nan - val_loss: 0.3920 - val_acc: 0.9020 - val_gini_normalized: nan\n",
      "Epoch 74/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.3687 - acc: 0.8816 - gini_normalized: nan - val_loss: 0.3817 - val_acc: 0.8940 - val_gini_normalized: nan\n",
      "Epoch 75/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3743 - acc: 0.8816 - gini_normalized: nan - val_loss: 0.3777 - val_acc: 0.8940 - val_gini_normalized: nan\n",
      "Epoch 76/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3628 - acc: 0.8840 - gini_normalized: nan - val_loss: 0.3713 - val_acc: 0.9020 - val_gini_normalized: nan\n",
      "Epoch 77/150\n",
      "2500/2500 [==============================] - 0s 48us/step - loss: 0.3618 - acc: 0.8864 - gini_normalized: nan - val_loss: 0.3782 - val_acc: 0.8980 - val_gini_normalized: nan\n",
      "Epoch 78/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3654 - acc: 0.8828 - gini_normalized: nan - val_loss: 0.3660 - val_acc: 0.9080 - val_gini_normalized: nan\n",
      "Epoch 79/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3605 - acc: 0.8844 - gini_normalized: nan - val_loss: 0.3726 - val_acc: 0.9000 - val_gini_normalized: nan\n",
      "Epoch 80/150\n",
      "2500/2500 [==============================] - 0s 44us/step - loss: 0.3541 - acc: 0.8852 - gini_normalized: nan - val_loss: 0.3639 - val_acc: 0.9100 - val_gini_normalized: nan\n",
      "Epoch 81/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3527 - acc: 0.8884 - gini_normalized: nan - val_loss: 0.3688 - val_acc: 0.9020 - val_gini_normalized: nan\n",
      "Epoch 82/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.3604 - acc: 0.8864 - gini_normalized: nan - val_loss: 0.3701 - val_acc: 0.9100 - val_gini_normalized: nan\n",
      "Epoch 83/150\n",
      "2500/2500 [==============================] - 0s 44us/step - loss: 0.3544 - acc: 0.8848 - gini_normalized: nan - val_loss: 0.3714 - val_acc: 0.9020 - val_gini_normalized: nan\n",
      "Epoch 84/150\n",
      "2500/2500 [==============================] - 0s 44us/step - loss: 0.3596 - acc: 0.8892 - gini_normalized: nan - val_loss: 0.3676 - val_acc: 0.9040 - val_gini_normalized: nan\n",
      "Epoch 85/150\n",
      "2500/2500 [==============================] - 0s 44us/step - loss: 0.3606 - acc: 0.8916 - gini_normalized: nan - val_loss: 0.3602 - val_acc: 0.9080 - val_gini_normalized: nan\n",
      "Epoch 86/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.3458 - acc: 0.8876 - gini_normalized: nan - val_loss: 0.3505 - val_acc: 0.9160 - val_gini_normalized: nan\n",
      "Epoch 87/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.3688 - acc: 0.8876 - gini_normalized: nan - val_loss: 0.3596 - val_acc: 0.9080 - val_gini_normalized: nan\n",
      "Epoch 88/150\n",
      "2500/2500 [==============================] - 0s 46us/step - loss: 0.3441 - acc: 0.8888 - gini_normalized: nan - val_loss: 0.3715 - val_acc: 0.9040 - val_gini_normalized: nan\n",
      "Epoch 89/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3488 - acc: 0.8864 - gini_normalized: nan - val_loss: 0.3652 - val_acc: 0.9080 - val_gini_normalized: nan\n",
      "Epoch 90/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.3470 - acc: 0.8884 - gini_normalized: nan - val_loss: 0.3473 - val_acc: 0.9080 - val_gini_normalized: nan\n",
      "Epoch 91/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3512 - acc: 0.8892 - gini_normalized: nan - val_loss: 0.3666 - val_acc: 0.9100 - val_gini_normalized: nan\n",
      "Epoch 92/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.3476 - acc: 0.8952 - gini_normalized: nan - val_loss: 0.3478 - val_acc: 0.9080 - val_gini_normalized: nan\n",
      "Epoch 93/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3418 - acc: 0.8888 - gini_normalized: nan - val_loss: 0.3617 - val_acc: 0.9080 - val_gini_normalized: nan\n",
      "Epoch 94/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.3431 - acc: 0.8948 - gini_normalized: nan - val_loss: 0.3534 - val_acc: 0.9040 - val_gini_normalized: nan\n",
      "Epoch 95/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.3459 - acc: 0.8904 - gini_normalized: nan - val_loss: 0.3394 - val_acc: 0.9100 - val_gini_normalized: nan\n",
      "Epoch 96/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3370 - acc: 0.8896 - gini_normalized: nan - val_loss: 0.3516 - val_acc: 0.9100 - val_gini_normalized: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3360 - acc: 0.8944 - gini_normalized: nan - val_loss: 0.3459 - val_acc: 0.9060 - val_gini_normalized: nan\n",
      "Epoch 98/150\n",
      "2500/2500 [==============================] - 0s 48us/step - loss: 0.3331 - acc: 0.8912 - gini_normalized: nan - val_loss: 0.3476 - val_acc: 0.9120 - val_gini_normalized: nan\n",
      "Epoch 99/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3411 - acc: 0.8920 - gini_normalized: nan - val_loss: 0.3291 - val_acc: 0.9160 - val_gini_normalized: nan\n",
      "Epoch 100/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.3278 - acc: 0.8972 - gini_normalized: nan - val_loss: 0.3513 - val_acc: 0.9100 - val_gini_normalized: nan\n",
      "Epoch 101/150\n",
      "2500/2500 [==============================] - 0s 44us/step - loss: 0.3428 - acc: 0.8892 - gini_normalized: nan - val_loss: 0.3335 - val_acc: 0.9160 - val_gini_normalized: nan\n",
      "Epoch 102/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.3327 - acc: 0.8960 - gini_normalized: nan - val_loss: 0.3299 - val_acc: 0.9140 - val_gini_normalized: nan\n",
      "Epoch 103/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.3427 - acc: 0.8944 - gini_normalized: nan - val_loss: 0.3262 - val_acc: 0.9200 - val_gini_normalized: nan\n",
      "Epoch 104/150\n",
      "2500/2500 [==============================] - 0s 44us/step - loss: 0.3414 - acc: 0.8916 - gini_normalized: nan - val_loss: 0.3375 - val_acc: 0.9080 - val_gini_normalized: nan\n",
      "Epoch 105/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3300 - acc: 0.8924 - gini_normalized: nan - val_loss: 0.3308 - val_acc: 0.9220 - val_gini_normalized: nan\n",
      "Epoch 106/150\n",
      "2500/2500 [==============================] - 0s 52us/step - loss: 0.3323 - acc: 0.8948 - gini_normalized: nan - val_loss: 0.3279 - val_acc: 0.9120 - val_gini_normalized: nan\n",
      "Epoch 107/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.3291 - acc: 0.8928 - gini_normalized: nan - val_loss: 0.3262 - val_acc: 0.9120 - val_gini_normalized: nan\n",
      "Epoch 108/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3291 - acc: 0.8948 - gini_normalized: nan - val_loss: 0.3380 - val_acc: 0.9120 - val_gini_normalized: nan\n",
      "Epoch 109/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3303 - acc: 0.8916 - gini_normalized: nan - val_loss: 0.3261 - val_acc: 0.9140 - val_gini_normalized: nan\n",
      "Epoch 110/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3350 - acc: 0.8956 - gini_normalized: nan - val_loss: 0.3277 - val_acc: 0.9140 - val_gini_normalized: nan\n",
      "Epoch 111/150\n",
      "2500/2500 [==============================] - 0s 44us/step - loss: 0.3314 - acc: 0.8940 - gini_normalized: nan - val_loss: 0.3244 - val_acc: 0.9220 - val_gini_normalized: nan\n",
      "Epoch 112/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3251 - acc: 0.8956 - gini_normalized: nan - val_loss: 0.3399 - val_acc: 0.9200 - val_gini_normalized: nan\n",
      "Epoch 113/150\n",
      "2500/2500 [==============================] - 0s 43us/step - loss: 0.3395 - acc: 0.8948 - gini_normalized: nan - val_loss: 0.3319 - val_acc: 0.9180 - val_gini_normalized: nan\n",
      "Epoch 114/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.3339 - acc: 0.8964 - gini_normalized: nan - val_loss: 0.3273 - val_acc: 0.9200 - val_gini_normalized: nan\n",
      "Epoch 115/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3242 - acc: 0.8936 - gini_normalized: nan - val_loss: 0.3267 - val_acc: 0.9220 - val_gini_normalized: nan\n",
      "Epoch 116/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.3202 - acc: 0.8932 - gini_normalized: nan - val_loss: 0.3241 - val_acc: 0.9280 - val_gini_normalized: nan\n",
      "Epoch 117/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3220 - acc: 0.8956 - gini_normalized: nan - val_loss: 0.3274 - val_acc: 0.9120 - val_gini_normalized: nan\n",
      "Epoch 118/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.3251 - acc: 0.8976 - gini_normalized: nan - val_loss: 0.3190 - val_acc: 0.9220 - val_gini_normalized: nan\n",
      "Epoch 119/150\n",
      "2500/2500 [==============================] - 0s 45us/step - loss: 0.3264 - acc: 0.8984 - gini_normalized: nan - val_loss: 0.3199 - val_acc: 0.9260 - val_gini_normalized: nan\n",
      "Epoch 120/150\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.3144 - acc: 0.8992 - gini_normalized: nan - val_loss: 0.3191 - val_acc: 0.9140 - val_gini_normalized: nan\n",
      "Epoch 121/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3132 - acc: 0.8996 - gini_normalized: nan - val_loss: 0.3281 - val_acc: 0.9180 - val_gini_normalized: nan\n",
      "Epoch 122/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.3160 - acc: 0.8980 - gini_normalized: nan - val_loss: 0.3270 - val_acc: 0.9140 - val_gini_normalized: nan\n",
      "Epoch 123/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3165 - acc: 0.8968 - gini_normalized: nan - val_loss: 0.3065 - val_acc: 0.9280 - val_gini_normalized: nan\n",
      "Epoch 124/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.3365 - acc: 0.8968 - gini_normalized: nan - val_loss: 0.3162 - val_acc: 0.9180 - val_gini_normalized: nan\n",
      "Epoch 125/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3059 - acc: 0.8980 - gini_normalized: nan - val_loss: 0.3146 - val_acc: 0.9240 - val_gini_normalized: nan\n",
      "Epoch 126/150\n",
      "2500/2500 [==============================] - 0s 49us/step - loss: 0.3160 - acc: 0.8996 - gini_normalized: nan - val_loss: 0.3223 - val_acc: 0.9160 - val_gini_normalized: nan\n",
      "Epoch 127/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3164 - acc: 0.8980 - gini_normalized: nan - val_loss: 0.3355 - val_acc: 0.9160 - val_gini_normalized: nan\n",
      "Epoch 128/150\n",
      "2500/2500 [==============================] - 0s 44us/step - loss: 0.3062 - acc: 0.8972 - gini_normalized: nan - val_loss: 0.3122 - val_acc: 0.9280 - val_gini_normalized: nan\n",
      "Epoch 129/150\n",
      "2500/2500 [==============================] - 0s 44us/step - loss: 0.3131 - acc: 0.9004 - gini_normalized: nan - val_loss: 0.3188 - val_acc: 0.9180 - val_gini_normalized: nan\n",
      "Epoch 130/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3111 - acc: 0.9016 - gini_normalized: nan - val_loss: 0.3137 - val_acc: 0.9220 - val_gini_normalized: nan\n",
      "Epoch 131/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3112 - acc: 0.8972 - gini_normalized: nan - val_loss: 0.3157 - val_acc: 0.9280 - val_gini_normalized: nan\n",
      "Epoch 132/150\n",
      "2500/2500 [==============================] - 0s 54us/step - loss: 0.3138 - acc: 0.9008 - gini_normalized: nan - val_loss: 0.3384 - val_acc: 0.9220 - val_gini_normalized: nan\n",
      "Epoch 133/150\n",
      "2500/2500 [==============================] - 0s 44us/step - loss: 0.3154 - acc: 0.8964 - gini_normalized: nan - val_loss: 0.3117 - val_acc: 0.9220 - val_gini_normalized: nan\n",
      "Epoch 134/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.3042 - acc: 0.8980 - gini_normalized: nan - val_loss: 0.3248 - val_acc: 0.9260 - val_gini_normalized: nan\n",
      "Epoch 135/150\n",
      "2500/2500 [==============================] - 0s 44us/step - loss: 0.3203 - acc: 0.9024 - gini_normalized: nan - val_loss: 0.3231 - val_acc: 0.9080 - val_gini_normalized: nan\n",
      "Epoch 136/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3143 - acc: 0.8988 - gini_normalized: nan - val_loss: 0.3144 - val_acc: 0.9220 - val_gini_normalized: nan\n",
      "Epoch 137/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3033 - acc: 0.9012 - gini_normalized: nan - val_loss: 0.3153 - val_acc: 0.9260 - val_gini_normalized: nan\n",
      "Epoch 138/150\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.3022 - acc: 0.8972 - gini_normalized: nan - val_loss: 0.3129 - val_acc: 0.9220 - val_gini_normalized: nan\n",
      "Epoch 139/150\n",
      "2500/2500 [==============================] - 0s 51us/step - loss: 0.3001 - acc: 0.9020 - gini_normalized: nan - val_loss: 0.3090 - val_acc: 0.9200 - val_gini_normalized: nan\n",
      "Epoch 140/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 51us/step - loss: 0.3088 - acc: 0.8992 - gini_normalized: nan - val_loss: 0.3151 - val_acc: 0.9220 - val_gini_normalized: nan\n",
      "Epoch 141/150\n",
      "2500/2500 [==============================] - 0s 46us/step - loss: 0.3034 - acc: 0.8988 - gini_normalized: nan - val_loss: 0.3086 - val_acc: 0.9240 - val_gini_normalized: nan\n",
      "Epoch 142/150\n",
      "2500/2500 [==============================] - 0s 55us/step - loss: 0.3144 - acc: 0.9004 - gini_normalized: nan - val_loss: 0.3145 - val_acc: 0.9220 - val_gini_normalized: nan\n",
      "Epoch 143/150\n",
      "2500/2500 [==============================] - 0s 44us/step - loss: 0.3148 - acc: 0.9004 - gini_normalized: nan - val_loss: 0.2986 - val_acc: 0.9220 - val_gini_normalized: nan\n",
      "Epoch 144/150\n",
      "2500/2500 [==============================] - 0s 44us/step - loss: 0.2987 - acc: 0.9012 - gini_normalized: nan - val_loss: 0.3005 - val_acc: 0.9340 - val_gini_normalized: nan\n",
      "Epoch 145/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3085 - acc: 0.9000 - gini_normalized: nan - val_loss: 0.3116 - val_acc: 0.9220 - val_gini_normalized: nan\n",
      "Epoch 146/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.3154 - acc: 0.8992 - gini_normalized: nan - val_loss: 0.3005 - val_acc: 0.9340 - val_gini_normalized: nan\n",
      "Epoch 147/150\n",
      "2500/2500 [==============================] - 0s 52us/step - loss: 0.2986 - acc: 0.9000 - gini_normalized: nan - val_loss: 0.3214 - val_acc: 0.9280 - val_gini_normalized: nan\n",
      "Epoch 148/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.2966 - acc: 0.9024 - gini_normalized: nan - val_loss: 0.3133 - val_acc: 0.9220 - val_gini_normalized: nan\n",
      "Epoch 149/150\n",
      "2500/2500 [==============================] - 0s 46us/step - loss: 0.3070 - acc: 0.9012 - gini_normalized: nan - val_loss: 0.3017 - val_acc: 0.9280 - val_gini_normalized: nan\n",
      "Epoch 150/150\n",
      "2500/2500 [==============================] - 0s 50us/step - loss: 0.2900 - acc: 0.9012 - gini_normalized: nan - val_loss: 0.3049 - val_acc: 0.9320 - val_gini_normalized: nan\n",
      "500/500 [==============================] - 0s 31us/step\n"
     ]
    }
   ],
   "source": [
    "###########################################################################################################################\n",
    "### narrow models, 1 layer\n",
    "###########################################################################################################################\n",
    "## original true covariates\n",
    "model_nl_narrow1 = Sequential()\n",
    "model_nl_narrow1.add(Dense(20, input_dim=7, kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model_nl_narrow1.add(Dense(1, activation='sigmoid'))\n",
    "model_nl_narrow1.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',gini_normalized])\n",
    "trace_nl_narrow1 = model_nl_narrow1.fit(x_nonlinear_true[0:2500,0:7], y_nonlinear[0:2500],epochs=150,batch_size=64, \\\n",
    "                    validation_data=(x_nonlinear_true[2500:3000,0:7], y_nonlinear[2500:3000]))\n",
    "score_nl_narrow1 = model_nl_narrow1.evaluate(x_nonlinear_true[2500:3000,0:7], y_nonlinear[2500:3000], batch_size=64)\n",
    "\n",
    "## all original covariates: 0:7,15:20\n",
    "model_nl_narrow5 = Sequential()\n",
    "model_nl_narrow5.add(Dense(20, input_dim=12, kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model_nl_narrow5.add(Dense(1, activation='sigmoid'))\n",
    "model_nl_narrow5.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',gini_normalized])\n",
    "trace_nl_narrow5 = model_nl_narrow5.fit(np.concatenate((x_nonlinear_true[0:2500,0:7],x_nonlinear_true[0:2500,15:20]), axis=1), y_nonlinear[0:2500],epochs=150,batch_size=64, \\\n",
    "                    validation_data=(np.concatenate((x_nonlinear_true[2500:3000,0:7],x_nonlinear_true[2500:3000,15:20]), axis=1), y_nonlinear[2500:3000]))\n",
    "score_nl_narrow5 = model_nl_narrow5.evaluate(np.concatenate((x_nonlinear_true[2500:3000,0:7],x_nonlinear_true[2500:3000,15:20]), axis=1), y_nonlinear[2500:3000], batch_size=64)\n",
    "\n",
    "## true features used to create nonl_narrowinear relationships\n",
    "model_nl_narrow2 = Sequential()\n",
    "model_nl_narrow2.add(Dense(20, input_dim=np.shape(x_nonlinear_true)[1], kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model_nl_narrow2.add(Dense(1, activation='sigmoid'))\n",
    "model_nl_narrow2.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',gini_normalized])\n",
    "trace_nl_narrow2 = model_nl_narrow2.fit(x_nonlinear_true[0:2500,:], y_nonlinear[0:2500],epochs=150,batch_size=64, \\\n",
    "                    validation_data=(x_nonlinear_true[2500:3000,:], y_nonlinear[2500:3000]))\n",
    "score_nl_narrow2 = model_nl_narrow2.evaluate(x_nonlinear_true[2500:3000,:], y_nonlinear[2500:3000], batch_size=64)\n",
    "\n",
    "## all extra features\n",
    "model_nl_narrow3 = Sequential()\n",
    "model_nl_narrow3.add(Dense(20, input_dim=np.shape(x_nonlinear_extra)[1], kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model_nl_narrow3.add(Dense(1, activation='sigmoid'))\n",
    "model_nl_narrow3.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',gini_normalized])\n",
    "trace_nl_narrow3 = model_nl_narrow3.fit(x_nonlinear_extra[0:2500,:], y_nonlinear[0:2500],epochs=150,batch_size=64, \\\n",
    "                    validation_data=(x_nonlinear_extra[2500:3000,:], y_nonlinear[2500:3000]))\n",
    "score_nl_narrow3 = model_nl_narrow3.evaluate(x_nonlinear_extra[2500:3000,:], y_nonlinear[2500:3000], batch_size=64)\n",
    "\n",
    "## selected features\n",
    "model_nl_narrow4 = Sequential()\n",
    "model_nl_narrow4.add(Dense(20, input_dim=len(selected_features_nl), kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model_nl_narrow4.add(Dense(1, activation='sigmoid'))\n",
    "model_nl_narrow4.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',gini_normalized])\n",
    "trace_nl_narrow4 = model_nl_narrow4.fit(x_nonlinear_extra[0:2500,selected_features_nl], y_nonlinear[0:2500],epochs=150,batch_size=64, \\\n",
    "                    validation_data=(x_nonlinear_extra[2500:3000,selected_features_nl], y_nonlinear[2500:3000]))\n",
    "score_nl_narrow4 = model_nl_narrow4.evaluate(x_nonlinear_extra[2500:3000,selected_features_nl], y_nonlinear[2500:3000], batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWkAAAEOCAYAAABLiuasAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21ecb4a7390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10*.55,7*.55))\n",
    "plt.title('Hidden layer: (20)')\n",
    "#plt.plot(trace_nl_narrow1.history['val_acc'],label='true features', color=\"green\")\n",
    "plt.plot(trace_nl_narrow2.history['val_acc'],label='original true covariates', color=\"red\")\n",
    "plt.plot(trace_nl_narrow3.history['val_acc'],label='all engineered features', color=\"orange\")\n",
    "plt.plot(trace_nl_narrow4.history['val_acc'],label='feature selection', color=\"purple\")\n",
    "plt.plot(trace_nl_narrow5.history['val_acc'],label='all original covariates', color=\"blue\")\n",
    "plt.legend(loc=4)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.8553 - acc: 0.6924 - gini_normalized: nan - val_loss: 0.7969 - val_acc: 0.7160 - val_gini_normalized: nan\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.7506 - acc: 0.7448 - gini_normalized: nan - val_loss: 0.7190 - val_acc: 0.7340 - val_gini_normalized: nan\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.6838 - acc: 0.7560 - gini_normalized: nan - val_loss: 0.6656 - val_acc: 0.7500 - val_gini_normalized: nan\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 0s 87us/step - loss: 0.6374 - acc: 0.7676 - gini_normalized: nan - val_loss: 0.6269 - val_acc: 0.7480 - val_gini_normalized: nan\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.6071 - acc: 0.7668 - gini_normalized: nan - val_loss: 0.6036 - val_acc: 0.7640 - val_gini_normalized: nan\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 0s 90us/step - loss: 0.5876 - acc: 0.7840 - gini_normalized: nan - val_loss: 0.5866 - val_acc: 0.7780 - val_gini_normalized: nan\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.5728 - acc: 0.7856 - gini_normalized: nan - val_loss: 0.5742 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.5622 - acc: 0.7948 - gini_normalized: nan - val_loss: 0.5644 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.5528 - acc: 0.7956 - gini_normalized: nan - val_loss: 0.5578 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.5448 - acc: 0.7968 - gini_normalized: nan - val_loss: 0.5487 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.5370 - acc: 0.7984 - gini_normalized: nan - val_loss: 0.5445 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.5301 - acc: 0.8028 - gini_normalized: nan - val_loss: 0.5359 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.5240 - acc: 0.8032 - gini_normalized: nan - val_loss: 0.5322 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.5192 - acc: 0.8076 - gini_normalized: nan - val_loss: 0.5261 - val_acc: 0.7800 - val_gini_normalized: nan\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.5139 - acc: 0.8076 - gini_normalized: nan - val_loss: 0.5248 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 0s 85us/step - loss: 0.5100 - acc: 0.8032 - gini_normalized: nan - val_loss: 0.5180 - val_acc: 0.7780 - val_gini_normalized: nan\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.5056 - acc: 0.8072 - gini_normalized: nan - val_loss: 0.5163 - val_acc: 0.7800 - val_gini_normalized: nan\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.5019 - acc: 0.8072 - gini_normalized: nan - val_loss: 0.5089 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4981 - acc: 0.8120 - gini_normalized: nan - val_loss: 0.5077 - val_acc: 0.7800 - val_gini_normalized: nan\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.4949 - acc: 0.8076 - gini_normalized: nan - val_loss: 0.5061 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.4925 - acc: 0.8068 - gini_normalized: nan - val_loss: 0.5053 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.4897 - acc: 0.8048 - gini_normalized: nan - val_loss: 0.5044 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.4867 - acc: 0.8132 - gini_normalized: nan - val_loss: 0.4991 - val_acc: 0.7980 - val_gini_normalized: nan\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.4847 - acc: 0.8132 - gini_normalized: nan - val_loss: 0.4986 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 0s 92us/step - loss: 0.4836 - acc: 0.8116 - gini_normalized: nan - val_loss: 0.4938 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 0s 99us/step - loss: 0.4811 - acc: 0.8128 - gini_normalized: nan - val_loss: 0.4960 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 0s 84us/step - loss: 0.4791 - acc: 0.8116 - gini_normalized: nan - val_loss: 0.4923 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4775 - acc: 0.8120 - gini_normalized: nan - val_loss: 0.4889 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4747 - acc: 0.8128 - gini_normalized: nan - val_loss: 0.4904 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 30/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4732 - acc: 0.8144 - gini_normalized: nan - val_loss: 0.4873 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 31/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4710 - acc: 0.8120 - gini_normalized: nan - val_loss: 0.4883 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.4694 - acc: 0.8164 - gini_normalized: nan - val_loss: 0.4835 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.4679 - acc: 0.8152 - gini_normalized: nan - val_loss: 0.4820 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4670 - acc: 0.8144 - gini_normalized: nan - val_loss: 0.4821 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 35/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4648 - acc: 0.8144 - gini_normalized: nan - val_loss: 0.4863 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 36/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4638 - acc: 0.8208 - gini_normalized: nan - val_loss: 0.4800 - val_acc: 0.8000 - val_gini_normalized: nan\n",
      "Epoch 37/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.4625 - acc: 0.8196 - gini_normalized: nan - val_loss: 0.4825 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 38/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4609 - acc: 0.8156 - gini_normalized: nan - val_loss: 0.4812 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 39/50\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4597 - acc: 0.8144 - gini_normalized: nan - val_loss: 0.4789 - val_acc: 0.7980 - val_gini_normalized: nan\n",
      "Epoch 40/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4598 - acc: 0.8164 - gini_normalized: nan - val_loss: 0.4772 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 41/50\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.4568 - acc: 0.8164 - gini_normalized: nan - val_loss: 0.4741 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 42/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4563 - acc: 0.8132 - gini_normalized: nan - val_loss: 0.4786 - val_acc: 0.8040 - val_gini_normalized: nan\n",
      "Epoch 43/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4551 - acc: 0.8204 - gini_normalized: nan - val_loss: 0.4742 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 44/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4532 - acc: 0.8232 - gini_normalized: nan - val_loss: 0.4750 - val_acc: 0.7760 - val_gini_normalized: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4528 - acc: 0.8228 - gini_normalized: nan - val_loss: 0.4762 - val_acc: 0.7940 - val_gini_normalized: nan\n",
      "Epoch 46/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4507 - acc: 0.8192 - gini_normalized: nan - val_loss: 0.4689 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 47/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4494 - acc: 0.8184 - gini_normalized: nan - val_loss: 0.4683 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 48/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.4496 - acc: 0.8204 - gini_normalized: nan - val_loss: 0.4686 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 49/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4478 - acc: 0.8212 - gini_normalized: nan - val_loss: 0.4654 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 50/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4464 - acc: 0.8220 - gini_normalized: nan - val_loss: 0.4682 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "500/500 [==============================] - 0s 42us/step\n",
      "Train on 2500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9922 - acc: 0.6284 - gini_normalized: nan - val_loss: 0.8959 - val_acc: 0.6960 - val_gini_normalized: nan\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.8346 - acc: 0.7244 - gini_normalized: nan - val_loss: 0.7824 - val_acc: 0.7080 - val_gini_normalized: nan\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.7345 - acc: 0.7372 - gini_normalized: nan - val_loss: 0.7026 - val_acc: 0.7200 - val_gini_normalized: nan\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.6682 - acc: 0.7472 - gini_normalized: nan - val_loss: 0.6521 - val_acc: 0.7380 - val_gini_normalized: nan\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.6262 - acc: 0.7612 - gini_normalized: nan - val_loss: 0.6196 - val_acc: 0.7700 - val_gini_normalized: nan\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.6005 - acc: 0.7736 - gini_normalized: nan - val_loss: 0.5997 - val_acc: 0.7620 - val_gini_normalized: nan\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.5825 - acc: 0.7756 - gini_normalized: nan - val_loss: 0.5822 - val_acc: 0.7680 - val_gini_normalized: nan\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.5688 - acc: 0.7812 - gini_normalized: nan - val_loss: 0.5727 - val_acc: 0.7680 - val_gini_normalized: nan\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.5583 - acc: 0.7836 - gini_normalized: nan - val_loss: 0.5624 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.5483 - acc: 0.8000 - gini_normalized: nan - val_loss: 0.5542 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.5408 - acc: 0.7988 - gini_normalized: nan - val_loss: 0.5491 - val_acc: 0.7740 - val_gini_normalized: nan\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.5344 - acc: 0.8020 - gini_normalized: nan - val_loss: 0.5425 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 0s 84us/step - loss: 0.5277 - acc: 0.8016 - gini_normalized: nan - val_loss: 0.5345 - val_acc: 0.7780 - val_gini_normalized: nan\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.5222 - acc: 0.8036 - gini_normalized: nan - val_loss: 0.5333 - val_acc: 0.7740 - val_gini_normalized: nan\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.5172 - acc: 0.7980 - gini_normalized: nan - val_loss: 0.5314 - val_acc: 0.8000 - val_gini_normalized: nan\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.5126 - acc: 0.8012 - gini_normalized: nan - val_loss: 0.5250 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.5084 - acc: 0.8076 - gini_normalized: nan - val_loss: 0.5228 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.5052 - acc: 0.8040 - gini_normalized: nan - val_loss: 0.5190 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.5003 - acc: 0.8040 - gini_normalized: nan - val_loss: 0.5127 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4970 - acc: 0.8036 - gini_normalized: nan - val_loss: 0.5216 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4959 - acc: 0.8080 - gini_normalized: nan - val_loss: 0.5100 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4922 - acc: 0.8060 - gini_normalized: nan - val_loss: 0.5130 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4895 - acc: 0.8048 - gini_normalized: nan - val_loss: 0.5171 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4870 - acc: 0.8092 - gini_normalized: nan - val_loss: 0.5035 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.4852 - acc: 0.8116 - gini_normalized: nan - val_loss: 0.5038 - val_acc: 0.8060 - val_gini_normalized: nan\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4826 - acc: 0.8128 - gini_normalized: nan - val_loss: 0.5020 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4801 - acc: 0.8068 - gini_normalized: nan - val_loss: 0.5039 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4786 - acc: 0.8104 - gini_normalized: nan - val_loss: 0.5055 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.4766 - acc: 0.8160 - gini_normalized: nan - val_loss: 0.5010 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 30/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4751 - acc: 0.8104 - gini_normalized: nan - val_loss: 0.5026 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 31/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4726 - acc: 0.8100 - gini_normalized: nan - val_loss: 0.4959 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4711 - acc: 0.8144 - gini_normalized: nan - val_loss: 0.4951 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4698 - acc: 0.8148 - gini_normalized: nan - val_loss: 0.4873 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 0s 79us/step - loss: 0.4678 - acc: 0.8148 - gini_normalized: nan - val_loss: 0.4938 - val_acc: 0.8040 - val_gini_normalized: nan\n",
      "Epoch 35/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.4671 - acc: 0.8088 - gini_normalized: nan - val_loss: 0.4909 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 36/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4643 - acc: 0.8112 - gini_normalized: nan - val_loss: 0.4908 - val_acc: 0.7880 - val_gini_normalized: nan\n",
      "Epoch 37/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4640 - acc: 0.8124 - gini_normalized: nan - val_loss: 0.4837 - val_acc: 0.7900 - val_gini_normalized: nan\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4626 - acc: 0.8132 - gini_normalized: nan - val_loss: 0.4900 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "Epoch 39/50\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.4616 - acc: 0.8140 - gini_normalized: nan - val_loss: 0.4858 - val_acc: 0.7860 - val_gini_normalized: nan\n",
      "Epoch 40/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.4602 - acc: 0.8132 - gini_normalized: nan - val_loss: 0.4868 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 41/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4589 - acc: 0.8156 - gini_normalized: nan - val_loss: 0.4893 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 42/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.4574 - acc: 0.8152 - gini_normalized: nan - val_loss: 0.4858 - val_acc: 0.8000 - val_gini_normalized: nan\n",
      "Epoch 43/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4559 - acc: 0.8208 - gini_normalized: nan - val_loss: 0.4801 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 44/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.4557 - acc: 0.8100 - gini_normalized: nan - val_loss: 0.4829 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 45/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4534 - acc: 0.8124 - gini_normalized: nan - val_loss: 0.4930 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 46/50\n",
      "2500/2500 [==============================] - 0s 78us/step - loss: 0.4537 - acc: 0.8140 - gini_normalized: nan - val_loss: 0.4796 - val_acc: 0.7980 - val_gini_normalized: nan\n",
      "Epoch 47/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4520 - acc: 0.8148 - gini_normalized: nan - val_loss: 0.4890 - val_acc: 0.7980 - val_gini_normalized: nan\n",
      "Epoch 48/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.4499 - acc: 0.8160 - gini_normalized: nan - val_loss: 0.4819 - val_acc: 0.7840 - val_gini_normalized: nan\n",
      "Epoch 49/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4502 - acc: 0.8140 - gini_normalized: nan - val_loss: 0.4784 - val_acc: 0.7920 - val_gini_normalized: nan\n",
      "Epoch 50/50\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.4497 - acc: 0.8140 - gini_normalized: nan - val_loss: 0.4761 - val_acc: 0.7960 - val_gini_normalized: nan\n",
      "500/500 [==============================] - 0s 36us/step\n",
      "Train on 2500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.2687 - acc: 0.6364 - gini_normalized: nan - val_loss: 1.0326 - val_acc: 0.7700 - val_gini_normalized: nan\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.9351 - acc: 0.7948 - gini_normalized: nan - val_loss: 0.8592 - val_acc: 0.8080 - val_gini_normalized: nan\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.7779 - acc: 0.8332 - gini_normalized: nan - val_loss: 0.7356 - val_acc: 0.8280 - val_gini_normalized: nan\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.6719 - acc: 0.8400 - gini_normalized: nan - val_loss: 0.6388 - val_acc: 0.8160 - val_gini_normalized: nan\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.6008 - acc: 0.8452 - gini_normalized: nan - val_loss: 0.6201 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.5599 - acc: 0.8520 - gini_normalized: nan - val_loss: 0.5679 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.5445 - acc: 0.8560 - gini_normalized: nan - val_loss: 0.5473 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.5133 - acc: 0.8620 - gini_normalized: nan - val_loss: 0.5771 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.5066 - acc: 0.8656 - gini_normalized: nan - val_loss: 0.5245 - val_acc: 0.8540 - val_gini_normalized: nan\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4855 - acc: 0.8692 - gini_normalized: nan - val_loss: 0.5090 - val_acc: 0.8580 - val_gini_normalized: nan\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4708 - acc: 0.8716 - gini_normalized: nan - val_loss: 0.4896 - val_acc: 0.8680 - val_gini_normalized: nan\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4748 - acc: 0.8676 - gini_normalized: nan - val_loss: 0.4889 - val_acc: 0.8600 - val_gini_normalized: nan\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 0s 57us/step - loss: 0.4565 - acc: 0.8760 - gini_normalized: nan - val_loss: 0.4608 - val_acc: 0.8700 - val_gini_normalized: nan\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.4500 - acc: 0.8752 - gini_normalized: nan - val_loss: 0.4610 - val_acc: 0.8760 - val_gini_normalized: nan\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 0s 58us/step - loss: 0.4422 - acc: 0.8812 - gini_normalized: nan - val_loss: 0.4518 - val_acc: 0.8740 - val_gini_normalized: nan\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.4305 - acc: 0.8796 - gini_normalized: nan - val_loss: 0.4475 - val_acc: 0.8680 - val_gini_normalized: nan\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 0s 81us/step - loss: 0.4224 - acc: 0.8820 - gini_normalized: nan - val_loss: 0.4171 - val_acc: 0.8780 - val_gini_normalized: nan\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4126 - acc: 0.8872 - gini_normalized: nan - val_loss: 0.4574 - val_acc: 0.8900 - val_gini_normalized: nan\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.4067 - acc: 0.8916 - gini_normalized: nan - val_loss: 0.4059 - val_acc: 0.8860 - val_gini_normalized: nan\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.3912 - acc: 0.8872 - gini_normalized: nan - val_loss: 0.4097 - val_acc: 0.8860 - val_gini_normalized: nan\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.3847 - acc: 0.8888 - gini_normalized: nan - val_loss: 0.4016 - val_acc: 0.9000 - val_gini_normalized: nan\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.3899 - acc: 0.8924 - gini_normalized: nan - val_loss: 0.3952 - val_acc: 0.9060 - val_gini_normalized: nan\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.3843 - acc: 0.8980 - gini_normalized: nan - val_loss: 0.3737 - val_acc: 0.9180 - val_gini_normalized: nan\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.3729 - acc: 0.9004 - gini_normalized: nan - val_loss: 0.3902 - val_acc: 0.8980 - val_gini_normalized: nan\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.3733 - acc: 0.8980 - gini_normalized: nan - val_loss: 0.3836 - val_acc: 0.9060 - val_gini_normalized: nan\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.3690 - acc: 0.8956 - gini_normalized: nan - val_loss: 0.3935 - val_acc: 0.9140 - val_gini_normalized: nan\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.3630 - acc: 0.8984 - gini_normalized: nan - val_loss: 0.3607 - val_acc: 0.9060 - val_gini_normalized: nan\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.3587 - acc: 0.8972 - gini_normalized: nan - val_loss: 0.3601 - val_acc: 0.9060 - val_gini_normalized: nan\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 0s 60us/step - loss: 0.3485 - acc: 0.9076 - gini_normalized: nan - val_loss: 0.3744 - val_acc: 0.9260 - val_gini_normalized: nan\n",
      "Epoch 30/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.3440 - acc: 0.9092 - gini_normalized: nan - val_loss: 0.3692 - val_acc: 0.9260 - val_gini_normalized: nan\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.3391 - acc: 0.9080 - gini_normalized: nan - val_loss: 0.3718 - val_acc: 0.9260 - val_gini_normalized: nan\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.3349 - acc: 0.9072 - gini_normalized: nan - val_loss: 0.3368 - val_acc: 0.9280 - val_gini_normalized: nan\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.3425 - acc: 0.9072 - gini_normalized: nan - val_loss: 0.3629 - val_acc: 0.9140 - val_gini_normalized: nan\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3314 - acc: 0.9108 - gini_normalized: nan - val_loss: 0.3253 - val_acc: 0.9300 - val_gini_normalized: nan\n",
      "Epoch 35/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.3305 - acc: 0.9124 - gini_normalized: nan - val_loss: 0.3337 - val_acc: 0.9240 - val_gini_normalized: nan\n",
      "Epoch 36/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.3302 - acc: 0.9108 - gini_normalized: nan - val_loss: 0.3430 - val_acc: 0.9260 - val_gini_normalized: nan\n",
      "Epoch 37/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.3244 - acc: 0.9124 - gini_normalized: nan - val_loss: 0.3536 - val_acc: 0.9260 - val_gini_normalized: nan\n",
      "Epoch 38/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.3230 - acc: 0.9136 - gini_normalized: nan - val_loss: 0.3346 - val_acc: 0.9300 - val_gini_normalized: nan\n",
      "Epoch 39/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.3101 - acc: 0.9172 - gini_normalized: nan - val_loss: 0.3516 - val_acc: 0.9280 - val_gini_normalized: nan\n",
      "Epoch 40/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 0.3103 - acc: 0.9156 - gini_normalized: nan - val_loss: 0.3161 - val_acc: 0.9260 - val_gini_normalized: nan\n",
      "Epoch 41/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.3226 - acc: 0.9104 - gini_normalized: nan - val_loss: 0.3720 - val_acc: 0.9180 - val_gini_normalized: nan\n",
      "Epoch 42/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.3094 - acc: 0.9172 - gini_normalized: nan - val_loss: 0.3050 - val_acc: 0.9380 - val_gini_normalized: nan\n",
      "Epoch 43/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.3091 - acc: 0.9196 - gini_normalized: nan - val_loss: 0.3117 - val_acc: 0.9360 - val_gini_normalized: nan\n",
      "Epoch 44/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.2999 - acc: 0.9192 - gini_normalized: nan - val_loss: 0.3147 - val_acc: 0.9380 - val_gini_normalized: nan\n",
      "Epoch 45/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.3165 - acc: 0.9156 - gini_normalized: nan - val_loss: 0.2888 - val_acc: 0.9400 - val_gini_normalized: nan\n",
      "Epoch 46/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.3046 - acc: 0.9172 - gini_normalized: nan - val_loss: 0.3064 - val_acc: 0.9380 - val_gini_normalized: nan\n",
      "Epoch 47/50\n",
      "2500/2500 [==============================] - 0s 56us/step - loss: 0.3006 - acc: 0.9192 - gini_normalized: nan - val_loss: 0.3309 - val_acc: 0.9360 - val_gini_normalized: nan\n",
      "Epoch 48/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.2984 - acc: 0.9224 - gini_normalized: nan - val_loss: 0.2763 - val_acc: 0.9460 - val_gini_normalized: nan\n",
      "Epoch 49/50\n",
      "2500/2500 [==============================] - 0s 59us/step - loss: 0.2918 - acc: 0.9220 - gini_normalized: nan - val_loss: 0.3060 - val_acc: 0.9400 - val_gini_normalized: nan\n",
      "Epoch 50/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.3012 - acc: 0.9224 - gini_normalized: nan - val_loss: 0.2881 - val_acc: 0.9420 - val_gini_normalized: nan\n",
      "500/500 [==============================] - 0s 78us/step\n",
      "Train on 2500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.8745 - acc: 0.6580 - gini_normalized: nan - val_loss: 1.5562 - val_acc: 0.7320 - val_gini_normalized: nan\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 0s 65us/step - loss: 1.3390 - acc: 0.7720 - gini_normalized: nan - val_loss: 1.2303 - val_acc: 0.7300 - val_gini_normalized: nan\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 1.0598 - acc: 0.8120 - gini_normalized: nan - val_loss: 0.9981 - val_acc: 0.7680 - val_gini_normalized: nan\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.8933 - acc: 0.8240 - gini_normalized: nan - val_loss: 0.8886 - val_acc: 0.7820 - val_gini_normalized: nan\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.7810 - acc: 0.8244 - gini_normalized: nan - val_loss: 0.7993 - val_acc: 0.7980 - val_gini_normalized: nan\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.7102 - acc: 0.8272 - gini_normalized: nan - val_loss: 0.7218 - val_acc: 0.8040 - val_gini_normalized: nan\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.6799 - acc: 0.8276 - gini_normalized: nan - val_loss: 0.7004 - val_acc: 0.8080 - val_gini_normalized: nan\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.6323 - acc: 0.8352 - gini_normalized: nan - val_loss: 0.6530 - val_acc: 0.8140 - val_gini_normalized: nan\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.6156 - acc: 0.8384 - gini_normalized: nan - val_loss: 0.6280 - val_acc: 0.8180 - val_gini_normalized: nan\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.5872 - acc: 0.8368 - gini_normalized: nan - val_loss: 0.6145 - val_acc: 0.8220 - val_gini_normalized: nan\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.5742 - acc: 0.8460 - gini_normalized: nan - val_loss: 0.6108 - val_acc: 0.8060 - val_gini_normalized: nan\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.5527 - acc: 0.8444 - gini_normalized: nan - val_loss: 0.5935 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.5361 - acc: 0.8476 - gini_normalized: nan - val_loss: 0.6150 - val_acc: 0.8020 - val_gini_normalized: nan\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.5326 - acc: 0.8428 - gini_normalized: nan - val_loss: 0.5650 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.5271 - acc: 0.8460 - gini_normalized: nan - val_loss: 0.5559 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.5095 - acc: 0.8496 - gini_normalized: nan - val_loss: 0.5522 - val_acc: 0.8300 - val_gini_normalized: nan\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4993 - acc: 0.8488 - gini_normalized: nan - val_loss: 0.5611 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.5009 - acc: 0.8588 - gini_normalized: nan - val_loss: 0.5155 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4939 - acc: 0.8508 - gini_normalized: nan - val_loss: 0.5441 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.4817 - acc: 0.8528 - gini_normalized: nan - val_loss: 0.5121 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 0s 61us/step - loss: 0.4782 - acc: 0.8468 - gini_normalized: nan - val_loss: 0.5437 - val_acc: 0.8340 - val_gini_normalized: nan\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.4756 - acc: 0.8620 - gini_normalized: nan - val_loss: 0.4848 - val_acc: 0.8400 - val_gini_normalized: nan\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.4653 - acc: 0.8656 - gini_normalized: nan - val_loss: 0.5013 - val_acc: 0.8360 - val_gini_normalized: nan\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4546 - acc: 0.8588 - gini_normalized: nan - val_loss: 0.5197 - val_acc: 0.8160 - val_gini_normalized: nan\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.4546 - acc: 0.8640 - gini_normalized: nan - val_loss: 0.4994 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4595 - acc: 0.8604 - gini_normalized: nan - val_loss: 0.4877 - val_acc: 0.8560 - val_gini_normalized: nan\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4448 - acc: 0.8684 - gini_normalized: nan - val_loss: 0.4819 - val_acc: 0.8640 - val_gini_normalized: nan\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.4376 - acc: 0.8704 - gini_normalized: nan - val_loss: 0.4754 - val_acc: 0.8600 - val_gini_normalized: nan\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.4390 - acc: 0.8724 - gini_normalized: nan - val_loss: 0.4801 - val_acc: 0.8480 - val_gini_normalized: nan\n",
      "Epoch 30/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4417 - acc: 0.8664 - gini_normalized: nan - val_loss: 0.4555 - val_acc: 0.8680 - val_gini_normalized: nan\n",
      "Epoch 31/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.4298 - acc: 0.8720 - gini_normalized: nan - val_loss: 0.4553 - val_acc: 0.8600 - val_gini_normalized: nan\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.4177 - acc: 0.8768 - gini_normalized: nan - val_loss: 0.4472 - val_acc: 0.8680 - val_gini_normalized: nan\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.4131 - acc: 0.8804 - gini_normalized: nan - val_loss: 0.4736 - val_acc: 0.8560 - val_gini_normalized: nan\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.4222 - acc: 0.8772 - gini_normalized: nan - val_loss: 0.4364 - val_acc: 0.8740 - val_gini_normalized: nan\n",
      "Epoch 35/50\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.4092 - acc: 0.8824 - gini_normalized: nan - val_loss: 0.4510 - val_acc: 0.8640 - val_gini_normalized: nan\n",
      "Epoch 36/50\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.4000 - acc: 0.8808 - gini_normalized: nan - val_loss: 0.4487 - val_acc: 0.8780 - val_gini_normalized: nan\n",
      "Epoch 37/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.3962 - acc: 0.8880 - gini_normalized: nan - val_loss: 0.4309 - val_acc: 0.8560 - val_gini_normalized: nan\n",
      "Epoch 38/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.4011 - acc: 0.8868 - gini_normalized: nan - val_loss: 0.4159 - val_acc: 0.8740 - val_gini_normalized: nan\n",
      "Epoch 39/50\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.3951 - acc: 0.8820 - gini_normalized: nan - val_loss: 0.4217 - val_acc: 0.8900 - val_gini_normalized: nan\n",
      "Epoch 40/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.3821 - acc: 0.8860 - gini_normalized: nan - val_loss: 0.4161 - val_acc: 0.8780 - val_gini_normalized: nan\n",
      "Epoch 41/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.3893 - acc: 0.8912 - gini_normalized: nan - val_loss: 0.4563 - val_acc: 0.8840 - val_gini_normalized: nan\n",
      "Epoch 42/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3844 - acc: 0.8920 - gini_normalized: nan - val_loss: 0.4058 - val_acc: 0.8880 - val_gini_normalized: nan\n",
      "Epoch 43/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3745 - acc: 0.8944 - gini_normalized: nan - val_loss: 0.4080 - val_acc: 0.8860 - val_gini_normalized: nan\n",
      "Epoch 44/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3685 - acc: 0.8968 - gini_normalized: nan - val_loss: 0.4124 - val_acc: 0.8780 - val_gini_normalized: nan\n",
      "Epoch 45/50\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.3772 - acc: 0.8952 - gini_normalized: nan - val_loss: 0.3925 - val_acc: 0.9000 - val_gini_normalized: nan\n",
      "Epoch 46/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3599 - acc: 0.8932 - gini_normalized: nan - val_loss: 0.3706 - val_acc: 0.9020 - val_gini_normalized: nan\n",
      "Epoch 47/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3720 - acc: 0.8936 - gini_normalized: nan - val_loss: 0.4221 - val_acc: 0.8940 - val_gini_normalized: nan\n",
      "Epoch 48/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.3644 - acc: 0.9008 - gini_normalized: nan - val_loss: 0.4188 - val_acc: 0.8640 - val_gini_normalized: nan\n",
      "Epoch 49/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.3642 - acc: 0.8960 - gini_normalized: nan - val_loss: 0.4071 - val_acc: 0.9040 - val_gini_normalized: nan\n",
      "Epoch 50/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3663 - acc: 0.9012 - gini_normalized: nan - val_loss: 0.3890 - val_acc: 0.8980 - val_gini_normalized: nan\n",
      "500/500 [==============================] - 0s 50us/step\n",
      "Train on 2500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.2262 - acc: 0.6784 - gini_normalized: nan - val_loss: 1.1194 - val_acc: 0.6960 - val_gini_normalized: nan\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.9992 - acc: 0.7696 - gini_normalized: nan - val_loss: 0.9560 - val_acc: 0.7800 - val_gini_normalized: nan\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.8672 - acc: 0.8116 - gini_normalized: nan - val_loss: 0.9130 - val_acc: 0.7640 - val_gini_normalized: nan\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.7919 - acc: 0.8172 - gini_normalized: nan - val_loss: 0.7989 - val_acc: 0.8100 - val_gini_normalized: nan\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 0s 63us/step - loss: 0.7382 - acc: 0.8172 - gini_normalized: nan - val_loss: 0.7590 - val_acc: 0.8120 - val_gini_normalized: nan\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.6783 - acc: 0.8188 - gini_normalized: nan - val_loss: 0.7074 - val_acc: 0.8100 - val_gini_normalized: nan\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 0s 62us/step - loss: 0.6517 - acc: 0.8236 - gini_normalized: nan - val_loss: 0.6714 - val_acc: 0.8140 - val_gini_normalized: nan\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 0s 64us/step - loss: 0.6350 - acc: 0.8248 - gini_normalized: nan - val_loss: 0.6558 - val_acc: 0.8180 - val_gini_normalized: nan\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 0s 89us/step - loss: 0.6120 - acc: 0.8256 - gini_normalized: nan - val_loss: 0.6290 - val_acc: 0.8120 - val_gini_normalized: nan\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 0s 87us/step - loss: 0.6000 - acc: 0.8284 - gini_normalized: nan - val_loss: 0.6328 - val_acc: 0.8120 - val_gini_normalized: nan\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 0s 83us/step - loss: 0.5865 - acc: 0.8296 - gini_normalized: nan - val_loss: 0.6333 - val_acc: 0.8060 - val_gini_normalized: nan\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.5627 - acc: 0.8324 - gini_normalized: nan - val_loss: 0.5942 - val_acc: 0.8120 - val_gini_normalized: nan\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.5533 - acc: 0.8372 - gini_normalized: nan - val_loss: 0.5671 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.5390 - acc: 0.8404 - gini_normalized: nan - val_loss: 0.5847 - val_acc: 0.8320 - val_gini_normalized: nan\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.5519 - acc: 0.8392 - gini_normalized: nan - val_loss: 0.5600 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.5225 - acc: 0.8440 - gini_normalized: nan - val_loss: 0.5700 - val_acc: 0.8240 - val_gini_normalized: nan\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.5149 - acc: 0.8472 - gini_normalized: nan - val_loss: 0.5378 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.4972 - acc: 0.8492 - gini_normalized: nan - val_loss: 0.5223 - val_acc: 0.8380 - val_gini_normalized: nan\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 0s 76us/step - loss: 0.5065 - acc: 0.8540 - gini_normalized: nan - val_loss: 0.4972 - val_acc: 0.8580 - val_gini_normalized: nan\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.4779 - acc: 0.8576 - gini_normalized: nan - val_loss: 0.5158 - val_acc: 0.8520 - val_gini_normalized: nan\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4887 - acc: 0.8552 - gini_normalized: nan - val_loss: 0.5105 - val_acc: 0.8420 - val_gini_normalized: nan\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4802 - acc: 0.8552 - gini_normalized: nan - val_loss: 0.4887 - val_acc: 0.8440 - val_gini_normalized: nan\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 0s 80us/step - loss: 0.4741 - acc: 0.8620 - gini_normalized: nan - val_loss: 0.4750 - val_acc: 0.8580 - val_gini_normalized: nan\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 0s 77us/step - loss: 0.4540 - acc: 0.8636 - gini_normalized: nan - val_loss: 0.4675 - val_acc: 0.8600 - val_gini_normalized: nan\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.4485 - acc: 0.8648 - gini_normalized: nan - val_loss: 0.4977 - val_acc: 0.8600 - val_gini_normalized: nan\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 0s 73us/step - loss: 0.4474 - acc: 0.8664 - gini_normalized: nan - val_loss: 0.4898 - val_acc: 0.8720 - val_gini_normalized: nan\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 0s 79us/step - loss: 0.4528 - acc: 0.8652 - gini_normalized: nan - val_loss: 0.4771 - val_acc: 0.8660 - val_gini_normalized: nan\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.4397 - acc: 0.8676 - gini_normalized: nan - val_loss: 0.4662 - val_acc: 0.8640 - val_gini_normalized: nan\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 0s 66us/step - loss: 0.4342 - acc: 0.8680 - gini_normalized: nan - val_loss: 0.4547 - val_acc: 0.8620 - val_gini_normalized: nan\n",
      "Epoch 30/50\n",
      "2500/2500 [==============================] - 0s 74us/step - loss: 0.4470 - acc: 0.8668 - gini_normalized: nan - val_loss: 0.4480 - val_acc: 0.8760 - val_gini_normalized: nan\n",
      "Epoch 31/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4267 - acc: 0.8696 - gini_normalized: nan - val_loss: 0.4648 - val_acc: 0.8580 - val_gini_normalized: nan\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4297 - acc: 0.8720 - gini_normalized: nan - val_loss: 0.4258 - val_acc: 0.8780 - val_gini_normalized: nan\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.4158 - acc: 0.8736 - gini_normalized: nan - val_loss: 0.4404 - val_acc: 0.8740 - val_gini_normalized: nan\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.4298 - acc: 0.8752 - gini_normalized: nan - val_loss: 0.4257 - val_acc: 0.8880 - val_gini_normalized: nan\n",
      "Epoch 35/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.4149 - acc: 0.8724 - gini_normalized: nan - val_loss: 0.4283 - val_acc: 0.8900 - val_gini_normalized: nan\n",
      "Epoch 36/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4035 - acc: 0.8792 - gini_normalized: nan - val_loss: 0.4034 - val_acc: 0.8900 - val_gini_normalized: nan\n",
      "Epoch 37/50\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.4081 - acc: 0.8716 - gini_normalized: nan - val_loss: 0.4233 - val_acc: 0.8840 - val_gini_normalized: nan\n",
      "Epoch 38/50\n",
      "2500/2500 [==============================] - 0s 72us/step - loss: 0.4044 - acc: 0.8756 - gini_normalized: nan - val_loss: 0.4422 - val_acc: 0.8740 - val_gini_normalized: nan\n",
      "Epoch 39/50\n",
      "2500/2500 [==============================] - 0s 71us/step - loss: 0.4076 - acc: 0.8788 - gini_normalized: nan - val_loss: 0.4098 - val_acc: 0.8920 - val_gini_normalized: nan\n",
      "Epoch 40/50\n",
      "2500/2500 [==============================] - 0s 67us/step - loss: 0.4040 - acc: 0.8780 - gini_normalized: nan - val_loss: 0.3886 - val_acc: 0.9080 - val_gini_normalized: nan\n",
      "Epoch 41/50\n",
      "2500/2500 [==============================] - 0s 69us/step - loss: 0.3900 - acc: 0.8764 - gini_normalized: nan - val_loss: 0.3983 - val_acc: 0.8920 - val_gini_normalized: nan\n",
      "Epoch 42/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.4049 - acc: 0.8808 - gini_normalized: nan - val_loss: 0.3951 - val_acc: 0.9020 - val_gini_normalized: nan\n",
      "Epoch 43/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.3896 - acc: 0.8856 - gini_normalized: nan - val_loss: 0.3839 - val_acc: 0.8940 - val_gini_normalized: nan\n",
      "Epoch 44/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3857 - acc: 0.8808 - gini_normalized: nan - val_loss: 0.3961 - val_acc: 0.9000 - val_gini_normalized: nan\n",
      "Epoch 45/50\n",
      "2500/2500 [==============================] - 0s 75us/step - loss: 0.3781 - acc: 0.8816 - gini_normalized: nan - val_loss: 0.3778 - val_acc: 0.9020 - val_gini_normalized: nan\n",
      "Epoch 46/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.3863 - acc: 0.8848 - gini_normalized: nan - val_loss: 0.3801 - val_acc: 0.9040 - val_gini_normalized: nan\n",
      "Epoch 47/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3631 - acc: 0.8880 - gini_normalized: nan - val_loss: 0.3861 - val_acc: 0.9020 - val_gini_normalized: nan\n",
      "Epoch 48/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.3671 - acc: 0.8900 - gini_normalized: nan - val_loss: 0.3810 - val_acc: 0.9080 - val_gini_normalized: nan\n",
      "Epoch 49/50\n",
      "2500/2500 [==============================] - 0s 68us/step - loss: 0.3543 - acc: 0.8896 - gini_normalized: nan - val_loss: 0.3847 - val_acc: 0.9080 - val_gini_normalized: nan\n",
      "Epoch 50/50\n",
      "2500/2500 [==============================] - 0s 70us/step - loss: 0.3643 - acc: 0.8884 - gini_normalized: nan - val_loss: 0.3893 - val_acc: 0.9000 - val_gini_normalized: nan\n",
      "500/500 [==============================] - 0s 44us/step\n"
     ]
    }
   ],
   "source": [
    "###########################################################################################################################\n",
    "### Wide models, 1 layer\n",
    "###########################################################################################################################\n",
    "## original true covariates\n",
    "model_nl_wide1 = Sequential()\n",
    "model_nl_wide1.add(Dense(100, input_dim=7, kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model_nl_wide1.add(Dense(1, activation='sigmoid'))\n",
    "model_nl_wide1.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',gini_normalized])\n",
    "trace_nl_wide1 = model_nl_wide1.fit(x_nonlinear_true[0:2500,0:7], y_nonlinear[0:2500],epochs=150,batch_size=64, \\\n",
    "                    validation_data=(x_nonlinear_true[2500:3000,0:7], y_nonlinear[2500:3000]))\n",
    "score_nl_wide1 = model_nl_wide1.evaluate(x_nonlinear_true[2500:3000,0:7], y_nonlinear[2500:3000], batch_size=64)\n",
    "\n",
    "## all original covariates: 0:7,15:20\n",
    "model_nl_wide5 = Sequential()\n",
    "model_nl_wide5.add(Dense(100, input_dim=12, kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model_nl_wide5.add(Dense(1, activation='sigmoid'))\n",
    "model_nl_wide5.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',gini_normalized])\n",
    "trace_nl_wide5 = model_nl_wide5.fit(np.concatenate((x_nonlinear_true[0:2500,0:7],x_nonlinear_true[0:2500,15:20]), axis=1), y_nonlinear[0:2500],epochs=150,batch_size=64, \\\n",
    "                    validation_data=(np.concatenate((x_nonlinear_true[2500:3000,0:7],x_nonlinear_true[2500:3000,15:20]), axis=1), y_nonlinear[2500:3000]))\n",
    "score_nl_wide5 = model_nl_wide5.evaluate(np.concatenate((x_nonlinear_true[2500:3000,0:7],x_nonlinear_true[2500:3000,15:20]), axis=1), y_nonlinear[2500:3000], batch_size=64)\n",
    "\n",
    "## true features used to create nonl_wideinear relationships\n",
    "model_nl_wide2 = Sequential()\n",
    "model_nl_wide2.add(Dense(100, input_dim=np.shape(x_nonlinear_true)[1], kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model_nl_wide2.add(Dense(1, activation='sigmoid'))\n",
    "model_nl_wide2.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',gini_normalized])\n",
    "trace_nl_wide2 = model_nl_wide2.fit(x_nonlinear_true[0:2500,:], y_nonlinear[0:2500],epochs=150,batch_size=64, \\\n",
    "                    validation_data=(x_nonlinear_true[2500:3000,:], y_nonlinear[2500:3000]))\n",
    "score_nl_wide2 = model_nl_wide2.evaluate(x_nonlinear_true[2500:3000,:], y_nonlinear[2500:3000], batch_size=64)\n",
    "\n",
    "## all extra features\n",
    "model_nl_wide3 = Sequential()\n",
    "model_nl_wide3.add(Dense(100, input_dim=np.shape(x_nonlinear_extra)[1], kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model_nl_wide3.add(Dense(1, activation='sigmoid'))\n",
    "model_nl_wide3.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',gini_normalized])\n",
    "trace_nl_wide3 = model_nl_wide3.fit(x_nonlinear_extra[0:2500,:], y_nonlinear[0:2500],epochs=150,batch_size=64, \\\n",
    "                    validation_data=(x_nonlinear_extra[2500:3000,:], y_nonlinear[2500:3000]))\n",
    "score_nl_wide3 = model_nl_wide3.evaluate(x_nonlinear_extra[2500:3000,:], y_nonlinear[2500:3000], batch_size=64)\n",
    "\n",
    "## selected features\n",
    "model_nl_wide4 = Sequential()\n",
    "model_nl_wide4.add(Dense(100, input_dim=len(selected_features_nl), kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model_nl_wide4.add(Dense(1, activation='sigmoid'))\n",
    "model_nl_wide4.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',gini_normalized])\n",
    "trace_nl_wide4 = model_nl_wide4.fit(x_nonlinear_extra[0:2500,selected_features_nl], y_nonlinear[0:2500],epochs=150,batch_size=64, \\\n",
    "                    validation_data=(x_nonlinear_extra[2500:3000,selected_features_nl], y_nonlinear[2500:3000]))\n",
    "score_nl_wide4 = model_nl_wide4.evaluate(x_nonlinear_extra[2500:3000,selected_features_nl], y_nonlinear[2500:3000], batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEOCAYAAACQMUyOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXd4VMXXgN9JgVATWugBQi9SA0iV3gRUEAQFBAtgxS5i\nV/yJ9bMhCkoTpAtIEaRLJ5SEHkpCCy1AQggkpOx8f5wN2fRNyKYx7/Pss7t35s49N+Xs2TOnKK01\nBoPBYMh7OOW0AAaDwWDIHEaBGwwGQx7FKHCDwWDIoxgFbjAYDHkUo8ANBoMhj2IUuMFgMORRjAI3\nOBSl1CGlVIdUxjoopc6lce50pdR4B8g0XCm1JavXdTRKqVFKqe+y4ToNlVLbHH0dw91jFLgh0yil\nTimluiQ5lkg5aq3ra603Zrtw+QylVAHgPeArm2OTlVIBSimLUmp4Cue8qpS6qJQKV0pNVUoVtBkr\nqZRarJS6qZQ6rZR6PH5Ma70fCFNK9XHsXRnuFqPADYZsQCnlcpdLPAQc1VoH2xzzB54H9qZwve7A\nWKAzUAXwBj62mTIRiAbKAk8Ak5RS9W3GZwOj7lJmg4MxCtzgUGytdKVUIatbJFQpdRhonmRuE6XU\nXqXUDaXUPMAtyXhvpZSfUipMKbVNKdUwyXXeUErtV0pdV0rNU0olOj8NGb9XSp21Wqp7lFLtrMfL\nKaVuKaVK2cxtqpQKUUq5Wt8/pZQ6Yr2n1UqpKjZztVLqBaXUceC4Ev5PKXXZeq0DSqkGdv4oewKb\nbA9orSdqrdcBUSnMfxL4XWt9SGsdCnwCDLfKVQToD7yvtY7QWm8BlgJDbc7fCHS2tdoNuQ+jwA3Z\nyYdAdeujO6JkgDsugiXAH0BJYAGiZOLHmwBTEauwFPAr8HcSBTMQ6AFUAxpiVVh24As0tl73T2CB\nUspNa30RUWQDbeYOBeZqrWOUUg8B44B+QBlgMzAnydoPAy2BekA3oD1QC3C3rnvVen+PK6X2pyHj\nfUCAnfcDUB+x0OPxB8paP4xqAbFa62NJxu9Y4FZLPwaonYFrGrIZo8ANd8sSq0UcppQKA35OY+5A\n4DOt9TWt9VngB5ux+wFX4DutdYzWeiGiWOMZCfyqtd6ptY7TWs8AblvPi+cHrfV5rfU1YBmilNNF\naz1La31Vax2rtf4GKEiC4poBDAFQSjkDg5EPGYDRwOda6yNa61jgf0BjWyvcOn5Nax2JKMRiQB1A\nWc+7YJXhT611Q1LHA7hhz/1YKQpct3kfbn0uZh0LTzI/3Dpmyw3rdQ25FKPADXfLw1prj/gH4pNN\njQrAWZv3p5OMBevE1dVsx6sAryf5sKhsPS+eizavbyGKKl2srpcjVtdLGGIdl7YOLwXqKaWqAV2B\n61rrXTYyfW8jzzVAARVtlr9zv1rr9cBPiP/5snUTsrg9MgKhJFewaREB2K7tbn2+kcJY/HjSD4hi\nQFgGrmnIZowCN2QnFxClG49XkrGKSimVyvhZxHr3sHkU1londVlkCKu/+y3k20EJ64fQdUQRo7WO\nAuYjVvhQEqzveJlGJZGpkNbaNgQvUblPrfUPWutmiEulFvCmnaLut863l0NAI5v3jYBLWuurwDHA\nRSlVM8n4ofg3SqmKQAEy5rYxZDNGgRuyk/nAO0qpEkqpSsBLNmPbgVjgZaWUq1KqH9DCZnwKMFop\n1dK6GVhEKfWgUiojVmlKFLNeNwRRah+Q3DqdifjT+5JYgf9ivZ/6AEopd6XUgNQupJRqbpXfFbiJ\nbD5a7JRzJfBAkvUKWDdqFeCqlHJTSsX/T88EnlZK1VNKlQDeB6YDaK1vAn8Bn1h/jm1TuLcHgPVa\n69t2ymfIAYwCN2QnHyNukSDgX2wUhtY6GtkMHI64Ih5DlEz8+G7gWcQFEQqcwP5NyrRYDaxCrNLT\niFK1dfOgtd6KKNq9WuvTNscXA18Ac5VS4cBBJFokNYojH0Sh1mtdxRrXrZR6Qil1KI1zlwF1lFK2\nLqN/gUigNTDZ+rq9VbZVwJfABhJ+5h/anPs8UAi4jGzcPqe1tr3+E8gHlCEXo0xDB4MhfZRS64E/\ntda/5aAMI4F6WutXHHydhsiGcStHXsdw9xgFbjCkg1KqObAGqKy1zkgkiMHgUIwLxWBIA6XUDGAt\n8IpR3obchrHADQaDIY9iLHCDwWDIoxgFbjAYDHmUu62QlqsoXbq0rlq1ak6LYTAYDJlmz549V7TW\nZeyZm68UeNWqVdm9e3dOi2EwGAyZRil1Ov1ZgnGhGAwGQx7FoQpcKdVDSceQE0qpsSmMl1DSFWS/\nUmqXbW1ka33nA9b6z8asNhgMhiQ4zIViLb05Eangdg7wVUr9rbU+bDNtHOCntX5EKVXHOr+zzXhH\nrfUVR8loMBgMeRlHWuAtgBNa60BrnYu5SFsoW+oB6wG01keBqkqpsg6UyWAwGPINjlTgFUlcFOgc\nieskg3QB6QeglGqB1FeuZB3TwFpri6uRqV1EKTVSKbVbKbU7JCQky4Q3GAyG3E5Ob2JOADyUUn5I\nadF9QJx1rK3WujFS3e0FpVT7lBbQWk/WWvtorX3KlLEr8sZgMBjyBY5U4MEkLt5fyXrsDlrrcK31\nCKuiHob0FQy0jgVbny8Di0lcG9pgMBiyl4UL4fXX4datnJbkDo5U4L5ATaVUNWvD2kHA37YTlFIe\n1jGAZ4D/tNbh1iLzxaxziiDNYA86UFaDwWBInX37YMgQ+PZbaNMGTtsdqu1QHKbArU1eX0QK5h8B\n5mutDymlRiulRlun1QUOKqUCEFfJGOvxssAWpZQ/sAtYYS1QbzAYDNlLeDgMHAilSsEff0BQEPj4\nwIYNOS1Z/qpG6OPjo00mpsFgyDK0hsGDYcEC2LgR2rWD48fhoYfg2DH4+msYMwbiW7lqDYcPw9q1\nsGYNfPcd1KiRoUsqpfZorX3smZuvUukNBoMhRcLDIS4OSpTI2HmTJ8O8efC//4nyBqhZE3buhGHD\n4NVXYc8e6NpVlPbatXDhQsK88+czrMAzgrHADQZD/iMmBnbsSLCEd+0CiwWaNIEuXUThtm0Lbm6p\nr+HvDy1bQocOsHIlOCXxOFss8Nln8MEH8r50aVk7/lGlSqZEz4gFbhS4wWDI3cydCwcOQOfOsoFY\nsGDyOUldF5s2QUSEKF0fH1GoBQvK+PbtEBsryrttW1HmXbpA48YJSvrGDTkvIkI2MD09U5dv/36x\n7hs1Sq7kM4FR4AaDIX8QGQnlyokLBKBQIXFldOkiz8eOJXdd1KiRoJQ7dkzuNomIgP/+E0W/Zg0c\nOiTHS5WSD4kuXWS9hQtlo7J9iikoDsP4wA0GQ/5gyRJR3kuWiHUbb2G/9VbCnNKlRfHGK+30XBdF\ni0KvXvIAUfzr1sm6a9fC/PlyfPz4bFfeGcVY4AaDIffSowccPQqBgYndE8HBsG2bWNtZ5LoAxBVz\n9CgEBEDfvlm3bgYwFrjBYMj7BAeLVfzuu8kVacWKMGBA1l9TKahbVx55gJyuhWIwGAwp88cfEunx\n5JM5LUmuxShwg+FeISxMEkviNwSzCq3FUv7iC3FrxMZmzZrTp8tGZfXqd79ePsUocIPhXmH8eEk8\nadlSfLxZwc6dsoHYrRuMHSthfiVLSqbijz/CkSOijDOzbkCAsb7TwShwgyGvce4cTJsGTzwhIXY9\neqSvJEND4ddfRcFevQotWsCyZZmX4ehR6N8f7r8fDh6EH36QaI4FC+DxxyU07+WXoV49qFwZhg+H\n2bPh4kX71p8xQ0IGHeHnzkeYKBSDIadYuxY2b7Z//pUrEu4Wbz17ekKtWrBliyjj3r1TP/ezz+C9\n9yS70MMDHnkE9u6FTz5JvkmotSTOrF8vij8pQUGijAsXhjfegNdeg2LFUp4XH5q3bh1cuybH77tP\nLPZ33pHY66RERckHU58+4ge/x8hIFApa63zzaNasmTYY8gRRUVqXLKm1qEv7HoULa92jh9bffKO1\nv7/WFovW0dFa16ihdYMGWsfGpnytmze1LlNG6549E47duqX10KGy7sMPa33kiNZTp2r9+ONae3qm\nLYebm9Yvv6z1pUv2329cnNa7d2s9YYLWnTtr7eKidbNmWl+/nnzu3LlynbVrM/YzzScAu7WdOi/H\nlW5WPowCN+QZFi2Sf79//rn7teIV3owZKY//9JOMb9qU+LjFovV332nt7JygnMuW1fqJJ7SePl3r\ns2fvXrbUWL5clPgDD8iHiS09emhdubIo/XuQjChw40IxGHKCvn1h9244exacne9uLYsFmjcX33ZA\nQOJaIbGxUhWvfHnYujWh7KktO3aILA88AA0apDzHEcyZI378Xr1g8WJwdZXqfZUri3tl/PjskSOX\nkREXitnENBiym0uXpLrd0KF3r7xB/NcTJkiXmF9+STw2fz6cOgVvv526Yr7/fnjxRfFNZ5fyBqmz\n/fPPsGKFbHJaLDBrlon9zgAmE9NgyG7+/FOq12WlkuraVcL5xo+HESOgeHFxikyYIFmFffpk3bWy\nktGjJT79nXfA3V2aJrRpI98aDOliLHDDvceGDfaHs2U1WksIYIsWEmKXlUyYIJEq33wj7//5R6JJ\n3n47R2p62M3YsSLjpEkSN26sb7vJxb9Vg8EB7Nolluqrr+bM9f38RKk6Qkn5+Ejc9DffiJvmiy+g\nUiVxVeR2Pv9c3DgVKkj/SYNdGAVuuHeIjYWRI8UKXrJEvrpnNzNmQIECMGiQY9YfP17iqAcOlJrX\nr78u18vtKCWZm2fOiCvFYBdGgRvuHb7/XhJZxo4VJRdf9zkz7Nsn1fIyQnS0JMA89JCkmzuCWrXg\n6adFeZcsCc8845jrOIqs2NS9hzAK3HBvcPq09C7s3Vsa1NavL8WSMsOKFeLDbtlSIjzsZeVK8VEP\nH56569rLhx+KFfv669K8wJBvMQrckP/RGl56SV7/9JN8XX/ySemNeOxYxtbatAkefVQ2IG/elOgP\nezdEp0+XFPFu3TJ2zYxSoYLUSxk71rHXMeQ4RoEb8j9LlkitkI8/Tmi3NWSIRGbMmGH/Onv2SDhe\ntWpS22PlSkk86d495ZohtoSEiOU+ZAi4ZEP0btGiuTvyxJAlmN+wIX9z44ZY3w0bwpgxCcfLl5cq\nfjNnSkx2ehw5Ioq6ZEn491/pw9iqlXw4HD0KDz4oFnlq/PmnbKKaEDlDFmISeQz5m/ffFyt54UJJ\n1bZl+HCJ1li/XlwhqXHqlIy7uEhlvUqVEsa6dpWU8AEDpMLfsmWJU9njmT5dwvwaNMiCm8rb3Lp6\ni6XDl9J5Qmc863vmtDh2oS2azZ9v5siiI8nGlFI0G9WMZiObZbtcRoEb8i979kho2ujRki6elD59\npLTq9OmpK/CLF2Xs5k3xf9eokXxOv37w+++SATl4sIQqJl3Dz0/87wZ2/rCTY8uP4VzQmYELc3/M\nd9T1KBYPWcyx5cfwauuFWwm3ROPh58JZPmo5Ti5ONHmqSbbKZhS4IX+yebNsNnp6StRJSri5icKd\nPh2uX08efxwaKhuO58+L5d2wYerXGz5c1njlFSnMlJRChRwX+52HiI6IZtePu3Bxc+HIX0e4EnCF\n0rVL57RYqXLl6BXmPjyX0JOh9PypJ82fb45KUi8m9nYsc/vOZdmzyyhYvCD1Hs3iDNs0MD5wQ/5C\naymQ1KmTKOR168TKTo3hwyEyUjrJ2BIRIX7tgADxc7dqlf61x4wRf/j27ckfhw+n3LzgHmPvb3uJ\nCo2i/9z+uBR0YdvX27JdBm3RXPS7yNavtjKn7xxWPL+CI38dITI0MtG8gL8DmNJiClGhUQxbN4wW\nL7RIprwBXALGM/DLG1S6vyKLHl/EyX9PZtetOLacrFKqB/A94Az8prWekGS8BDAVqA5EAU9prQ/a\nc25KmHKy9zhRUfDCCzB1qijfWbPSVt4gCr9+fdmc3LJFjt2+Le6VdetEsffr53jZ7wHiouP4ofoP\nlKheguEbh7PihRXsnbKXMUFjKF6xeKrnRV6LRDkr3NzdUp2THtfPXCdwbSCBawIJXBfIrZBbAJSs\nXoyIS7eJjohGOSkq+FTAu6s3cTFxbPtyGxV8KjDwr4G4V04lOzT2JswvBmiiSj3J9Ldacu1EKEPX\nDKVy68qZkjUj5WQd5kJRSjkDE4GuwDnAVyn1t9b6sM20cYCf1voRpVQd6/zOdp5rMCQQHCyKdtcu\naR328cf2hdHFx4SPHQvHj0uI4OOPSyuwadOM8s5CDvx5gPBz4fSeLK3fWr/emj2/7GHHdzvo9lXK\nsfG3rt7i1ya/AvDU1qdSV6RJiAqLImhD0B2lfe24tHMrWrYQNdqAd/1zeHutpljRs8SV6kyw2y8E\nbjhH4JpAtkzYgo7TNHqyEQ9OehDXQq6pXyjsIKChfA/cLsxgyNhjTPtgALN7zWb4puGUa1TO/h9Q\nJnCYBa6UagV8pLXubn3/DoDW+nObOSuACVrrzdb3J4HWgHd656aEscDvUQICpBnBzZsS151RpRsc\nDF5eosTPnxef+HffJQ47NNwV2qL5ucHPOLs6M8pv1B1XxKLHF3Fs2TFeOfMKhUoUSnbOnL5zCFwT\niIubC0XLF2XEfyMo4lkk1esEbQhi/bj1BO8KRls0rkVcqdqhKt5Nr+Nd5jfKlNwrJc8LVYTyXeX5\n0GdQ6WFouwCcXLgdfpvrZ69Tpl6ZFF0miTj+K/iOhr5BEHYAtg8h7Gpppn36LHGxLozYMoJSNTPm\nOssVFjhQEThr8/4c0DLJHH+gH7BZKdUCqAJUsvNcAJRSI4GRAF5eXlkiuCGP8cYb4j7ZsUPcIRml\nYkXZrPziC4kJ//BDo7yzmIBlAVw5coV+f/ZLpBTbvN2Gg3MOsnvSbtqNa5fonO3fbuf4iuP0+KEH\n5RqXY1b3WczqMYsnNzyZzJ2itWbn9zv5941/8ajqQbv32uHdxZtKLSvh7KpgSWVwLQ41f4ByXaF4\n7YTmFW7lYM9LsPNpuH8aBYsXtD+8MdQPXN2hSBUoWhW678Ljv4cZ+up3zPvlBW5fj7qbH1u65PQm\n5gTAQynlB7wE7APsyKpIQGs9WWvto7X2KVOmjCNkNORmtmyB5cvFes6M8o7n6adFeY8ZIwrckGVo\nrdk6YSse1TyoPyDx76hco3LU6FmDHd/tICYy5s7xs9vPsu6dddTtV5cWL7agSrsqDFw0kMsHLjOn\n9xxibiXMjYmMYcmwJax+dTW1+9Rm1L5RdPy4I1XaVcG5gDOEbIHI89DgA6j9ErjXSdx5qPaLcN8n\nEDQT9rwi+yL2EuoHJRonrFe8NnTfSenmLXnuow+p4OnYTVpHKvBgwNaLX8l67A5a63Ct9QitdWNg\nGFAGCLTnXIMBraURQPny8PLLd7dW//6wfz98+232thW7Bziz+Qzndpyj9RutcXJJrnLavN2GWyG3\n8JvmB8im5aJBiyheuTh9f+97x2Kv2bMm/Wb348zWM8x/dD5x0XFcP3OdaW2nsX/Wfjp80oGBiwZS\nsFiSRKrT88C5EFRMoytRg/eg9qtw7Ec48JF9N2aJg7D9osBtcS0O7Rfj1Ho6VHLsHoojXSi+QE2l\nVDVE+Q4CHredoJTyAG5praOBZ4D/tNbhSql0zzUYWLYMtm2TPpCFC9/dWkpJT0hDlrNlwhYKlylM\n4xGNUxyv0r4Kle6vxLavt9H02aYsGb6EGxdu8PS2p3HzSOwqqT+wPlHXo1g+cjlz+s7hwt4LxN2O\nY/CywdTqXSv54pZYOLsQKjwIrmlUZlQKmn4DMdfh4CdQwAPqpNP0I+IExN1KrsABlBN4D0v7/CzA\nYQpcax2rlHoRWI2EAk7VWh9SSo22jv8C1AVmKKU0cAh4Oq1zHSWrIQ8SFwfjxknvxKeeymlpDKlw\n0f8iJ/45QafPOqUazaGUos3YNsx7eB5/PvgngWsC6fF9Dyr4VEhxfrNnmxEVFsXat9ZSuk5pHlvy\nWOrJQJc3QdRlqPJY+sIqBS0mixLf+5r4yj3SKH0QKt8YUlTg2YRDMzG11iuBlUmO/WLzejuQwsdm\nyucaDHf44w84dEiaMiStcWLINWz7chsFihWg+fPN05xXu09tStctTeCaQOo8UocWL7VIc36bN9tQ\nuVVlyjYqm9xlYsvpeeBSBCr0sk9gJ2do+n9wdhFcXJO+AlcuULyufWs7gJzexDQYJIIko/M//BCa\nNZN0ecNdERcTR3hweLLHjfM3uJsw4xvnb3Bo/iGaPtM0mSskKcpJ0f3b7tToWSOR3zstvNp6pa28\nLTGiiCv2BZcMuNiKVIai1cV6T4tQP3CvB85pyOBgTC0UQ87y9dfwzjswapRUDixbNv1zJk2S3om/\n/242HDOB1pqQwyF3klxObzpNdER0inOrPFCFAfMHpBl7nRp7p+zGEmuh+f1zgO7pzq/RowY1eqRQ\nLCyzXFwH0dfsc58kpWwHOPsXaIv4s1MizF/cLDmIUeCGnOPkSVHaVavKRuT06fDaaxLXXTyV1Orr\n1+Gzz6BLF3kY7ObWlVuseXMNJ1afIOJCBAAla5ak4dCGlG1UFuWU+MPw5uWbbB6/mck+k3ls8WNU\naJayTzol4mLi2DNpGzUaHqdk7Gw49whUeijjQsfdhsDpEBMGZTtDiSbi5rCHM/MkIqR8j4xf17MD\nnPw95SgTgMhLEHkhR/3fYBS4IafQGp5/XvzXGzdKFuX778Onn0oxqnffhWHDkje5/eILuHoVJqRb\nGseQhLVj17J/9n7q9quLd1dvvLt441El7VoxNXvWZO7Dc5nWdhq9J/em0dBGdl0rYGkANy7F8uCz\n58HjPtj9IpTtBK7F7BPWEgen/4T9H8DNUwnHC5SUdcp1kUzKot4pnx93G84ulgzLzLg4PB+Q50sb\nU1bSYf7ynMMK3PjADTnDvHnS2eZ//5NMyFq15JivLzRpIpZ46dJQokTix4QJ0oShWfYXz8/LhBwJ\nwW+aH81faM6jcx+l6dNN01XeAOWblmfk7pFUbFmRJcOWsOrVVVhiLeme5/vdatxLh1Fz6OPQ/Fe4\nFQz77UiQ0hqCV8CqJrB9mCjsjv/CIxeh9Wyx4q/ukPT1v6uD//spr3PhX4km8cqE+wSsfnBvuLwx\n5fH4CBQP+z7QHIWxwA3ZT1iY1M328YHnnks85uMjhaQ2bpQmCEkpUACeeCJbxMxPbHhvA65FXJOl\nq9tDEc8iDF0zlH/f+Jed3+3kkv8lBi0ZRMHiKVu2IUdCOLU1nM5DAnCqPkEs4Bqj4Nj3UG0olEyl\n6UHYQfB9TjIni9aANnPBa0CCD7rq4/LQGm4cg0P/g0PjoYA71H0j8Vpn5kGBEmKpZxbPDnBuccp+\n8FA/KOwFBUtmfv0swChwQ/bzzjvS5Peff5K7SOLp0EEehrvm3M5zHPnrCB0+7kCRMhnfjARwdnWm\n5/c9Kd+0PH8//TfLRi6j/5z+KUaL7P52Bc4usTQZ3SnBfdH4c1GGu0ZCtx3J/dhnFsKO4RLy1/xn\nqP4MOKUSHqqUpKy3nApxUbDvTalHUuNZGY+NhHNLZfPSuUCm7heQjczAqVKkqkQSSzs+hT6HMS4U\nQ/ayfbtsWI4ZI64Sg0PRWrNu7DqKeBah1Wt2NKVIh8ZPNqbjpx05NO8Qe37dk2w8OiIa/zmB1G91\nnCItRiUMFPCApt/Btd1w/OeE45Y48BsHWwaAR0Po6Qc1n0tdedvi5Ayt/pBNyl2j4PR8OX7hH4iN\ngCp32QHJ1g9uS+wtuBFgFLjhHiMmRvpFVq4Mn3yS09LcE5xcfZJTG0/R/v32FCh6F9aoDW3fbkv1\n7tVZ9coqLvpdTDS2/7c13L7pjM8zNZNvWFZ5DMp1A/93xSceHQqb+sDhz6HGSOi8AQqVz5gwzgWg\n3SIo0wa2D4HzqyR5p2AZcYHcDUW8UvaDhx0Ut0pSqzwHMArckH383//BwYPS3LdoGnUpDFmCtmjW\nvbMOj2oeWdoxXTkpHvnjEQqXKsyCgQu4feO2XE9rfH/aRrmqF6k04MUUTlTiHtExsP1JWNUCLq2F\n5r9Ai18znxDjUhgeWA7uDWBzPwj+G7weBacs8BB7dpCEHm2zcRuW8yn08RgFbsgeAgLgo4/g4Yeh\nb9+clibf8M+Yf5jSfArHVhxLljV5cN5BLvpdpOOnHaWsakaIuw2rW0HATykOFylThP5z+hN6MpTl\no5ajtebsur1cPlmA5o8XRhVKJSGrWHVo8D5cWidujs4boOaolOdmhALu0HEVFK4sfvHMRp8kpWwH\n+aYQdiDhWKifxJcXqZo117gLzCamIX0iI2HRIvD2hhYtwCWDfzaRkTBgABQpIta3IVW01hxeeJjq\n3aqn2wMy8loke37Zg9aaOb3n4NXOiy5fdKFyq8rERcex4b0NlG1UlvsGZ6LK4olfJVwv+hrUeiHF\njNcq7avQ8dOOrH93PVU7VOXUX4spWDiO+8aMTnvtOm9IhEjFvlC4YsZlSw03T/lAuLgWPNtnzZrx\nfvDLmxJcJqH+Ej6YWoZmNmIUuCFtzp6FRx6BPdYNq+LFoWPHhEzI2rXTT2cfMwYOHJCok4pZ+A+b\nDzm65CgLBy6k1RutUu0TGc/BuQeJi47j6R1Pc2HPBTZ9sompradS+6HalKpditDAUB5f+XiyDMt0\nibkBB8eDS1EJ1wvzT9Vd0HZsW05vOs0/L/+DjnWief8IXD1rpr2+cwHZqHQEhStkbRnXIl5QpJps\nZNZ+WVwpYf7gnTsqYOb8R4gh9/Lff5Iwc+wYzJ0rHdoHDRJl/NJLULcuNGgg71Pjzz9hyhTpmNMj\nEynN9xCWWAvr310PgN9Uv0QdalLCf4Y/ZRuWpWKLijR/vjkvn3iZjuM7cmrDKbZ9uY0qD1RJXFvk\n2h7xO19Ppzf40W/hdgi0nQ/KWTYFUyHeH16oeByWOGeavzHA7vvNM5TtkOAHv3FSOtHnAv83GAVu\nSAmtxdXRuTOULCmd3h97TCr//fqr1DA5eVLCAcPCoFUrWLgw+ToBAVKkqk0bSZHPRwTvCubayWtZ\nuqb/TH+uHLlC8xebE3ktkkPzUy+BH3I4hOBdwTQa3uhOLHaBogVo/257Xj75Mp0ndKbvb0mq+h36\nHK75wpZuhJsSAAAgAElEQVSBEgqXElGX4cjXULk/VOgpiTCn56XZZqxI6YIMfXcR/cYFUKp5m0zd\ne67Gs4O4ksIO5qoNTDAK3JCUqCjpD/nSS9CzJ+zcCXXqJJ/n7S3KefduaNRIfNzjxkmjBRC/98CB\nULCgWO8Z9ZvnYq4eu8q09tP4tfGvHPnrSJasGRMZw8YPN1KxRUV6ft+T0nVL4zvRN9X5fjP8cHJx\nouETDZONFS5dmLZvt6VkDZsswVvn4NwSUUbXD8Pul1Je+OBnEBcJjT6T916Pwc0gid9OjeDleJY5\nwH2jB9pxp3mQsvF+8I0JNcDd6+WoSPEYBW5IIDoaunaFadOk3vaSJeDunvY55cvDhg2izD//HHr3\nhtBQePVV6TE5cyZUqpQ98mcDWmtWPLcCl4IulK5bmvn957P+/fVoS+brZgP4TvQl/Fw4nSd0Rjkp\nmj/fnPO+5wn2Td4K1hJrYf8f+6nRs4b9ZV5PTBEXwP1Tof44yTAM+iPxnIggODFJ/LvFa8uxyg9L\nUk0abhSOT5Toj4q97bzbPEaRKuIHv7zJWgO8LjinvcGcXRgFnt+JjZW6IvGWcVq89ZZ0eZ81S0L+\nnOz88yhQQNwpv/4K69ZBvXry+q23oJednVDyCAdmHyBofRCdJ3RmxOYRNH6qMZvHb2buQ3OJup7B\nxhRWosKi2Py/zVTvXp1qHavBVV8aDq6JaxFXdv+c3PINXBtIxIUIGg9vDBGn4MaJtC8QFw0nJktX\nmqLV4L6PJEpj12i4bvMNYv8H4vO+z6boVIESUK47nJmfOBY6nvAAifqoMSpr4q5zK/F+8NB94JE7\n3CdgFHj+5803JWrkhRfS9GOyeDF8/71EjGS2WNTIkfJhAdCuHYwfn7l1cimR1yJZ/dpqKrasiM8o\nH1wKutD3t770mtiLE6tO8FuL3wg5EpLhdbd+tZWo0Cg6f94Zru2F1S1w2/cIDZ+oz8G5B7l1NbG/\n2m+6H4VKFaJW2xhY1RT+bQW3r6Z+gXNLIOoi1Hxe3ju5QOs/JQEm3h8euh9OzYbaY5KH9lV5DG6d\nhSs7kq99fJJY6NWfyfB95yk8O8jPOPJCrsjAjMco8PzMkiXw3XcSLfLrr1JEKiWCgqQxsI8PfPnl\n3V2zdWtZb926fNercs3ba4i8FknvX3vfCc1TStwdw9YPIyosit9a/MbSp5Zy4M8DRFyKSHfNGxdu\nsOP/dtBgcAPKNykvzQuUC1z+j+YtZxMbFYvf9ISqjJGhkRxdcpT7HvXCeUt3cCogiSZ+b6d+keMT\nxQVQwSYKqHBFaDULrh+EPS+D/zgpCFUvhXUq9QWngsndKLE3Rd7Kj0JqiTv5hXg/OOSaDUwwCjz/\ncuoUjBghYYD79sHo0dIMIWkjhOhoiTDRWupxF8iCehlubvlOeZ/efJp9v+3j/lfvp1yjcsnGq7Sr\nwrO+z1CrawmOLjnKX0/8xTflvuGXRr+w+vXVnFh1guibyduWbfpkE5YYCx0/7SjZj6dmSwRI84mU\ndVuAV6Nb7J60+46P/dC8Q8TdjqNxra8lJb3zeqjzunSPufxfcsHDDsrxms8lTzyp0B3qvSPnnl8B\n9ceKyyQprsXF/XJmvhSfiufUHKm5HW/Z52eKVEnIvMzhGuC25GOn1T1MvFK2WKRre8GCMHGitCN7\n5x3w8BCFDhKf7eubkGlpSEZcdBwrRq/A3cudDh91SHWe+7Uv6f/o51ieqMxF53cIPFKfwLWn8P3J\nlx3f7sDJ1YnKrSvf6Ybj5u7G3il78RntQ8nqJaUHY/Q18B4u1nJ0GM3b/cminx7l5OoT1OhZE//p\nu/GsEka5isegw3qJhrjvA1Guu0ZLNT/bEqrHfxbr2XtEykI3/ASubIObp6FWKpEpIG6Uc4shZLP4\ng7UWy96joRSSuheo8KCUAHArndOS3MEo8PzI2LESu71wYYJSdnKCGTMgPFxambm7Q+HCUmDqpZeg\nX7+clTkXs+3rbYQcDmHwssEUKJLKN5TDX0pVPa/HcLoZRIWrz1Phvrq0HfIZMSXf4szWs3eaCG94\nbwMb3tuAclK4uLnQ/j1r2nfgdKnGF98ot95Y6g4NpcgfEfhOmIVHpRGc23mJrk/sQXX4G0r5yDyX\nIuAzETY9CEe+ggbvyvGYcIk0qTIodaXj5AKd1kHcrbQ7t1fsDc6FxY1StoP4w0P9pBDVvdJYuuk3\nYLmd01Ikwijw/MbSpaKUX3wR+vdPPObqKtmUPXpIv8nChcXF8tVXOSNrLiLqehQX9l7AEpM40iI6\nIpr/Pv2Puv3rUqt3rZRPPjFZfNBVBkt9auUk1qr/ONjcD9dS91O9yVdU7yaK+WbITYLWBxG0Lgiv\ndl4ULVdUmuSeXynukPhmB0rh3PwLmvZ7g83TFQVe+AjlVIWGr70iStSWir2ke83BT8VaLlZDlHds\nRPouDidncEqnV6VLEVHiZxeBz49ifbsWh6r3UHck54KZr5joIFTSCmZ5GR8fH717dxoJB/md06eh\ncWOxurdtE9dJSoSHQ6dOcOKE1DipXj175cwFxEXHcW7nOQLXBBK4NpDgXcHouJT/Fwq6F+T5Q89T\nvGLx5IOn5sK2x8VH3H5x4kYEllgImiG9IKMuQY89UCJ54g0AR/8P9r4GDx5KliRy/fQ1vvf+AW1R\n1OpUmMHr3kx5jVvnYUVdKNUSOq6GlQ3AuRB0980aK/nsX7C5v/Sm3DFCQgd9frj7dQ2JUErt0Vr7\n2DPXWOD5BT8/2bSMi5PNyNSUN0hBqq1bxSfu6Zl9MmaAPVP2EH42nPbvt8fZNYOlUNNAa83yUcs5\n8OcBYm7GoJwUFZpXoO3YtlRpXyXFpgclqpegaNkU6pcHr4TtQ8GzHbRdkLyLjJMLVH9aOqMvryNd\nY7ptTb6ZqDUEToNSLVLM8HOvUpLaD9Xh6OIAGj33YOo3V7gCNPqfdID3fU4yLltOzToXR/meUuDK\n9zmwRDuuIJXBbowCz+sEBsL770vRKA8PmD0batRI/7yCBXOt8o65FcOaN9ZwO/w2pzedZsCCAfZn\nHKbD4YWH2TtlLw0GN6DegHpU7VCVQiUKZXyhy//Blv4SE/zAMnBJY42CpaDpt9Jl/cSU5PWvQ/2k\n3rTPxFSX6PBRR9zcC1GrTypunHhqjIagmVIOtkAJcadkFS6FpCv8qdlQtpNkJBpyFBNGmFe5fFk2\nH+vUkSScsWNFmffpk9OS3TVHlxzldvhtWo5pSbBvMJObTeb87vN3vW5cTBzr311PmfpleOSPR6j7\nSN3MKe9re2Bjb4mt7rBKfMHpUXWIKD2/tyEycRsygmZIPHcaPRzLNizLQ9MewqVgOjaXk7N0t1HO\nYv2ntTGZGaoOkee0IlYM2YZR4HkNreHbb8XPPWmSuE1OnJA6JCVSiOHNg/hN98O9ijvdv+3OU1uf\nQjkrpradiv9M/7tbd5of145fo/P/OuPknMk//etHYUMPKFgSOv1rf0iZUtB8khSK2vtqwvG4aLFo\nKz0ka2YFJRrDg4ehoQMqQFboAb0OSo0UQ47jUAWulOqhlApQSp1QSo1NYdxdKbVMKeWvlDqklBph\nM3ZKKXVAKeWnlLqHdyZtuHlT6nG//rqkxx86JBmWFSrktGRZRvi5cALXBtLoyUYoJ0X5JuUZuXsk\nlVtXZsmTS/hnzD/ExdhR1yUJMbdi2PjRRiq3qZy+GyI1Ik7B+i5i3XZaC4UzWKSreC2o/y6cngvn\nV8ux8yvh9hWoNjxzMqV1LUcVXPKo75h1DRnGYQpcKeUMTAR6AvWAwUqppDs0LwCHtdaNgA7AN0op\n212kjlrrxvbuyOZrAgMlTX3BAsmm/Ptv6YaTz/D/wx80NBqWkO1WuHRhhv47lJavtGTXD7v456V/\nMrzuzh92EnEhgi4TuiSukW0vkRdhfVdJH+/4r4TpZYZ6b0ulv93PQ2ykuE/cykH5tLvvGAwp4chN\nzBbACa11IIBSai7wEGDbDkQDxZT8RxUFrgGxDpQpb7J2bUJm5cqV+bazjdYa/+n+eLXzksxEG5xc\nnOjxfz1wLuDMti+3UbVDVRoMamDXupHXItkyYQu1etfCq61XxgWLDoUN3SHyvFjeqYUC2oNzQUl+\nWdcR9r4Cwcuhziv5u5KfwWE40oVSEThr8/6c9ZgtPwF1gfPAAWCM1ndqVmpgrVJqj1JqZGoXUUqN\nVErtVkrtDgnJeCW4bCcqCm7bmc2lNXzzDXTvLnW3fX3zrfIGOLfjHFePXZUyqanQaXwnKreuzLJn\nl3H1eBoV+GzYMmELt8Nv0+l/nTIuVOxN2PgghB+F9kugTKuMr5GUsh2g2pOSAKRj5bXBkAlyehOz\nO+AHVAAaAz8ppeK39NtqrRsjLpgXlFIptpnWWk/WWvtorX3KlCmTLUJnGotFfNeVKkmVwLQU+ebN\n0LYtvPGGNBXescO+8MA8jP8Mf1wLu1JvQOrdTpxdnek/tz/OBZxZMGABsVFpf2ELPxfOrh930XBI\nQ8rel4mKeQc+hqs7oc0cKN814+enRpOvJbywpA942PdNwmBISroKXCn1klIqM+ENwUBlm/eVrMds\nGQH8pYUTQBBQB0BrHWx9vgwsRlwyeZuFC0URe3pKx5pataQ+iW2zhf37patN+/ZSUXDKFPF7F00h\nkSQfERMZw8G5B6nbvy4Fi6Wdruxe2Z2HZz7MJf9LrH5tdZpzN368EW3RdPykY+YEu7hOakFXzuJa\nMW6loetWaJdCL1GDwU7sscDLAr5KqfnWqBJ7d4B8gZpKqWrWjclBwN9J5pwBOgMopcoCtYFApVQR\npVQx6/EiQDfgoJ3XzZ3ExMC770oX9/37Yc0aKFMGhg+X9PfZs2HoUHm9datsVB4/Ds88k2+KBVli\nU+joYiVgaQC3r99O031iS60Ha9H6zdbsnrSbg/NS/tO4cvQKflP98HnOB4+qHhkXOOaGNLEt0zbj\n59pD8dpSptRgyCTp7pxord9TSr2PKNERiJtjPvC71vpkGufFKqVeBFYDzsBUrfUhpdRo6/gvwKfA\ndKXUAUABb2utryilvIHF1s8KF+BPrfWqu7rTnOb33yVee9kycHaGLl0SKga++y4MGSJ1tN98U5Jy\n8klMdzxhp8P4peEv1BtQj14TeyVLSPGb7oe7lztVO1S1e81On3XizJYzLHt2GRWaVaBE9RJcOXKF\nk2tOErQ2iFMbT+Fa2JV277bLnNBXdkgbsXulXKohz2F3MSulVCNEgfcANgD3A2u01m85TryMkWuL\nWd26JQWjqlcX33ZSizomRizyhg3zVQNgWzZ9somNH24EoGLLigxcNPBOcajw4HC+8/qOtuPa0unT\njG00Xj9znV8a/0LBYgWxxFq4cf4GACVrlKRal2o0GdGEii2S7p3byf4P4dB4eDTUvmxLgyELyNJi\nVkqpMcAw4ArwG/Cm1jpGKeUEHAdyjQLPtXz/PVy8KNZ2Su4QV9d81/zXFq01/jP8qda5Gs2fb87i\nYYuZ4jOFAQsH4NXGi/2z9qMtmsZP2uE+scQllFsF3L3c6Te7H/+8+A+VWlXCu4s0S/Co6mHtAXoX\n1TZDtkj3FaO8DbkUe4JPSwL9tNanbQ9qrS1Kqd6OESsfce2atDLr0wfa3Jtfxc9sOUNoYCgdPu5A\n3X51KVWrFHMfnsuMjjPo+WNPif1u60XJGumkkp/7G3YMh4p9JS3dWkCqZs+a1DxZM/HcyIvSsDfi\nBDT4QOqCJK0WmBaWGHGhVH86YzdrMGQj9mxi/oMk2ACglCqulGoJoLU+4ijB8g2ffy71tz/7LKcl\nyXIu7b/E/tn7053nN92PAsUKUOeROgB4NvDkWd9n8e7szYrRK7hy9AqNnkyjz6C2wP6P4L+HpMJe\n0AxY2w5unkl5/pWdsKqZFJ0qVEnKn66oD6fny1r2EOonXWoctYFpMGQB9ijwSYBte+0I6zFDepw7\nBz/+KNEl992X09JkKftn7+e3lr+xeMhiTv93OtV50TejOTz/MPUG1EvUjqxQiUIMXj6YtuPaUq5x\nOeoPTKW+Rkw4/PcIHPxYEl56HYT2SyH8GKzygUubEs8/ORXWtpc+kN22Qfed0P5vqfa39TFY3QIu\nrEn/BkO2yrPZwDTkYuxR4Erb7HRaMyVN3q89fPSR+GE/+SSnJckyLLEWVr++msVDFlOhvoViJW+y\n9vXFpLYZfuSvI0RHRKcYHujk7ETnzzozat8oChZPIfY7PABWt5SO6c2+h/unWWtS94Xuu6R63/ou\nEPCTVPXzfQF2Pg2eD0APX6nVrRRU6gM9/eH+6RAVAhu6SQectAjZIuViC2dyA9RgyAbsUcSBSqmX\nSbC6nwcCHSdSPuHoUZg2DV5+Garkj1jfW1dusXDQQoLWBdF8ZE26t3sav033sfy3Bwn45XvqjB6T\nbJPWf7o/JbxL4NWiOAT8ANHX7buY5TYc+1Es505rk/eAdK8D3XZKR5w9L8GRL+DWOaj7pnSlSVpb\nxMkZvJ+Umtvru0LAj1B7TPLuOCAfuiFboJwpMGXI3dijwEcDPwDvIVv664BUa5MYrHz9tcR1jxuX\n05JkCRf9LzLv4XncuHCDh6b2pXHl1yC0IE2+mMH21TNY/9llajUaiVPLn+40fg07HUbQhiA6vOCK\nWlZdikJlhFItoe18KJJKAaoC7lKf5MAn0mS39RyomnpTBEBkqzEKtg+By5uh7APJ50SclB6Wxn1i\nyOXYk8hzGcmiNNhLaKi0OBs6VLIt8zinNp5idq/ZFCpZiBGbR1Cx1DrYsRGa/4JTybp0+noICx5b\nhP+MJTS50QHaLQI3T/Z/P01Kw9b4CkrdL5axRwYq+Smn9LNQlRM0/Aju+9D+jNXKj4BvMQianrIC\nD9kiz2YD05DLsScO3A14GqgP3KkQr7V+yoFy5W2mT4fISHgu7zd9DfYNZk6fOZTwLsGwtcMoWuI2\nLH8dSreCGs8CUHdAfSp8vZ2NywdwX7svcFnVDO1aAr8/u1K1kcZj0OLkLpCsJiPlBlwKS6/I03Og\n2Y/gmqTOTMgWiXYxPR8NuRx7NjH/AMohlQM3IUWpbjhSqDyNxQI//yzNFxrbV9cjt3L50GVm95hN\n4TLSUKFouaKw7y2IDrP2XZQ/H6UUXSZ0Ifx8DL6np4FrMc4eLkXopZI0fvUpxyvvzFDtSSkVe/av\n5GMhW6B0m5T94wZDLsKev9AaWuv3gZta6xnAg0BLx4qVSxk6NH2f9tq1UvPkhReyRyYHERoUyqxu\ns3Au6MywtcMoVqGYdGIPnAp1XwePxGGR1TpVo3q36mz+9gRRbffhd+xNXIu4Urd/6qVhc5QybaBo\ndXGj2BIVItEvnsZ9Ysj92KPAY6zPYUqpBoA74Ok4kXIpx4/DrFmSmLN9e+rzJk4Uv3f//tknWxZz\n48IN/ujyBzGRMQz9dyglvEtA3G3YNQqKVJXMxhToPKEzkdci2fTpFg4tOET9AfUpULRAinNzHKXA\nezhc2iC9LuO5sk2ejf/bkAewR4FPttYDfw8pB3sY+MKhUuVGZswAJyfpjDNypBSgSsrp07B8OTz7\nLBRMu6Z1biXyWiSzus3i5uWbDFk1BM8G1s/qI19JV5rmP4sPOQXKNylPg0EN2PF/O4i+EU2j4Wlk\nV+YGqg0DFAT9kXAsZIskAZU0bVgNuZ80Fbi1YFW41jpUa/2f1tpba+2ptf41m+TLHVgsMHMmdOsG\nkybBwYPwfykkgvxq/bGMzANRliemwLYhiQ5Z4izM6TuHq8evMmjpoIQqfjfPwsHx4DUQKvRMc9mO\nn3bEycUJj6oeVGmXy+Pfi3hB2Y7iRolPRLq8BUr53AmFNBhyM2kqcGvWpak2uGEDnD0rzRceekge\nH30EQUEJc27fht9+k246OZG4o7XENduTKGOJgf0fwKnZcD2hx7Tvz76c3XqWPlP6UK1TtYT5p+dI\nYk3jz9NdumSNkvSd2pcHJz2IcsoDjSi8h0NEoFjesbcgdI9xnxjyDPa4UNYqpd5QSlVWSpWMfzhc\nstzE9Ong7i6KG6S+iZMTvPhiguW2cCGEhOTM5uWlTfBva6kB4vt8+vPPLYGoi/L69DxAanKvf3c9\n1btXp+GQJLHap+dKUk1Rb7vEaTS0ETV65JH+nZX7gUtRCJwOV33lw80ocEMewR4F/hjwAvAfsMf6\nyIVdExxEeDgsWgSDB0tmJUDlyvDpp7BypShukNDBGjWk0052EeoPG3rBug5w6yyU6wJn5opFmRbH\nJkqdD8/2cGYeaM2qMauwxFh48OcHSdQ1L/w4hO6TuOn8iEsRcQ2dWQAXrP01S7fOWZkMBjtJV4Fr\nraul8LDPFMsPLFggSTnDhyc+/tJL0KSJ1DrZtAm2bYPnnxfLPIuIvhnN2e1nkxeKiggS//U/TeDq\nDmj8JfQ5LsWalDMc+Sb1RcMOweVNUHM0VBkM4QEcm/cvRxYdof0H7SXixJYzYqHjNSDL7ivX4f0k\nxN6AgO/Bvb4UyTIY8gD2ZGIOS+m41npm1ouTC5kxA2rXhhYtEh93cYHJk6FlS2nWUKhQciWfSeJi\n4tj7217+++Q/Ii5G0OjJRvT+pTcu+qq0+DrxKygXqPc21HtLsgYBXCpKZEXgVEktd0sh2vP4zxJl\n4f0UoIne8iorx22nTH1PWr+eguV5ep64FArnz1ZvgNxfUW/55mLcJ4Y8hD3mYnObRzvgI6CvA2XK\nPZw4IT0shw9POVXbx0d83jduiIvlLhsRa4vm4LyD/FzvZ1Y+v5IS1UvQ8pWW+M/wZ5rPeK5PawzH\nJ4H3CLG4G3+eoLzjqfumxGwH/JD8AjE3IGimuEPcSoNbGTauGsr1i4revzyIcwHnxPOvH4brB8Er\nn7pP4lFOkpkJRoEb8hT2FLN6yfa9UsoDmOswiXITM2eKS2To0NTnjB8vLpaxY+/qUifXnGTd2HVc\n2HsBzwaeDF42mJo9q6KOT6JqgRUs/qELU957hgGzu1GlRRpd1ovXlo25YxPFQnctljAW9AfERkBN\n2ei86H+RHYsq0rTjHrzqPggkiZ45PU+Um9ejd3VveYKao2UfoaLpEmjIO2TGYXsTqJburLyOxSLu\nk65doWIaRf2LF4cpU6TjfCY4v/s8M7vMZFa3Wdy6eouHZzzMKL9R1OrigdrQFfa+Qp1uxXh2Q1fc\nypRlZt+N7Jq4K9UGCoAo7pgwODE54ZjW4j4p2QxKtcASZ2H5qOUULlWILoM3JPi6beefmSfNEQqV\ny9S95SncPKHlFCjgkdOSGAx2Y48PfBkJrb2dgHrAfEcKlSvYuBHOnJGGxBkgOiKaU5tOEbg2kLCg\nMLzaeuHdxZuyDcsmiou+euwq699bz+EFhylcujDdv+uOz2gfXAq6wNXdsPkRuH0VWv0BVZ+gtFI8\ns6sVi4cs5p8X/8F/hn+yNHXlpGg8vDENhzSHsp3g6LdQ60VJSrn8H1w/BC1/RwObP9tM8M5gHpn1\nCIUqbpJ+kY2/THAVhe2XmiC1X73LH6TBYHAU9jR0+NrmdSxwWmt9zkHy5B5mzEgc+50GF/Ze4NiK\nYwSuCeTc9nNYYi24uLlQrGIxApYGAFC4TGG8O3tTrUs1gncFs+/3fbi4udD+g/a0fr11QkuxwJmw\na6RYvV23Qskmd67j5u7GoKWD2PLFFk78cwJLbOIGvTcv32Tx0MUE7wqm2xtv4bylB5yaJZ3Vj/8M\nBUoQ49mfFcOX4j/TnwaDGnDf4/dB0GNwfqV0YS/TShY7PU8iWirn3ZouBkN+R6X5VRxQSlUDLmit\no6zvCwFltdanHC9exvDx8dG7d2dBiPqNG1CuHAwZkpAenwqhQaH84P0DKCjftDzeXbzx7uqNVxsv\nXNxcCA8OJ3BtIEFrgwhcG0jExQicXJ1oNqoZ7d9rT9Gy1lrUlhjY+wYc+0HSu9vMl43GDGCJtbDm\nrTXs+L8dVHmgCgNG/UKRYmHQaR0srcp19zHM+6AWF/ZcoMPHHWj/Xnv5VhB9Hf7yhJrPQbPvxH2y\nrAYUrQGdVmf2p2gwGDKBUmqP1tquYjz2WOALANv4sjjrseaZkC1vsGgR3LplV1jgJf9LAAzfNDzF\n2h/FKxan8ZONafxkY7TWhBwOwc3djeKViidMCjsgDXlDNkPtV6DJV8l7OtqBk4sT3b/tTvmm5Vn2\n7DImH+/DY89PpILro5w6XJEFv5QmLvoag/4eRO0+tRNOLOAuNU7OLICm38K1vRJSV//dDMtgMBiy\nD3u0hIvWOjr+jdY6WimVS2uEZhHr1knVwfvvT3dqyOEQAMo1Tn+jTymFZ32b2OyIU9aaJLPA1R1a\nzYRqaUS82EnDIQ0pU68M8x6Zy9SPn6FRu334bepGiRpFGbR0EKVrp2DZew2Cc0ulJkjwMnByldZj\n9zjR0fJZ7mH2Ng25EHuiUEKUUnfivpVSDwFXHCdSLmDvXonxtqNNV8jhEIpXLk7BYhmoXhcVArvH\nwPJacHaBxG4/FJglyjue8k3L8+zukVRuWoi9632o0bEEz+x8JmXlDRI+51xI6p6cni8d2ZPGmN+D\njB0L9eunXD3YYMhp7FHgo4FxSqkzSqkzwNvAKMeKlYPcvAlHj0LTpnZNv3LkCmXq2dm4WGs48jX8\n7Q3Hf5LkkT7HockXDlGWRcoUYch/bzDi7+YMWvUybu5uqU92LSpK/OTvcOtM/q19kgEsFpg7F86f\nl0ZLeZ3gYHj9dUlbMOQP7KmFclJrfT8SPlhPa91aa33CnsWVUj2UUgFKqRNKqWSZLkopd6XUMqWU\nv1LqkFJqhL3nOgx/f/nPbdYs3anaogk5EkLpunZsNsZEwJYBsO9N2aTsdUjijh2cou5cwBWvPr1Q\nznZ8Vns9BpZoSbWvlH70TX5n9264cEFez5uX9ty8wJtvwrff5o97MQjp/lcrpf6nlPLQWkdorSOU\nUiWUUuPtOM8ZmAj0RJT/YKVU0gaJLwCHtdaNgA7AN0qpAnae6xj27pVnOyzw62euExsZm74FfuME\n/E5bY/0AACAASURBVHs/nFsMTb6G9kvBvU4WCJvFVOgFLsXk2bV4+vPzOUuWgLOzRJIuWSIl3/Mq\n+/bBnDnyesaMnJXFkHXY40LpqbUOi3+jtQ4FetlxXgvghNY60LoJOhdIatZpoJiS+qVFgWtIrLk9\n5zqGPXugbFmoUCHdqfEbmGkq8POrYFVziLwAHVZJQ2A7fOs5gksh6LoZmk+ya/rhw1JV99IlB8uV\nQyxZAg88AKNHw/XrsDoPR1SOGyelet54Q3LUbHuR5HZmz5bAMENy7FHgzkqpOzt01jhwe3bsKgJn\nbd6fsx6z5SegLnAeOACMsXYBsufceHlGKqV2K6V2h4SE2CFWOuzdK9a3nRuYAGXqpqDAtYZDE2Bj\nL2nd1cMXyne9e/kcTYlGUKisXVPHj4cPPpAqAh9+KKXT8wsBAXDkCDz8MHTuDKVK5V3Xw8aNsGqV\nKPGXXpI/7Zl5pJbo5MmSjjFgQMI3iKwkMlIMkKSPiIisv5YjsEeBzwbWKaWeVko9A6wBsupLWHfA\nD6gANAZ+Ukpl6Lu71nqy1tpHa+1Tpoydm4mpERkJhw7ZvYEZciSEImWLUKhkoeSDAT+A/zvSLKDb\nNru72eQV4uLEIu3RA3r1gk8+EUX+/fd529UQz9Kl8ty3L7i6Qr9+8PffeW8DUGt4+22oVEkaSHl5\nQadO4kaxWNI/PyeZO1e+/fTsCe3bw7Bh0jM8q1i6VPL1Unv4+mbdtRyFPZuYXwDjEUu5NrCaZGXr\nUiQYqGzzvpL1mC0jgL+0cAIIAurYeW7Wc+CAaCY7NjABrhxOJQIl7jYc+cKaUTlHur5kIVu35vxX\nyl274No1yXWaP1/eN2oEr7wCdeo4JmojKgq++Uas48wSGwsTJ4r7Jy2WLpV+HfHtTR97TKyylStT\nPycyEiZMkD+j7GLJErFMU0uoXrxYfjcff5zQUGr4cHGhbN6cdXJs3y4tYbOKlSulCGjbttL06u+/\n5e9rwADpn3I3WCzS0vbhh6XU/8SJ0lAr/jFxIhQuLB986SSqp8rx4/Jzvnr17mRNF611ug+gCfAV\ncArYALxoxzkuQCBSubAA4A/UTzJnEvCR9XVZREmXtufclB7NmjXTd8WkSVqD1qdOpTvVYrHoz4t/\nrpc/vzz54PEpWs9G6wtr7k6eVGjeXGsXF63373fI8nbx3ntaOzlpfe1a4uP//qt1rVpae3pqfeNG\n1l3v7FmtW7SQX0/58lqfOJHxNUJCtO7cWdZo3FjruLiU5124oLVSWn/8ccKxmBi5p0cfTX39ceNk\nbaW0HjpU66CgjMtoLzExWr/2mlwPtH7mGa2jopLPqV1b67p15XU8ERFaFyum9YgRdy+HxaL1jz/K\n3yNoPW3a3a+5aZPWbm5aN22qdVhYwvGQELmXYsW09vXN3NphYVr37SuyDh+udWRkyvO+/17mrFqV\nsfXPn9d69Gj5eRQunPHztdYa2K3t0MtaRExVAdcCPgSOAluAl5BCVnYtbF2jF3AMOAm8az02Ghht\nfV0B+Bfxfx8EhqR1bnqPu1bgzzyjdcmS8leZDuHB4fojPtI7f9qZeCAuVuu/a2m9sqld62SUa9dE\nQfD/7Z13eJTF1sB/QwiGAFKkSE9sQHqhQwigNEEQvKCIV1ARULnAvUqzIpYPlKuIBUUFvCCIoNhA\nhSBdEBIMAhEIapCikAAJJCGBZM/3x+wum2Q32TQgyfyeZ5/dnXdm3jPvvnvmvGdmziDSoYNrJVTa\nhIeLdO7s/Ni2bVq+6dNL5lybN4s0aCBSvbrI66/rn8jXV+TYMffriI0V8fERueYakfvu0/ItWeI8\n77x5+vju3TnTH31UpGpV5x3T3r0inp4iQ4aITJqkFZCnp8i4cSInT7ovpzs4dkT/+teljqN9+5zX\n5P33dfrnn+et46GHRKpVK14ne/687gRApF8/kchIrbT27St6nTExItdeK9KypfPrdvSo/h2vu04k\nLq5wdf/6q+7QPDx0p5Pf3zMjQ58nNNS9/1hysv4dvL218n7sMW0IFIWSUuAWYCNwk0Pa7+5WfCVe\nxVbgYWEiPXq4lfW3tb/JNKbJ7z/8nvPA4RXa+j78afFkccGKFfpXGzVKv7/7bqmcJl/++kuf+6WX\nXOe5805tKRVHeVks+qGocmWRm266pBh27NDK3M9PJCmp4HqWLtWKt3FjkZ9+0n/IoCCRG24QyczM\nm//223UHkfsPvnGjc8Wfna07szp1LrX36FGRhx/WyqJ6dZGXXy6Z/tyxI3K0dles0Ar5+utFtm4V\nSU/X7W3f3vl5N23Sbfnoo6LJ4fhE9Oyz+hocP66fUvz8tJVfWH79VaRuXZHmzXX9roiP1+1s3Nj9\np5zVq/X9WK+eyIYN7pVZtEi3b+nS/PO9847+7UFk6NCiPR06UlIK/E709L0jwPvArcAf7lZ8JV7F\nUuAZGdpkmjzZrezb39gu05gm5/5yMGEsFpFvW4t8eZO2xEuBMWO0QsjMFOneXaRmzaL39EVlwQJ9\n5/z8s+s8cXHaxTJhQtHOkZGhH4hApE8fkTNnch5fv14rsTZtRM6edV5HVpbIxIm6js6dc16nVat0\n+ttv5yxz9qxIlSoi//533vqys0UaNRIZMCBnus3SnT8/b5n9+0UGDtTHn3iieErcsSPasSPv8T17\nRG68Ud/Gffroc7pSVhaL7sC6dSu8HI5PRCtX5jy2Zo1+QiyseyYhQaRJE90BHDxYcP5ffhGpXVu3\nt6D7PypK/6ahoSKHD7svk62jv/FG5x29iMirr+rrfNttIrt2uV93fpSIArdngGrAvcDX6N145gI9\n3T3B5XwVS4HHxOjL8al7lvPXY76WGbVniMXxH/lXlLa+4+cVXY4CuOkm/bgqInLggL4x77mn1E7n\nlCFDtB+6IGX04INaPjeGFHKQnq4VC+jH0iwXfeFXX2kLt2tXXUZEuxeWLdPWb/Pmuo5HHsn7B7RY\nRLp00YrI0Y2wfHn+im/8eN0mm2/2xAmtSLp0cX09LBaRsWOlwKcWW5uuu07svu3cr86dRf7+23X5\n06dFevW61PHlx/Tp4taQz8WL2qp//nl9fg8PkZtvdu0qefppXe///pd/vTb+/lvf17Vq5XVb5ce2\nbfqpIzAw71iMje3bdZ6AAJFTp9yv24arjl7kkqvt7rtd36NFoUQVeI7MUBsYBawrTLnL9SqWAreZ\nUW4+/yzoskA+7PRhzsR1PUQ+u14ky8XISDH54w8t4htvXEqbNk2KNNhSVC5e1Fb/gw8WnPfPP7WV\nPHy4+/VfuKA7KKXcUwCLF+u87dppD5htfKBmTe3Gya8//vFHnfeFFy6lDRumFajjoJ+zMjbXw333\naYu3IH9sdvYl37szZZCdrRUk6HY891ze11tvubYEHcnK0vIVNEaQkCAuxyoyM0U++EAP+NWoIfbB\n2datRZ56Ku8TkSMXL17yhxd0XU6fFgkO1nl//LHApuVh7VrdobZvn9efv2fPJSv9+PHC1y3iuqNf\ntkxfjz593PtNCkOpKfCr/VUsBT5mjP7Xu/mM+0rdV+TLkV9eSjgVra3vfTOLLkMB2PoYR8snI0PP\n+vD1FUlLK7VT27H5TlescC//44/rG33PnoLzZmeL3Huvrn/uXPdlmjtX+yC7dNHKeNs21wo4NwMG\n6EGzxETdedSsqWcnuMJiEWnWTPvJo6K0rM884965Lly4NANi8eJL6SkpurMBkfvvv/Q0cTno3l27\nUmy3fXa29vHfcIOW54YbREaP1k8mhbFgjx3T/uaAANf3ZWqqHoj39NSul6Ly+efaXXfbbZdm4hw6\npP3kjRqJ/P57/uULwtZpv/ii/r56tZY5IqJ0/nNGgReFtm3ddgimnkyVaUyTH19zMBk2Dxb5tKbI\nhZSiy1AAQ4boGzJ3H/PDD/qXnDq11E5tZ+pUPajoOL0rP5KStIK8447881ks2tUBIv/3f8WX0132\n7dN//v/8R1tzIPLFF/mXeeIJfQ18ffWjv6upaM44f17fZh4e2l1y4ICeceHhITJ7dqlMXMqXjz7S\nbd64UT/FhYbq78HBWlEVR57vv9edd4sWekxh1apLg5sZGSI9e+pr764xkB8LF2q5Bw7Ufm5fX/0k\nVZwZMY7YOvqVK/U4RO4pjiWJUeCF5cIF/az/+ONuZU/YmCDTmCbx38brhJSDIksqifw8pWjnd4Ps\nbH1D3n+/8+PDh2ul4o6lK6LdMUWxeoKD9eNxYXjpJX2nbd7sOs/UqTrPpEmFl6m4PPCAfgwfMED/\nOQuyqnbuFLtPem0RpvqfPasHX6+5RiuFunV1J3wlSE3Vg5G1aun2+Prqp4OSmp66ZIme8njNNbp+\nT0/9pBQZKS4HfovK7Nm6Tm9v3SZnA71FxdbRg+6QSnpqqCNGgReW3bv1pfj4Y7ey73x3p0xjmiQf\ntnbBP40SWXqNSHrpTQexjbG68gsnJmpFEBxc8CN4cvKlR+R//Uv3X+5w9KguM7OQXqLUVP0426mT\nc4tu5kyxT4283BaoiLbYbArmzjsLzm+x6IVADz1U9HMmJenfqnXrwg/yljTjx+vZH3PmlLw/10Z6\nuu7sJk3S1mvVqlrhljTTp2s32Pr1JV/3uHF68PbPP0u+bkeMAi8stnlx+/e7lX31uNXycvWX9QyU\ntKMiS6uI/DSmaOd2E5uSy28wxjZiPnq06zwWi8jgwfqR3eZvjozUsykK4oMPdH53rXxHbItcr7tO\n+0Ztr7p1pVRG8guLbVXjwoXu5c/OLn5nk5V1ZTqs3Fgsl1+O0lyAVlr3kcVyeRbOFUaBF37n3PJI\nTAxUrw433wxAelI6p387TZN2zjdbSIpLom7LuiilYM/zgIDfpFIVMSpKb+3VsKHrPLffDpMmwSuv\nQNeucM89efPMnQvLl+s8EyfqQEEPP6x3kFu5Mv8wMKtX66BI/v6Fl/+hhyA5Gf78M++xRo203B4e\nha+3pHj2Wb3v5eDB7uWv5E4YuAK4ku115EpENy6J6+eK0rquSl2FkaDd1fRl4VVkC7xjRz2kbGXt\nlLXyvMfzcvp355NL/9v4v7Ly/pUiKftFlniI7BxXtPO6yfnzemm2O4tiLlzQzalePe+CiJgY7eu9\n/faclkRMjJ5Z4eXl2kWTmamnk40aVfR2GAyGgqEQFngp9oNlhOxsiI3NEUL23NFzSLaw7b/b8mTP\nSMng3LFz1PWrC7uf0hsBBzxVqiJu3aoj8d12W8F5PT11dLoqVWDIEF0OdKzuIUOgfn0dStTRAgoL\n09uHtW+vQ3befz8cPpyz3h9/hHPntJVvMBiuDowCP3AA0tNzKPDUEzqa+88f/kzaybQc2ZN+TQKg\nXuNkOPIZtHwcvOqXqohr10Llyjomsjs0a6aVdGws/Oc/er7Eww9DQoKOsVzXyRae9erBmjU66P+n\nn8Itt+iySbq5rF6tO4fu3UusWQaDoZgYBW7bA9PB+Zt2Io16fvXIyszipzk/5cie+Kt1Fx7LXLim\nnt4irZSJioIOHaBGDffL9Ount8+aO1f7wj/9FF56CTp1cl3G01PnOXhQ74Lyxht6k4YXX4Svv9Yd\nSGFkMBgMpYtR4DExULWqjuxuJfVEKk07NaXVwFbsfHsnmecubTGTGJeIxzWKWpW+hYCnwbN0Ndqp\nU7qPccd9kpuXX9ZukU8/1YOVEye6V65ZM/jwQ70xQffu8MwzsH+/cZ8YDFcbRoHv2qW3+qisJ+RY\nsi2kJ6ZTrUE1Ok3uREZyBjHzYuzZk+ISqdsomUo1msNNo0tdvB9+0C6QHkXYTtPTU884+c9/9B6I\nhR359/PTM1O2bYPHHtO+cYPBcPVQsacRWizw8885NNP50+cRi1CtfjUat22Mb3dftr+2nbZj21L5\nmsok7jlMkyZ/QtB08HBnb+fiERUF114LbdoUrXyTJnobsuLQvr1+VUQuXrzI0aNHybCNBhsMJYSX\nlxdNmjTB09OzyHVUbAV+6JCeWuEwgJl2Qg9aVm9QHYBOkzuxuNdi9ny8B/9/3Ezy0QuERFaC5vfm\nW3VsLLz+un7VqVN0EdeuhW7d7A8IhsvM0aNHqVGjBj4+Pnrev8FQAogIp06d4ujRo/j6+ha5noqt\nFs6f187ltm3tSbYZKNUa6I2Ib+hxA9eHXs/WV7bSoOYmEEW9zndApfxXC7z7rnZbHDyolXD16vmL\nsncvnDyZM+3UKb357H/+U/imGUqGjIwMo7wNJY5Siuuuu47ExMRi1VOxFXhwsNauDuS2wJVSdJ7S\nmRV3r2DLf48ATanXuVeBVW/Zonc037FD7369ahVc48Tjkp2tBwn/7/+c16MU9Cr4dIZSxChvQ2lQ\nEveVGcTMRW4LHKDVXa2ofUNNft3WlEqVoc7N1+Vbx+nTsG8fjBoF8+fDunUwdChkZeXMd+YM3HGH\nVt4PPQQbN+Z9/fKLfYW/wZAvt99+O8nJyfnmefbZZ4mKiipS/Rs2bKBfv3550mNjY1m9enWR6rwa\n6dixY77Hk5OTeeeddy6TNPlTsS1wJ6SdTKOSZyW8annZ0yp5VKLjmPqsmpRCHR8vPKrk7z758Uf9\n3rmznjudkgLjx+vFNB9+qGeD7NunLfPDh/Vc7dGjr8I4C4YygW1ZtTtKdPr06SV+/tjYWKKjo7nd\nyTzTrKwsKpeRARybrD/a/sAusCnwRx999DJJ5hpjgeci7UQa1epXy/N4E9LjONVrneP6MOcBrhzZ\nskVP4bPNHBk3Dp5/HhYu1P7szz/XszrOnYP162HMGKO8Da557bXXCAgIICAggNmzZwOQkJBAixYt\nuP/++wkICODIkSP4+PiQZF06+8ILL9CiRQs6d+7M0KFDmTVrFgAjRoxgxYoVAPj4+PDcc88RFhZG\nYGAg+/fvB2DHjh106NCB0NBQOnbsyIEDB1zKduHCBZ599lmWLVtGSEgIy5YtY9q0afzzn/+kU6dO\n/POf/2ThwoWMHTvWXqZfv35s2LABgDVr1tChQwfCwsIYPHgwqampec5x6NAhbrvtNoKDgwkLC+O3\n335DRJg4cSIBAQEEBgaybNkyAO655x5WrVplL2trb0JCAhEREYSFhREWFmZX0hs2bCAiIoL+/fvj\n5+cHQHXrgFVqaiq33nqr/fp8+eWXAEyZMoXffvuNkJAQJloXV7z66qu0adOGoKAgnnvuOQDS0tLo\n27cvwcHBBAQE2GUsScpG13gZSTuRZvd/O1I57WcefjUaz0EvFFjHli16YWfVqpfSnnlGu0xmz9Yr\nHNu21Yq8ceOSlN5QqkyYoKcXlSQhIfqmcEFMTAwLFizgp59+QkRo164dkZGR1K5dm/j4eD766CPa\n55rjuXPnTj777DN2797NxYsXCQsLI9xFmMm6deuya9cu3nnnHWbNmsUHH3xAy5Yt2bx5M5UrVyYq\nKoonn3ySzz77zGn5KlWqMH36dKKjo3nrrbcAmDZtGnFxcWzZsoWqVauycOFCp2WTkpJ48cUXiYqK\nolq1asycOZPXXnuNZ599Nke+YcOGMWXKFAYOHEhGRgYWi4XPP/+c2NhYdu/eTVJSEm3atKFLly7c\nfffdfPrpp/Tt25cLFy6wbt065s6di4iwdu1avLy8iI+PZ+jQoURHRwOwa9cu9u7dm2c2iJeXFytX\nruTaa68lKSmJ9u3b079/f2bMmMHevXuJtd4La9asIT4+nh07diAi9O/fn02bNpGYmEijRo3sHUpK\nSorL37moGAWei9QTqTn833bO7OLam1tCnap5jzmQkQE7d2qr2xGl9HxsT0+4cAFmzAAvL+d1GAw2\ntmzZwsCBA6lWTd+TgwYNYvPmzfTv35/mzZvnUd4AW7duZcCAAXh5eeHl5cUdd9zhsv5BgwYBEB4e\nzueffw5oRTN8+HDi4+NRSnHx4sVCy92/f3+qVs3/v7J9+3bi4uLoZI3vcOHCBTp06JAjz7lz5zh2\n7BgDBw4EtFIFfV2GDh2Kh4cHDRo0IDIykp07d9KnTx/Gjx9PZmYm3333HV26dKFq1aqkpKQwduxY\nYmNj8fDw4ODBg/ZztG3b1ulUPhHhySefZNOmTVSqVIljx45x4sSJPPnWrFnDmjVrCA0NBbTlHh8f\nT0REBI8//jiTJ0+mX79+REREFOIKuodR4LlIO5FG/YBcwakunoOzB6C5kwDbuYiJ0Qq6c+e8xypV\n0nG4DWWUfCzlK4FNqReHa6xTozw8PMiyjrI/88wzdOvWjZUrV5KQkEDXrl2LJVvlypWxWCz277ZF\nUSJCjx49WLp0aTFakBMvLy+6du3K999/z7Jly7jHGhT/9ddfp0GDBuzevRuLxWLvCHLL6sjHH39M\nYmIiMTExeHp64uPj43RBl4gwdepURo/OuzJ7165drF69mqeffppbb701z9NFcTE+cAdEhLSTaXkt\n8DO7AYE6+ex2YGXLFv1ewEC2weAWERERfPHFF6Snp5OWlsbKlSsLtOQ6derE119/TUZGBqmpqXzz\nzTeFOmdKSgqNrb49V+4PR2rUqMG5c+dcHvfx8SE2NhaLxcKRI0fYsWMHAO3bt2fr1q0cOnQI0D5j\nR8vYVneTJk344osvAMjMzCQ9PZ2IiAiWLVtGdnY2iYmJbNq0ibbW9Rx33303CxYsYPPmzfTu3dve\npoYNG1KpUiUWLVpEdna2W9ehfv36eHp6sn79eg5bYyznbm+vXr2YP3++3X9/7NgxTp48yfHjx/H2\n9ua+++5j4sSJ7LIFzitBjAJ3IDMlk+wL2Xl94KetsVBqh+UtlIstW6BlSx2e1WAoLmFhYYwYMYK2\nbdvSrl07Ro4caX9Ud0WbNm3o378/QUFB9OnTh8DAQGrWrOn2OSdNmsTUqVMJDQ21W+X50a1bN+Li\n4uyDmLnp1KkTvr6++Pn5MW7cOMKsK5/r1avHwoULGTp0KEFBQXTo0ME+kOrIokWLmDNnDkFBQXTs\n2JG///6bgQMHEhQURHBwMN27d+eVV17h+uuvB6Bnz55s3LiR2267jSpVqgDw6KOP8tFHHxEcHMz+\n/fvdenoZNmwY0dHRBAYG8r///Y+WLVsCcN1119GpUycCAgKYOHEiPXv25N5776VDhw4EBgbyj3/8\ng3PnzrFnzx7atm1LSEgIzz//PE8//XSB5ywsSm8AUT5o3bq12AYmikLSgSTebvk2AxcPJGhY0KUD\n24bDX2tg0F/5lrdYdKztu+6C998vshiGq4hff/2VVq1aXWkxCk1qairVq1cnPT2dLl26MG/ePLvi\nNFw9OLu/lFIxItLanfLGB+5A7lWYdk7vgjoF3/y//qpnmjjzfxsMl5NRo0YRFxdHRkYGw4cPN8q7\nnFKqClwp1Rt4A/AAPhCRGbmOTwSGOcjSCqgnIqeVUgnAOSAbyHK3RyoO9lWY9R0er7LS4WwcNB1Y\nYHmb/zu/TRMMhsvBkiVLrrQIhstAqSlwpZQH8DbQAzgK7FRKfSUicbY8IvIq8Ko1/x3Av0XktEM1\n3UQkqbRkzI3NAs8xiJn8C4jFbf93gwZ6FxuDwWAobUpzELMtcEhEfheRC8AnwIB88g8FSm4+URFI\nO5mGqqTwrut9KdE2gOnGDJStW7X7xKyqNBgMl4PSVOCNgSMO349a0/KglPIGegOOy70EiFJKxSil\nRrk6iVJqlFIqWikVXdzQjKknUvGu600lD4fLcnoXXFMXvPNfQn/smA79avzfBoPhcnG1TCO8A9ia\ny33SWURCgD7AY0opp3uyi8g8EWktIq3rFXPuXtoJZ3PAd2n3SQFm9datVqGNAjcYDJeJ0lTgx4Cm\nDt+bWNOccQ+53Ccicsz6fhJYiXbJlCq2QFZ2sjMgea/bC3iqVdOhLQyGy4Fj8KrqBe0YUkyOHz/O\nP/7xj1I9R2FwbLsjy5cvp1WrVnTr1q3QdV5NYWLdpTQV+E7gZqWUr1KqClpJf5U7k1KqJhAJfOmQ\nVk0pVcP2GegJ7C1FWQHtQskxhTB5L0iWW1MIt2zREQbLSORMg6FQNGrUyB7FsLRwZ9FQQXz44Ye8\n//77rF+/vtBli6rA3VnVWVqUmgIXkSxgLPA98CvwqYjsU0qNUUqNccg6EFgjImkOaQ2ALUqp3cAO\nYJWIfFdastrIs4zezQHMc+dg927jPjGUDnfeeSfh4eH4+/szb968QpVdvHixfTXg6NGj7cqmevXq\nPPXUUwQHB9O+fXt7kKbffvuN9u3bExgYyNNPP2237BMSEggICAD08vpBgwbRu3dvbr75ZiZNmmQ/\nn6vwsDExMURGRhIeHk6vXr346y+9KK5r165MmDCB1q1b88Ybb5CYmMhdd91FmzZtaNOmDVutvslT\np07Rs2dP/P39GTlyJM4WIE6fPp0tW7bw0EMPMXHiRLKzs5k4caI9zOt7770HuB8mNvcGFmPHjrWH\nFvDx8WHy5MmEhYWxfPlyfvvtN3r37k14eDgRERH2FaXLly8nICCA4OBgunRx6gUuHrZg8OXhFR4e\nLkUlMzVTpjFNNs/YfCnxp1Eiy2uLWCz5ll2zRgT0u6F8ERcXd+lL9HiRtZEl+4oeX6AMp06dEhGR\n9PR08ff3l6SkJBERad68uSQmJoqISLVq1ZzK3q9fP7lw4YKIiDzyyCPy0UcfiYgIIF999ZWIiEyc\nOFFeeOEFERHp27evLFmyRERE5s6da6/3jz/+EH9/fxERWbBggfj6+kpycrKcP39emjVrJn/++ack\nJiZKRESEpKamiojIjBkz5Pnnn5cLFy5Ihw4d5OTJkyIi8sknn8gDDzwgIiKRkZHyyCOP2GUeOnSo\nbN6s/4OHDx+Wli1biojIv/71L3n++edFROSbb74RwN52RyIjI2Xnzp0iIvLee+/Z25WRkSHh4eHy\n+++/y8WLFyUlJUVERBITE+XGG28Ui8WSo40iIuvXr5e+ffvavz/22GOyYMEC+7WfOXOm/Vj37t3l\n4MGDIiKyfft26datm4iIBAQEyNGjR0VE5MyZM05/o9wA0eKmzjMP/FacrsI87d4A5pYtOtKgiH5A\nTAAAFzlJREFUk8ieBkOxmTNnDitXrgTgyJEjxMfHc911+W/rB7Bu3TpiYmJoY91Z5Pz589SvryNt\nVqlSxW5dhoeHs9a6N+y2bdvsgaPuvfdennjiCad133rrrfb4Kn5+fhw+fJjk5GSn4WEPHDjA3r17\n6dGjB6BdDg0bNrTXdffdd9s/R0VFERdnXyrC2bNnSU1NZdOmTfZwt3379qV27doFtn/NmjX88ssv\ndtdPSkoK8fHxNGnSxK0wsQVhkzs1NZUff/yRwYMH249lZmYCOg7MiBEjGDJkiD10b0liFLiVPKsw\nsy/oRTwtxhdYdssWPXhZo0ZpSmi44oRf/nCyGzZsICoqim3btuHt7U3Xrl2dhjR1hogwfPhw/s/J\njtmenp72XaccQ8m6yzUOO3TbyouL8LB79uzB39+fbdu2Oa3LMbCUxWJh+/btOcK9FhUR4c0336RX\nrl3BFy5c6FaYWFdhcHPLbbFYqFWrln2DB0feffddfvrpJ1atWkV4eDgxMTFudb7ucrVMI7zi5FmF\neTYOLBcKXIF58SJs327834bSISUlhdq1a+Pt7c3+/fvZvn2722VvvfVWVqxYwcmTJwE4ffq0PSSq\nK9q3b2/ffeeTTz4plKyuwsO2aNGCxMREuwK/ePEi+/btc1pHz549efPNN+3fbUqxS5cu9vAA3377\nLWfOnClQnl69ejF37lz7hhQHDx4kLS3N7TCxzZs3Jy4ujszMTJKTk1m3bp3T81x77bX4+vqyfPly\nQHccu3fvBvSYQrt27Zg+fTr16tXjyJEjTusoKkaBW0k7mcuF4uYA5rp1kJ4ORYh5bzAUSO/evcnK\nyqJVq1ZMmTLF6Q48rvDz8+PFF1+kZ8+eBAUF0aNHD/vgoStmz57Na6+9RlBQEIcOHSpUGFpX4WGr\nVKnCihUrmDx5MsHBwYSEhLjcOHjOnDlER0cTFBSEn58f7777LgDPPfccmzZtwt/fn88//5xmzZoV\nKM/IkSPx8/MjLCyMgIAARo8eTVZWltthYps2bcqQIUMICAhgyJAh+Ybx/fjjj/nwww8JDg7G39/f\nPjA6ceJEAgMDCQgIoGPHjgQHB7t9Pd3BhJO1svGFjWx4dgNPZz6td53f+Rj8sQgGJ4Ny3c/17w87\ndsCff4I19LChHFFWw8kWlfT0dKpWrYpSik8++YSlS5falZGh5DHhZEuItBNpeNX20sobLoWQzUd5\nJyTAN9/AU08Z5W0oH8TExDB27FhEhFq1ajF//vwrLZIhHyq2Arc9fSiVcxWmJQuSd8NNY1yXBd57\nT09QGeUyUovBULaIiIiw+28NVz8VW4GfOwjrusP1t5F62I/q9axTk87uh+zz+fq/MzLggw+0C6Vp\nU5fZDAaDodSo2ArckgX1OsPxVaQdvZYGzWJg1ZtQ1TpHNZ8l9CtWQFISPPbYZZLVYDAYclGxZ6HU\n8ofOy2DQSdLSG1LtxiCoej2c3AReDaDGLS6Lvv023HILdO9+GeU1GAwGByq2BW4l64KFjJSLVG/V\nDbo/DVnn9RzwSh5O8+/aped+z56tV2AaDAbDlcCoHy7NAbcPYlauClVcz3995x3w9obhwy+HdIaK\nzpw5c2jVqhXDhg0rOHMuEhISrpr9MR0DYhWWhQsXcvz4cfv3kSNH5lhyX1ExChwXe2G64MwZWLIE\nhg2DWrVKWzKDAd555x3Wrl3Lxx9/XOiyRVXgVzJEqjNyK/APPvgAPz+/KyjR1YFR4DhZhZkPCxfC\n+fPw6KOlLJTBAIwZM4bff/+dPn368Prrr5OWlsaDDz5I27ZtCQ0NtS+ySUhIICIigrCwMMLCwuwr\nHadMmcLmzZsJCQnh9ddfZ+HChYwdO9Zef79+/diwYQOgQ8w+/vjjBAcHs23bNpchYB1xFi7VVRhX\nR/LLM3PmTAIDAwkODmbKlCmsWLGC6Ohohg0bRkhICOfPn6dr167YFu0tXbrUvtpx8uTJ9npchcwt\nTxgfOA6BrAqwwC0WmDsXOnQwO+9URL6b8B1/x/5donVeH3I9vWf3dnn83Xff5bvvvmP9+vXUrVuX\nJ598ku7duzN//nySk5Np27Ytt912G/Xr12ft2rV4eXkRHx/P0KFDiY6OZsaMGcyaNYtvvvkGwB7P\n2hlpaWm0a9eO//73v1y8eJHIyEi+/PJL6tWrx7Jly3jqqafyLOyZPn0633//PY0bNyY5ORnQmyrU\nrFmTnTt3kpmZSadOnejZs6c9eFZ+efbv38+XX37JTz/9hLe3N6dPn6ZOnTq89dZbzJo1i9atcy5Q\nPH78OJMnTyYmJobatWvTs2dPvvjiC+68807S0tJo3749L730EpMmTeL999/n6aefLuxPdFVjFDgO\nLpT6+SvwqCiIj4fnnrscUhkMeVmzZg1fffUVs2bNAnSEvD///JNGjRoxduxYYmNj8fDw4ODBg4Wu\n28PDg7vuugugwBCwNpyFS3UVxvWWWy7N6nKVJyoqigceeABvb28A6tSpk6/MO3fupGvXrtj2wx02\nbBibNm3izjvvdBkytzxhFDjaAves5kmVavmvh3/zTahXD66irQENl5H8LOXLhYjw2Wef0aJFixzp\n06ZNo0GDBuzevRuLxeIyHGt+IVK9vLzw8PCwnye/ELA2nIVLdRXGNSEhIUc7nOX5/vvv8z1fYShu\nyNyygPGBoy3wgvzf33+v456MGwcOoZANhstKr169ePPNN+1biv3888+AtmAbNmxIpUqVWLRokX0Q\nMneIVB8fH2JjY7FYLBw5coQdO3Y4PY+7IWCdhUt1FcY1dzuc5enRowcLFiwgPT0d0CFwnbXDRtu2\nbdm4cSNJSUlkZ2ezdOlSIiMj3byaZR9jgWPdjT4f/7dt0PKWW8DFBiUGw2XhmWeeYcKECQQFBWGx\nWPD19eWbb77h0Ucf5a677uJ///sfvXv3tm82EBQUhIeHB8HBwYwYMYIJEybg6+uLn58frVq1IizM\n+WpjWwjYcePGkZKSQlZWFhMmTMDf3z9HvokTJxIfH4+IcOuttxIcHExQUBAJCQmEhYUhItSrV8++\ny4+NkSNHOs3Tu3dvYmNjad26NVWqVOH222/n5ZdfZsSIEYwZM4aqVavmeCpo2LAhM2bMoFu3bogI\nffv2ZcCAASV81a9eTDhZYG7gXOrcVIe7V97t9PhTT8HLL8MPP0C3bsWV0lCWqGjhZA2Xl+KGkzUu\nFLQP3Lu+t9Nj+/bBK6/A/fcb5W0wGK4uKrwCt2RZSE9Kd+oDt1hgzBi49lqwDvobDAbDVUOF94Gn\nJ6WDOJ8DPn++3rB4/nw9+8RgMBiuJiq8BW5bxJPbAj95EiZNgi5dYMSIKyCYwWAwFECFV+D2QFa5\nLPDHH4fUVHj3Xb3rjsFgMFxtGAXuZBXmunWweDFMmQJmAoLBYLhaqfAKPLcLJSNDD1zedBM8+eSV\nlMxgyB8fHx+SkpIAHbipONx+++32WCauePbZZ4mKiipS/Rs2bLAva7+SuNOG3JEPr2Yq/CBm2ok0\nPKp4cE1Nvbzy5Zfh0CFYuxZcrEY2GMoNIoKIsHr16gLzTp8+/TJIVHpkZ2e71YaFCxcSEBBAo0aN\nLoNUxaPCW+C2VZhKKfbvhxkzdKzv22670pIZDJo777yT8PBw/P39mTdvXqHKvvbaawQEBBAQEMDs\n2bMBHZOkRYsW3H///QQEBHDkyJEc1vwLL7xAixYt6Ny5M0OHDrUHzhoxYoQ9+JSPjw/PPfccYWFh\nBAYGsn//fgB27NhBhw4dCA0NpWPHjhw4cCBf+bKzs3niiScICAggKCiIN998E4B169YRGhpKYGAg\nDz74IJmZmXz33XcMHjzYXtbRqn/kkUdo3bo1/v7+POcQbc7Hx4fJkycTFhbG8uXLc7Rh+vTptGnT\nhoCAAEaNGoWIOA1d6yqs7pw5c/Dz8yMoKIh77rmnUL9LiWHrgUvjBfQGDgCHgClOjk8EYq2vvUA2\nUMedss5e4eHhUlgW914s81rPE4tFJDJSpHZtkRMnCl2NoZwSFxdn/zx+vL5HSvI1fnzBMpw6dUpE\nRNLT08Xf31+SkpJERKR58+aSmJgoIiLVqlXLUy46OloCAgIkNTVVzp07J35+frJr1y75448/RCkl\n27Zts+e11bVjxw4JDg6W8+fPy9mzZ+Wmm26SV199VUREhg8fLsuXL7fnnzNnjoiIvP322/LQQw+J\niEhKSopcvHhRRETWrl0rgwYNEhGR9evXS9++ffPI+M4778hdd91lL3Pq1Ck5f/68NGnSRA4cOCAi\nIv/85z/l9ddfl4sXL0rTpk0lNTVVRETGjBkjixYtynGNsrKyJDIyUnbv3m2Xc+bMmfbzObbBVkZE\n5L777pOvvvpKREQiIyNl586dIiJy4cIF6dChg5w8eVJERD755BN54IEHRESkYcOGkpGRISIiZ86c\nydM2d3C8v2wA0eKmji01C1wp5QG8DfQB/IChSqkcW2iIyKsiEiIiIcBUYKOInHanbEmReiKVavWr\n8dFHsHEjzJwJ9euXxpkMhqIxZ84c+6YER44cIT4+3q1yW7ZsYeDAgVSrVo3q1aszaNAgNm/eDEDz\n5s1p3759njJbt25lwIABeHl5UaNGDe644w6X9dvCx4aHh9sjDaakpDB48GACAgL497//7TQAliNR\nUVGMHj2aypW1N7dOnTocOHAAX19fe/jZ4cOHs2nTJipXrkzv3r35+uuvycrKYtWqVfa4J59++ilh\nYWGEhoayb9++HNut3X238xAZ69evp127dgQGBvLDDz84ldUxrG5ISAgvvvgiR48eBXScmWHDhrF4\n8WK7/Jeb0jxrW+CQiPwOoJT6BBgAuNrIbiiwtIhli0zaiTS8WzbjiSegUyd46KGSPoOhvGD1QFxW\nNmzYQFRUFNu2bcPb25uuXbvmCAFbVGzBrorDNdawnI6hWp955hm6devGypUrSUhIoGvXrsU+jyP3\n3HMPb731FnXq1KF169bUqFGDP/74g1mzZrFz505q167NiBEjclwjZ23NyMjg0UcfJTo6mqZNmzJt\n2jSn11XyCau7atUqNm3axNdff81LL73Enj17LrsiL00feGPgiMP3o9a0PCilvNEuk8+KUHaUUipa\nKRWdmJhYKAHFIqSdTGPRnmBSUuC998wu84ari5SUFGrXro23tzf79+9n+/btbpeNiIjgiy++ID09\nnbS0NFauXElERES+ZTp16sTXX39NRkYGqamp9p18CiNv48b6r5rf7j82evTowXvvvWfvAE6fPk2L\nFi1ISEjg0KFDACxatMgeIjYyMpJdu3bx/vvv2/3OZ8+epVq1atSsWZMTJ07w7bffFnhem7KuW7cu\nqampdr845Axd6yqsri0cb7du3Zg5cyYpKSmkpqa6c4lKlKtFXd0BbBWR04UtKCLzRKS1iLSuV8j1\n7ufPnOe3rKas3duIiRMhV6RMg+GK07t3b7KysmjVqhVTpkxx6vZwRVhYGCNGjKBt27a0a9eOkSNH\nEhoamm+ZNm3a0L9/f4KCgujTpw+BgYHUrFnT7XNOmjSJqVOnEhoa6tYGCiNHjqRZs2YEBQURHBzM\nkiVL8PLyYsGCBQwePJjAwEAqVarEmDFjAG3t9+vXj2+//dY+gBkcHExoaCgtW7bk3nvvpVOnTgWe\nt1atWjz88MMEBATQq1cv2rRpYz9mC10bEhJCdnY2K1asYPLkyQQHBxMSEsKPP/5IdnY29913H4GB\ngYSGhjJu3DhqXYFdzkstnKxSqgMwTUR6Wb9PBRCR/3OSdyWwXESWFLasI4UNJ3t0dyIhIYqq9Wtw\n4I9r8HYekNBQgamI4WRTU1OpXr066enpdOnShXnz5rmMG24oHsUNJ1uaDpudwM1KKV/gGHAPcG/u\nTEqpmkAkcF9hyxaXTT9YOENdZv37JN7eeff7MxgqIqNGjSIuLo6MjAyGDx9ulPdVTKkpcBHJUkqN\nBb4HPID5IrJPKTXGevxda9aBwBoRSSuobEnLeO+/G9Du9ov43GCmnRgMNpYsWXKlRTC4SakOmYrI\namB1rrR3c31fCCx0p2xpcGMLz9I+hcFgMJQKV8sgpsFw1VJa40SGik1J3FdGgRsM+eDl5cWpU6eM\nEjeUKCLCqVOn8CpmwKUKH8zKYMiPJk2acPToUQq7xsBgKAgvLy+aNGlSrDqMAjcY8sHT0xNfX98r\nLYbB4BTjQjEYDIYyilHgBoPBUEYxCtxgMBjKKKW2lP5KoJRKBA4XoWhdIKmExbmaKO/tA9PG8oJp\nIzQXEbcCO5UrBV5UlFLR7sYeKIuU9/aBaWN5wbSxcBgXisFgMJRRjAI3GAyGMopR4JrC7RRb9ijv\n7QPTxvKCaWMhMD5wg8FgKKMYC9xgMBjKKBVagSuleiulDiilDimlplxpeUoCpdR8pdRJpdReh7Q6\nSqm1Sql463vtKyljcVFKNVVKrVdKxSml9imlxlvTy007lVJeSqkdSqnd1jY+b00vN20EUEp5KKV+\nVkp9Y/1ertoHoJRKUErtUUrFKqWirWkl0s4Kq8CVUh7A20AfwA8YqpTyu7JSlQgL0RtEOzIFWCci\nNwPrrN/LMlnA4yLiB7QHHrP+duWpnZlAdxEJBkKA3kqp9pSvNgKMB351+F7e2mejm4iEOEwfLJF2\nVlgFDrQFDonI7yJyAfgEGHCFZSo2IrIJyL059ADgI+vnj4A7L6tQJYyI/CUiu6yfz6EVQGPKUTtF\nY9vm3NP6EspRG5VSTYC+wAcOyeWmfQVQIu2syAq8MXDE4ftRa1p5pIGI/GX9/DfQ4EoKU5IopXyA\nUOAnylk7re6FWOAksFZEylsbZwOTAItDWnlqnw0BopRSMUqpUda0EmmnCSdbwRARUUqVi6lHSqnq\nwGfABBE5q5SyHysP7RSRbCBEKVULWKmUCsh1vMy2USnVDzgpIjFKqa7O8pTl9uWis4gcU0rVB9Yq\npfY7HixOOyuyBX4MaOrwvYk1rTxyQinVEMD6fvIKy1NslFKeaOX9sYh8bk0ud+0EEJFkYD16bKO8\ntLET0F8plYB2X3ZXSi2m/LTPjogcs76fBFai3bcl0s6KrMB3AjcrpXyVUlWAe4CvrrBMpcVXwHDr\n5+HAl1dQlmKjtKn9IfCriLzmcKjctFMpVc9qeaOUqgr0APZTTtooIlNFpImI+KD/ez+IyH2Uk/bZ\nUEpVU0rVsH0GegJ7KaF2VuiFPEqp29F+OA9gvoi8dIVFKjZKqaVAV3TEsxPAc8AXwKdAM3S0xiEi\nknugs8yglOoMbAb2cMl/+iTaD14u2qmUCkIPbnmgDa1PRWS6Uuo6ykkbbVhdKE+ISL/y1j6l1A1o\nqxu0y3qJiLxUUu2s0ArcYDAYyjIV2YViMBgMZRqjwA0Gg6GMYhS4wWAwlFGMAjcYDIYyilHgBoPB\nUEYxCtxQIVFKZVujw9leJRY0SSnl4xgN0mAoLcxSekNF5byIhFxpIQyG4mAscIPBAWvs5les8Zt3\nKKVusqb7KKV+UEr9opRap5RqZk1voJRaaY3bvVsp1dFalYdS6n1rLO811tWUBkOJYhS4oaJSNZcL\n5W6HYykiEgi8hV6pC/Am8JGIBAEfA3Os6XOAjda43WHAPmv6zcDbIuIPJAN3lXJ7DBUQsxLTUCFR\nSqWKSHUn6QnojRR+twbM+ltErlNKJQENReSiNf0vEamrlEoEmohIpkMdPujwrzdbv08GPEXkxdJv\nmaEiYSxwgyEv4uJzYch0+JyNGW8ylAJGgRsMebnb4X2b9fOP6Kh5AMPQwbRAb4f1CNg3YKh5uYQ0\nGIxVYKioVLXudmPjOxGxTSWsrZT6BW1FD7Wm/QtYoJSaCCQCD1jTxwPzlFIPoS3tR4C/MBguA8YH\nbjA4YPWBtxaRpCsti8FQEMaFYjAYDGUUY4EbDAZDGcVY4AaDwVBGMQrcYDAYyihGgRsMBkMZxShw\ng8FgKKMYBW4wGAxlFKPADQaDoYzy//NGKc3NqQyrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21ed66e7cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10*.55,7*.55))\n",
    "plt.title('Hidden layers: (100)')\n",
    "#plt.plot(trace_nl_wide1.history['val_acc'],label='true features', color=\"green\")\n",
    "plt.plot(trace_nl_wide2.history['val_acc'],label='original true covariates', color=\"red\")\n",
    "plt.plot(trace_nl_wide3.history['val_acc'],label='all engineered features', color=\"orange\")\n",
    "plt.plot(trace_nl_wide4.history['val_acc'],label='feature selection', color=\"purple\")\n",
    "plt.plot(trace_nl_wide5.history['val_acc'],label='all original covariates', color=\"blue\")\n",
    "plt.legend(loc=4)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The differences are particularly notable for a single wide hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

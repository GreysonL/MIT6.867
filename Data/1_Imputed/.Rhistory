summary(glm(as.numeric(fam_founders_binary2[,i])~ fam_founders_binary2$rs11655198_T+
fam_founders_binary2$PC1+fam_founders_binary2$PC2,
family=binomial(link='logit')))$coefficients[2,c(1,4)])
}
rownames(summary.table.bin) = colnames(fam_founders_binary2[,c(2,4:(ncol(fam_founders_binary2)-2))])
summary.table.bin2 = summary.table.bin[order(summary.table.bin[,"Pr(>|z|)"]),]
kable(summary.table.bin2[1:10,])
## Cont vars
summary.table.cont = summary(lm(as.numeric(fam_founders_cont2[,4])~ fam_founders_cont2$rs11655198_T+
fam_founders_cont2$PC1+fam_founders_cont2$PC2))$coefficients[2,c(1,4)]
for(i in 5:(ncol(fam_founders_cont2)-2)){
summary.table.cont = rbind(summary.table.cont,
summary(glm(as.numeric(fam_founders_cont2[,i])~ fam_founders_cont2$rs11655198_T+
fam_founders_cont2$PC1+fam_founders_cont2$PC2))$coefficients[2,c(1,4)])
}
rownames(summary.table.cont) = colnames(fam_founders_cont2[,4:(ncol(fam_founders_cont2)-2)])
# Non-missing counts
count=c()
for(i in rownames(summary.table.cont)){
count = c(count,length(which(!is.na(fam_founders_cont2[,i]))))
}
summary.table.cont = cbind(summary.table.cont,"N, non-missing" = count)
summary.table.cont = summary.table.cont[order(summary.table.cont[,"Pr(>|t|)"]),]
kable(summary.table.cont[1:10,]) #sample sizes (non-missing): 4
SL.library = c("SL.glm", "SL.glmnet", "SL.randomForest", "SL.step.interaction",
"SL.gam", "SL.rpart", "SL.kernelKnn", "SL.ksvm", "SL.nnet")
### Covariates of interest
data = fam_founders_cont2[,c("fev1_fvc_pred", "rs11655198_T", "PC1", "PC2")] # Completers analysis for now
data_complete = data[!is.na(data$fev1_fvc_pred),] #Y, A, X1, X2
### Linear model
fit_log = glm(fev1_fvc_pred ~ rs11655198_T + PC1 + PC2, family="gaussian",data = data_complete)
### Summary table
summary.table.causal.estimators = c(coef(fit_log)[2], confint(fit_log)[2,], summary(fit_log)$coefficients[2,4])
names(summary.table.causal.estimators)[4] = "P-value"
summary.table.causal.estimators = as.data.frame(t(summary.table.causal.estimators))
rownames(summary.table.causal.estimators) = "OLS"
temp <- ipwpoint(exposure = rs11655198_T,family = "multinomial", numerator = ~ 1, denominator = ~ PC1 + PC2,data = data_complete)#, truc=0.025)
data_complete$ipweights = temp$ipw.weights
msm <- (svyglm(fev1_fvc_pred ~ rs11655198_T, design = svydesign(~ 1, weights = ~ ipweights, data = data_complete))) #Robust SE estimate
summary.table.causal.estimators = rbind(summary.table.causal.estimators, "IPW, multinomial" = c(coef(msm)[2], confint(msm)[2,], summary(msm)$coefficients[2,4]))
data_complete_binary = data_complete #Y=fev1_fvc_pred, A=rs11655198_T, X1=PC1, X2=PC2
data_complete_binary$rs11655198_T = ifelse(data_complete$rs11655198_T >0, 1, 0)
### IPW
temp2 <- ipwpoint(exposure = rs11655198_T,family = "binomial", link="logit", numerator = ~ 1, denominator = ~ PC1,data = data_complete_binary)#, truc=0.025) #One PC because otherwise model doesn't fit
data_complete_binary$ipweights2 = temp2$ipw.weights
msm2 <- (svyglm(fev1_fvc_pred ~ rs11655198_T, design = svydesign(~ 1, weights = ~ ipweights2, data = data_complete_binary))) #Robust SE estimate
summary.table.causal.estimators = rbind(summary.table.causal.estimators, "IPW, binary" = c(coef(msm2)[2], confint(msm2)[2,], summary(msm2)$coefficients[2,4]))
ipwSL = SuperLearner(Y=data_complete_binary$rs11655198_T, X=data_complete_binary[,3:4], #Y=A,X=X's
SL.library=SL.library, family="binomial",method="method.NNLS",
verbose=F)
predictions = cbind(ipwSL$SL.predict,ipwSL$library.predict)
data_complete_binary$pi_1 <- ipwSL$SL.predict
data_complete_binary$ipwSLweight[data_complete_binary$rs11655198_T==1] <- 1/data_complete_binary$pi_1[data_complete_binary$rs11655198_T==1]
data_complete_binary$ipwSLweight[data_complete_binary$rs11655198_T==0] <- 1/(1-data_complete_binary$pi_1[data_complete_binary$rs11655198_T==0])
# Use truncated propensity scores for generating estimates - ensure weights btw 1-40
data_complete_binary$ipwSLweight.trunc <- ifelse(1/data_complete_binary$ipwSLweight<0.025,1/0.025,
ifelse(1/data_complete_binary$ipwSLweight>0.975,1/0.975,
data_complete_binary$ipwSLweight))
ATE.ipw.SL <- weighted.mean(data_complete_binary$fev1_fvc_pred[data_complete_binary$rs11655198_T==1],
w=data_complete_binary$ipwSLweight.trunc[data_complete_binary$rs11655198_T==1])-
weighted.mean(data_complete_binary$fev1_fvc_pred[data_complete_binary$rs11655198_T==0],
w=data_complete_binary$ipwSLweight.trunc[data_complete_binary$rs11655198_T==0])
summary.table.causal.estimators = rbind(summary.table.causal.estimators, "SL IPW, binary" = c(ATE.ipw.SL, NA, NA, NA))
### G-comp: Super Learning
n = nrow(data_complete_binary)
covars <- rbind(cbind(rs11655198_T=1, data_complete_binary[,c(3:4)]), #A=1,X's
cbind(rs11655198_T=0, data_complete_binary[,c(3:4)])) #A=0,X's
gcompSL <- SuperLearner(Y=data_complete_binary$fev1_fvc_pred, X=data_complete_binary[,2:4], #Y=Y,X=A,X's
SL.library=SL.library, family="gaussian",method="method.NNLS", newX=covars, verbose=F)
data_complete_binary$Y1.pred = gcompSL$SL.predict[1:n]
data_complete_binary$Y0.pred = gcompSL$SL.predict[(n+1):(2*n)]
ATE.gcomp.SL <- mean(data_complete_binary$Y1.pred - data_complete_binary$Y0.pred)
summary.table.causal.estimators = rbind(summary.table.causal.estimators, "SL g-comp, binary" = c(ATE.gcomp.SL, NA, NA, NA))
### TMLE approach: Super Learning
tmleSL <- tmle(data_complete_binary$fev1_fvc_pred, data_complete_binary$rs11655198_T, data_complete_binary[,3:4], #Y,A,X's
Q.SL.library = SL.library, g.SL.library = SL.library)
ATE.tmle.SL <- tmleSL$estimates$ATE$psi
summary.table.causal.estimators = rbind(summary.table.causal.estimators, "SL TMLE, binary" = c(ATE.tmle.SL, tmleSL$estimates$ATE$CI, tmleSL$estimates$ATE$pvalue))
### TMLE approach: Super Learning - just glm
tmleSL2 <- tmle(data_complete_binary$fev1_fvc_pred, data_complete_binary$rs11655198_T, data_complete_binary[,3:4], #Y,A,X's
Q.SL.library = "SL.glm", g.SL.library = "SL.glm")
ATE.tmle.SL2 <- tmleSL2$estimates$ATE$psi
### Summary table
summary.table.causal.estimators.converted = summary.table.causal.estimators
summary.table.causal.estimators.converted[,c(1:3)] = exp(summary.table.causal.estimators[,c(1:3)])
colnames(summary.table.causal.estimators.converted)[1] = "OR"
kable(round(summary.table.causal.estimators.converted,2))
summary.table.causal.estimators.converted[c(2:6),c(1:3)] = exp(summary.table.causal.estimators[c(2:6),c(1:3)])
colnames(summary.table.causal.estimators.converted)[1] = "OR"
kable(round(summary.table.causal.estimators.converted,2))
summary.table.causal.estimators.converted = summary.table.causal.estimators
summary.table.causal.estimators.converted[c(2:6),c(1:3)] = exp(summary.table.causal.estimators[c(2:6),c(1:3)])
colnames(summary.table.causal.estimators.converted)[1] = "OR"
kable(round(summary.table.causal.estimators.converted,2))
summary.table.causal.estimators.converted
kable(summary.table.causal.estimators.converted)
table(fam_founders_binary$G14I0EV)
table(fam_founders_binary$G14I0EV, fam_founders_binary$rs11655198_T)
data_complete_binary$ipwSLweight.trunc
View(data_complete_binary)
setwd("C:/Users/Irina/Google Drive/Harvard classwork/MIT 6.867/Final project/Data")
data = read.csv("1_Imputed/trainset_impute50000.csv",header=T)
cat_varname=c('ps_ind_02_cat','ps_ind_04_cat','ps_ind_05_cat','ps_ind_06_bin','ps_ind_07_bin',
'ps_ind_08_bin','ps_ind_09_bin','ps_ind_10_bin','ps_ind_11_bin','ps_ind_12_bin',
'ps_ind_13_bin','ps_ind_16_bin','ps_ind_17_bin','ps_ind_18_bin','ps_car_01_cat',
'ps_car_02_cat','ps_car_03_cat','ps_car_04_cat','ps_car_05_cat','ps_car_06_cat',
'ps_car_07_cat','ps_car_08_cat','ps_car_09_cat','ps_car_10_cat','ps_car_11_cat',
'ps_calc_15_bin','ps_calc_16_bin','ps_calc_17_bin','ps_calc_18_bin','ps_calc_19_bin',
'ps_calc_20_bin')
for (i in 1:length(cat_varname)){
one_hot=c()
drop = cat_varname[i]
cat_var=data[,drop]
cat_range=unique(cat_var)
if (length(cat_range)==2){
data[cat_var==cat_range[1],drop]=1
data[cat_var==cat_range[2],drop]=-1
}
else{
data=data[,!(names(data) %in% drop)]
for (j in 1:length(cat_range)){
one_hot=cbind(one_hot,as.numeric(cat_var==cat_range[j]))
}
one_hot=data.frame(one_hot)
for (j in 1:length(cat_range)){
colnames(one_hot)[j]=paste0(drop,"_",cat_range[j])
}
data=cbind(data,one_hot)
}
}
write.csv(data,"trainset_impute_onehot.csv",row.names = F)
## real data - testset
data = read.csv("testset_impute50000.csv",header=T)
cat_varname=c('ps_ind_02_cat','ps_ind_04_cat','ps_ind_05_cat','ps_ind_06_bin','ps_ind_07_bin',
'ps_ind_08_bin','ps_ind_09_bin','ps_ind_10_bin','ps_ind_11_bin','ps_ind_12_bin',
'ps_ind_13_bin','ps_ind_16_bin','ps_ind_17_bin','ps_ind_18_bin','ps_car_01_cat',
'ps_car_02_cat','ps_car_03_cat','ps_car_04_cat','ps_car_05_cat','ps_car_06_cat',
'ps_car_07_cat','ps_car_08_cat','ps_car_09_cat','ps_car_10_cat','ps_car_11_cat',
'ps_calc_15_bin','ps_calc_16_bin','ps_calc_17_bin','ps_calc_18_bin','ps_calc_19_bin',
'ps_calc_20_bin')
for (i in 1:length(cat_varname)){
one_hot=c()
drop = cat_varname[i]
cat_var=data[,drop]
cat_range=unique(cat_var)
if (length(cat_range)==2){
data[cat_var==cat_range[1],drop]=1
data[cat_var==cat_range[2],drop]=-1
}
else{
data=data[,!(names(data) %in% drop)]
for (j in 1:length(cat_range)){
one_hot=cbind(one_hot,as.numeric(cat_var==cat_range[j]))
}
one_hot=data.frame(one_hot)
for (j in 1:length(cat_range)){
colnames(one_hot)[j]=paste0(drop,"_",cat_range[j])
}
data=cbind(data,one_hot)
}
}
colnames(data)[1]='id'
write.csv(data,"testset_impute_onehot.csv",row.names = F)
############################################################
train = read.csv("trainset_impute_onehot.csv",header=T)
### Add interactions
cont_inter_name=c("ps_calc_05","ps_calc_06","ps_calc_07","ps_calc_08","ps_calc_09","ps_calc_10",
"ps_calc_11","ps_calc_12","ps_calc_13","ps_calc_14","ps_car_13","ps_reg_01",
"ps_reg_02","ps_reg_03")
cont_inter_var=c()
for(i in 1:(length(cont_inter_name)-1)){
for(j in (i+1):length(cont_inter_name)){
a=train[,cont_inter_name[i]]
b=train[,cont_inter_name[j]]
d=c()
for (k in 1:length(a)){
d[k]=a[k]*b[k]
}
cont_inter_var=cbind(cont_inter_var,d)
t=ncol(cont_inter_var)
colnames(cont_inter_var)[t] = paste0(cont_inter_name[i],'*',cont_inter_name[j])
}
}
std_inter = scale(cont_inter_var)
std_inter = as.data.frame(cont_inter_var)
cont_name = c("ps_ind_01","ps_ind_03","ps_ind_14","ps_ind_15","ps_reg_01","ps_reg_02",
"ps_reg_03","ps_car_11","ps_car_12","ps_car_13","ps_car_14","ps_car_15",
"ps_calc_01","ps_calc_02","ps_calc_03","ps_calc_04","ps_calc_05","ps_calc_06",
"ps_calc_07","ps_calc_08","ps_calc_09","ps_calc_10","ps_calc_11","ps_calc_12",
"ps_calc_13","ps_calc_14")
for (i in 1:length(cont_name)){
train[,cont_name[i]]=scale(train[,cont_name[i]])
}
train=cbind(train,std_inter)
### Add count of missing values
train$na_count <- apply(train, 1, function(x) sum(is.na(x)))
head(train$na_count)
train$na_count[1:40]
train$na_count[1:100]
train$na_count[1:500]
raw_data = read.csv("train.csv",header=T)
head(train[,1:10])
head(raw_data[,1:10])
train = train[order(train$id),]
raw_data = raw_data[order(raw_data$id),]
head(raw_data[,1:10])
head(train[,1:10])
train$na_count <- apply(raw_data, 1, function(x) sum(is.na(x)))
### Add powers and logarithms
train2 = train
for(i in cont_inter_name){
train2[,paste0(i,"sq")] = train2[,i]^2
}
View(train2)
head(train2)
train2 = train
for(i in cont_inter_name){
train2[,paste0(i,"_sq")] = train2[,i]^2
}
for(i in cont_inter_name){
train2[,paste0(i,"_cube")] = train2[,i]^3
}
for(i in cont_inter_name){
train2[,paste0(i,"_log")] = log(train2[,i]+0.01)
}
warnings()
train2[,"ps_ind_01"]
train2$ps_ind_14
train2$ps_ind_15
train = read.csv("trainset_impute_onehot.csv",header=T)
############################################################
### Add interactions
cont_inter_name=c("ps_calc_05","ps_calc_06","ps_calc_07","ps_calc_08","ps_calc_09","ps_calc_10",
"ps_calc_11","ps_calc_12","ps_calc_13","ps_calc_14","ps_car_13","ps_reg_01",
"ps_reg_02","ps_reg_03")
cont_inter_var=c()
for(i in 1:(length(cont_inter_name)-1)){
for(j in (i+1):length(cont_inter_name)){
a=train[,cont_inter_name[i]]
b=train[,cont_inter_name[j]]
d=c()
for (k in 1:length(a)){
d[k]=a[k]*b[k]
}
cont_inter_var=cbind(cont_inter_var,d)
t=ncol(cont_inter_var)
colnames(cont_inter_var)[t] = paste0(cont_inter_name[i],'*',cont_inter_name[j])
}
}
View(train)
head(train)
head(train[,cont_inter_name])
### Add count of missing values
raw_data = read.csv("train.csv",header=T)
train = train[order(train$id),]
raw_data = raw_data[order(raw_data$id),]
train$na_count <- apply(raw_data, 1, function(x) sum(is.na(x)))
train2 = train
for(i in cont_inter_name){
train2[,paste0(i,"_sq")] = train2[,i]^2
}
for(i in cont_inter_name){
train2[,paste0(i,"_cube")] = train2[,i]^3
}
for(i in cont_inter_name){
train2[,paste0(i,"_log")] = log(train2[,i]+0.01)
}
head(train[,cat_varname])
cat_varname
cat_varname=c('ps_ind_02_cat','ps_ind_04_cat','ps_ind_05_cat','ps_ind_06_bin','ps_ind_07_bin',
'ps_ind_08_bin','ps_ind_09_bin','ps_ind_10_bin','ps_ind_11_bin','ps_ind_12_bin',
'ps_ind_13_bin','ps_ind_16_bin','ps_ind_17_bin','ps_ind_18_bin','ps_car_01_cat',
'ps_car_02_cat','ps_car_03_cat','ps_car_04_cat','ps_car_05_cat','ps_car_06_cat',
'ps_car_07_cat','ps_car_08_cat','ps_car_09_cat','ps_car_10_cat','ps_car_11_cat',
'ps_calc_15_bin','ps_calc_16_bin','ps_calc_17_bin','ps_calc_18_bin','ps_calc_19_bin',
'ps_calc_20_bin')
head(train[,cat_varname])
head(train[,c('ps_ind_02_cat','ps_ind_04_cat','ps_ind_05_cat','ps_ind_06_bin','ps_ind_07_bin',
'ps_ind_08_bin','ps_ind_09_bin','ps_ind_10_bin','ps_ind_11_bin','ps_ind_12_bin',
'ps_ind_13_bin','ps_ind_16_bin','ps_ind_17_bin','ps_ind_18_bin','ps_car_01_cat',
'ps_car_02_cat','ps_car_03_cat')])
head(train[,c('ps_ind_02_cat','ps_ind_04_cat')])
head(train[,c('ps_ind_02_cat')])
train = train[order(train$id),]
raw_data = raw_data[order(raw_data$id),]
train$na_count <- apply(raw_data, 1, function(x) sum(is.na(x)))
### Add powers and logarithms
train2 = train
for(i in cont_inter_name){
train2[,paste0(i,"_sq")] = train2[,i]^2
}
for(i in cont_inter_name){
train2[,paste0(i,"_cube")] = train2[,i]^3
}
for(i in cont_inter_name){
train2[,paste0(i,"_log")] = log(train2[,i]+0.01)
}
for(i in 1:(length(cont_inter_name)-1)){
for(j in (i+1):length(cont_inter_name)){
a=train[,cont_inter_name[i]]
b=train[,cont_inter_name[j]]
d=c()
for (k in 1:length(a)){
train2[,paste0(cont_inter_name[i],'*',cont_inter_name[j])] = a[k]*b[k]
train2[,paste0(cont_inter_name[i],'-',cont_inter_name[j])] = a[k]-b[k]
train2[,paste0(cont_inter_name[i],'/',cont_inter_name[j])] = a[k]/b[k]
}
}
}
for(i in 1:(length(cont_inter_name)-1)){
for(j in (i+1):length(cont_inter_name)){
a=train[,cont_inter_name[i]]
b=train[,cont_inter_name[j]]
train2[,paste0(cont_inter_name[i],'*',cont_inter_name[j])] = a*b
train2[,paste0(cont_inter_name[i],'-',cont_inter_name[j])] = a-b
train2[,paste0(cont_inter_name[i],'/',cont_inter_name[j])] = a/b
}
}
head(train2)
train_scaled = train2
train_scaled[,214:ncol(train_scaled)] = scale(train_scaled[,214:ncol(train_scaled)])
train_scaled[,214:300] = scale(train_scaled[,214:300])
head(train_scaled[,214:300])
head(train2[,214:300])
for(i in 1:(length(cont_inter_name)-1)){
for(j in (i+1):length(cont_inter_name)){
a=train[,cont_inter_name[i]]
b=train[,cont_inter_name[j]]
train2[,paste0(cont_inter_name[i],'*',cont_inter_name[j])] = a*b
train2[,paste0(cont_inter_name[i],'-',cont_inter_name[j])] = a-b
train2[,paste0(cont_inter_name[i],'/',cont_inter_name[j])] = a/(b+0.5) #avoid dividing by zero
}
}
train_scaled = train2
train_scaled[,214:300] = scale(train_scaled[,214:300])
head(train2[,214:300])
head(train_scaled[,214:300])
train_scaled[,301:400] = scale(train_scaled[,301:400])
train_scaled[,401:ncol(train_scaled)] = scale(train_scaled[,401:ncol(train_scaled)])
train_scaled[,401:500] = scale(train_scaled[,401:500])
train_scaled[,501:ncol(train_scaled)] = scale(train_scaled[,501:ncol(train_scaled)])
cont_name = c("ps_ind_01","ps_ind_03","ps_ind_14","ps_ind_15","ps_reg_01","ps_reg_02",
"ps_reg_03","ps_car_11","ps_car_12","ps_car_13","ps_car_14","ps_car_15",
"ps_calc_01","ps_calc_02","ps_calc_03","ps_calc_04","ps_calc_05","ps_calc_06",
"ps_calc_07","ps_calc_08","ps_calc_09","ps_calc_10","ps_calc_11","ps_calc_12",
"ps_calc_13","ps_calc_14")
train_scaled[,cont_name]=scale(train_scaled[,cont_name])
head(train_scaled)
write.csv(train_scaled,"trainset_1208.csv",row.names = F)
############################################################
test = read.csv("testset_impute_onehot.csv",header=T)
############################################################
### Add count of missing values
raw_data = read.csv("test.csv",header=T)
test = test[order(test$id),]
raw_data = raw_data[order(raw_data$id),]
test$na_count <- apply(raw_data, 1, function(x) sum(is.na(x)))
### Add powers and logarithms
test2 = test
for(i in cont_inter_name){
test2[,paste0(i,"_sq")] = test2[,i]^2
}
for(i in cont_inter_name){
test2[,paste0(i,"_cube")] = test2[,i]^3
}
for(i in cont_inter_name){
test2[,paste0(i,"_log")] = log(test2[,i]+0.01)
}
############################################################
### Add count of missing values
raw_data_test = read.csv("test.csv",header=T)
## real data - testset
data = read.csv("testset_impute50000.csv",header=T)
cat_varname=c('ps_ind_02_cat','ps_ind_04_cat','ps_ind_05_cat','ps_ind_06_bin','ps_ind_07_bin',
'ps_ind_08_bin','ps_ind_09_bin','ps_ind_10_bin','ps_ind_11_bin','ps_ind_12_bin',
'ps_ind_13_bin','ps_ind_16_bin','ps_ind_17_bin','ps_ind_18_bin','ps_car_01_cat',
'ps_car_02_cat','ps_car_03_cat','ps_car_04_cat','ps_car_05_cat','ps_car_06_cat',
'ps_car_07_cat','ps_car_08_cat','ps_car_09_cat','ps_car_10_cat','ps_car_11_cat',
'ps_calc_15_bin','ps_calc_16_bin','ps_calc_17_bin','ps_calc_18_bin','ps_calc_19_bin',
'ps_calc_20_bin')
for (i in 1:length(cat_varname)){
one_hot=c()
drop = cat_varname[i]
cat_var=data[,drop]
cat_range=unique(cat_var)
if (length(cat_range)==2){
data[cat_var==cat_range[1],drop]=1
data[cat_var==cat_range[2],drop]=-1
}
else{
data=data[,!(names(data) %in% drop)]
for (j in 1:length(cat_range)){
one_hot=cbind(one_hot,as.numeric(cat_var==cat_range[j]))
}
one_hot=data.frame(one_hot)
for (j in 1:length(cat_range)){
colnames(one_hot)[j]=paste0(drop,"_",cat_range[j])
}
data=cbind(data,one_hot)
}
}
colnames(data)[1]='id'
write.csv(data,"testset_impute_onehot.csv",row.names = F)
## real data - testset
data = read.csv("testset_impute50000.csv",header=T)
## real data - trainset
setwd("C:/Users/Irina/Google Drive/Harvard classwork/MIT 6.867/Final project/Data")
## real data - testset
data = read.csv("testset_impute50000.csv",header=T)
wd()
getwd()
## real data - trainset
setwd("C:/Users/Irina/Google Drive/Harvard classwork/MIT 6.867/Final project/Data/1_Imputed")
## real data - testset
data = read.csv("testset_impute50000.csv",header=T)
cat_varname=c('ps_ind_02_cat','ps_ind_04_cat','ps_ind_05_cat','ps_ind_06_bin','ps_ind_07_bin',
'ps_ind_08_bin','ps_ind_09_bin','ps_ind_10_bin','ps_ind_11_bin','ps_ind_12_bin',
'ps_ind_13_bin','ps_ind_16_bin','ps_ind_17_bin','ps_ind_18_bin','ps_car_01_cat',
'ps_car_02_cat','ps_car_03_cat','ps_car_04_cat','ps_car_05_cat','ps_car_06_cat',
'ps_car_07_cat','ps_car_08_cat','ps_car_09_cat','ps_car_10_cat','ps_car_11_cat',
'ps_calc_15_bin','ps_calc_16_bin','ps_calc_17_bin','ps_calc_18_bin','ps_calc_19_bin',
'ps_calc_20_bin')
for (i in 1:length(cat_varname)){
one_hot=c()
drop = cat_varname[i]
cat_var=data[,drop]
cat_range=unique(cat_var)
if (length(cat_range)==2){
data[cat_var==cat_range[1],drop]=1
data[cat_var==cat_range[2],drop]=-1
}
else{
data=data[,!(names(data) %in% drop)]
for (j in 1:length(cat_range)){
one_hot=cbind(one_hot,as.numeric(cat_var==cat_range[j]))
}
one_hot=data.frame(one_hot)
for (j in 1:length(cat_range)){
colnames(one_hot)[j]=paste0(drop,"_",cat_range[j])
}
data=cbind(data,one_hot)
}
}
colnames(data)[1]='id'
write.csv(data,"testset_impute_onehot.csv",row.names = F)
############################################################
test = read.csv("testset_impute_onehot.csv",header=T)
test = data
test = test[order(test$id),]
raw_data_test = raw_data_test[order(raw_data_test$id),]
test$na_count <- apply(raw_data_test, 1, function(x) sum(is.na(x)))
head(test)
test2 = test
for(i in cont_inter_name){
test2[,paste0(i,"_sq")] = test2[,i]^2
}
for(i in cont_inter_name){
test2[,paste0(i,"_cube")] = test2[,i]^3
}
for(i in cont_inter_name){
test2[,paste0(i,"_log")] = log(test2[,i]+0.01)
}
test = test[order(test$id),]
#test$na_count <- apply(raw_data_test, 1, function(x) sum(is.na(x)))
raw_data_test$na_count <- apply(raw_data_test, 1, function(x) sum(is.na(x)))
merge(test,raw_data_test[,c("id", "na_count")], by="id")
test = data
test$na_count <- apply(raw_data_test, 1, function(x) sum(is.na(x)))
test2 = test
for(i in cont_inter_name){
test2[,paste0(i,"_sq")] = test2[,i]^2
}
for(i in cont_inter_name){
test2[,paste0(i,"_cube")] = test2[,i]^3
}
for(i in cont_inter_name){
test2[,paste0(i,"_log")] = log(test2[,i]+0.01)
}
### Add interactions, ratios, and differences
for(i in 1:(length(cont_inter_name)-1)){
for(j in (i+1):length(cont_inter_name)){
a=test[,cont_inter_name[i]]
b=test[,cont_inter_name[j]]
test2[,paste0(cont_inter_name[i],'*',cont_inter_name[j])] = a*b
test2[,paste0(cont_inter_name[i],'-',cont_inter_name[j])] = a-b
test2[,paste0(cont_inter_name[i],'/',cont_inter_name[j])] = a/(b+0.5) #avoid dividing by zero
}
}
### Scale data
test_scaled = test2
test_scaled[,214:300] = scale(test_scaled[,214:300]) # Split up for RAM limitations
test_scaled[,301:400] = scale(test_scaled[,301:400])
test_scaled[,401:500] = scale(test_scaled[,401:500])
test_scaled[,501:ncol(test_scaled)] = scale(test_scaled[,501:ncol(test_scaled)])
cont_name = c("ps_ind_01","ps_ind_03","ps_ind_14","ps_ind_15","ps_reg_01","ps_reg_02",
"ps_reg_03","ps_car_11","ps_car_12","ps_car_13","ps_car_14","ps_car_15",
"ps_calc_01","ps_calc_02","ps_calc_03","ps_calc_04","ps_calc_05","ps_calc_06",
"ps_calc_07","ps_calc_08","ps_calc_09","ps_calc_10","ps_calc_11","ps_calc_12",
"ps_calc_13","ps_calc_14")
test_scaled[,cont_name]=scale(test_scaled[,cont_name])
write.csv(test_scaled,"testset_1208.csv",row.names = F)
test_scaled = test2
for (i in 214:ncol(test_scaled)){ # Split up for RAM limitations
test_scaled[,i] = scale(test_scaled[,i])
}
test = test[order(test$id),]
gc()
gc()
test = test[order(test$id),]
for (i in 214:ncol(test_scaled)){ # Split up for RAM limitations
test_scaled[,i] = scale(test_scaled[,i])
}
